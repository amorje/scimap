{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Scimap is a scalable toolkit for analyzing spatial molecular data. The underlying framework is generalizable to spatial datasets mapped to XY coordinates. The package uses the anndata framework making it easy to integrate with other popular single-cell analysis toolkits. It includes preprocessing, phenotyping, visualization, clustering, spatial analysis and differential spatial testing. The Python-based implementation efficiently deals with large datasets of millions of cells. </p> <p>SCIMAP development was led by Ajit Johnson Nirmal, Harvard Medical School. Check out other tools from the Nirmal Lab. </p>"},{"location":"#funding","title":"Funding","text":"<p>This work was supported by the following NIH grant K99-CA256497</p>"},{"location":"Getting%20Started/","title":"Getting Started","text":"<p>Import Scimap as:</p> <pre><code>pip install scimap\nimport scimap as sm\n</code></pre>"},{"location":"Getting%20Started/#load-data","title":"Load Data","text":"<p>In order to make data analysis tools interoperable, <code>scimap</code> has adopted the the <code>AnnData</code> data structure. This allows users to use a wealth of single-cell analysis tools that works with AnnData structuring.</p> <p>At the most basic level, an <code>AnnData</code> object <code>adata</code> stores a data matrix <code>adata.X</code>, annotation of observations <code>adata.obs</code> and variables <code>adata.var</code> as <code>pd.DataFrame</code> and unstructured annotation <code>adata.uns</code> as dict. Names of observations and variables can be accessed via <code>adata.obs_names</code> and <code>adata.var_names</code>, respectively. AnnData objects can be sliced like dataframes, for example, <code>adata_subset = adata[:, list_of_gene_names]</code>. For more, see the <code>AnnData</code> page.</p> <p>To initialize an AnnData object, the following can be performed.</p> <pre><code>import anndata as ad\nimport pandas as pd\n\n# Load the data\ndata = pd.read_csv('counts_matrix.csv') # Single-Cell counts matrix\nmeta = pd.read_csv('meta_data.csv') # MetaData\n\n# Create the AnnData object\nadata = ad.AnnData(data)\nadata.obs = meta\n</code></pre> <p>Note</p> <p>If you used mcmicro pipeline to process your images, <code>scimap</code> provides a handy function to convert <code>mcmicro</code> output to <code>AnnData</code> object.</p> <pre><code>filepath = ['/path/to/file.csv']\nadata = sm.pp.mcmicro_to_scimap (filepath)\n</code></pre>"},{"location":"Getting%20Started/#work-flow","title":"Work Flow","text":"<p>The typical workflow then consists of subsequent calls of <code>scimap</code> tools:</p> <p>Pre-Processing Tools under <code>sm.pp.&lt;tool&gt;</code> Analysis Tools under <code>sm.tl.&lt;tool&gt;</code> Plotting Tools under <code>sm.pl.&lt;tool&gt;</code> Helper Tools under <code>sm.hl.&lt;tool&gt;</code> </p>"},{"location":"Tools%20Shortcut/","title":"Tools Shortcut","text":"<pre><code>import scimap as sm\n</code></pre>"},{"location":"Tools%20Shortcut/#preprocessing-pp","title":"Preprocessing: <code>pp</code>","text":"<p><code>Scimap</code> provides a suite of tools to preprocess the data for subsequent analysis.</p> Function Short Description <code>sm.pp.mcmicro_to_scimap</code> <code>mcmicro</code> output to scimap compatible object <code>sm.pp.rescale</code> Manual/Auto gate based scaling of data <code>sm.pp.combat</code> Batch correction tool"},{"location":"Tools%20Shortcut/#tools-tl","title":"Tools: <code>tl</code>","text":"<code>sm.tl.phenotype_cells</code> Probability distribution based cell phenotyping <code>sm.tl.cluster</code> Cluster or sub-cluster single-cells using a variety of algorithms <code>sm.tl.umap</code> Dimensionality Reduction using UMAP <code>sm.tl.foldchange</code> Compute foldchange in phenotypes between samples/ROIs <code>sm.tl.spatial_distance</code> Computes nearest distance between all phenotypes for every cell <code>sm.tl.spatial_interaction</code> cell\u2013cell interactions analysis <code>sm.tl.spatial_count</code> Distribution of cell-types with local neighborhood <code>sm.tl.spatial_lda</code> Latent Dirichlet Allocation (LDA) modelling for spatial motifs <code>sm.tl.spatial_expression</code> Distribution of spatial expression with local neighborhood <code>sm.tl.spatial_cluster</code> Distribution of spatial expression with local neighborhood <code>sm.tl.spatial_pscore</code> Scoring proximity between user defined cell types <code>sm.tl.spatial_aggregate</code> Aggregates of cell-types with local neighborhood <code>sm.tl.spatial_similarity_search</code> Search for similar looking regions within and across images"},{"location":"Tools%20Shortcut/#plotting-pl","title":"Plotting: <code>pl</code>","text":"<code>sm.pl.image_viewer</code> Opens the image with overlays on a <code>napari</code> browser <code>sm.pl.addROI_image</code> Add ROI's with  <code>napari</code> browser <code>sm.pl.gate_finder</code> Overlays gating positivity on the image for manual gating <code>sm.pl.distPlot</code> Distribution plot of a given marker <code>sm.pl.densityPlot2D</code> 2D density plotting of marker expression <code>sm.pl.cluster_plots</code> Meta function that outputs umap, heatmap and ranked makers for each group <code>sm.pl.umap</code> Overlays markers on UMAP <code>sm.pl.foldchange</code> vizualize foldchange in phenotypes between samples/ROIs <code>sm.pl.spatial_scatterPlot</code> Scatter plots of spatially resolved data <code>sm.pl.spatial_distance</code> Visualize distance between phenotypes <code>sm.pl.spatial_interaction</code> Heatmap of cell\u2013cell interaction analysis <code>sm.pl.spatial_pscore</code> Bar plot of the derived Spatial Proximity Scores <code>sm.pl.stacked_barplot</code> Generate a stacked barplot from any two columns of categorical data <code>sm.pl.pie</code> Generate a pieplot of cell-type proportion or any categorical data <code>sm.pl.voronoi</code> Generate a voronoi diagram and color it with categorical data"},{"location":"Tools%20Shortcut/#helper-functions-hl","title":"Helper Functions: <code>hl</code>","text":"<code>sm.hl.classify</code> Quickly classify cells based on pos/negativity of list of markers <code>sm.hl.rename</code> Quickly rename values within columns based on <code>dict</code> mapping <code>sm.hl.addROI_omero</code> Add ROI's extracted from Omero to Scimap object <code>sm.hl.dropFeatures</code> Handy Function to subset the <code>adata</code> object <code>sm.hl.animate</code> Create a animated scatter plot of <code>embedding -&gt; physical location</code> <code>sm.hl.scimap_to_csv</code> Export scimap object to CSV"},{"location":"Functions/hl/addROI_omero/","title":"addROI_omero","text":"<p>Short Description</p> <p><code>sm.hl.addROI_omero</code>: The function allows users to add annotations that have been  extracted from Omero using the following  script: https://gist.github.com/Yu-AnChen/58754f960ccd540e307ed991bc6901b0.</p>"},{"location":"Functions/hl/addROI_omero/#scimap.helpers._addROI_omero--function","title":"Function","text":""},{"location":"Functions/hl/addROI_omero/#scimap.helpers._addROI_omero.addROI_omero","title":"<code>addROI_omero(adata, roi, x_coordinate='X_centroid', y_coordinate='Y_centroid', imageid='imageid', subset=None, overwrite=True, label='ROI', n_jobs=-1, verbose=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData object</p> required <code>roi</code> <p>DataFrame Pandas dataframe of ROI's that have been extracted from Omero using the following script: https://gist.github.com/Yu-AnChen/58754f960ccd540e307ed991bc6901b0. Please note that the function currently does not handle overlapping ROI's and so make sure the ROI's are mutually exclusive.</p> required <code>x_coordinate</code> <p>float, required Column name containing the x-coordinates values.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <p>float, required Column name containing the y-coordinates values.</p> <code>'Y_centroid'</code> <code>imageid</code> <p>string, optional In the event that the adata object contains multiple images, it is important that ROIs are added to each image seperately. Pass the name  of the column that contains the <code>imageid</code> and use it in conjunction with the <code>subset</code> parameter to add ROI's to a specific image.</p> <code>'imageid'</code> <code>subset</code> <p>list, optional Name of the image to which the ROI is to be added. Note if you have multiple images in the  adata object, you will need to add ROI's to each image one after the other independently. </p> <code>None</code> <code>overwrite</code> <p>bool, optional In the event you have multiple images in the adata object, ROI can be added to each image independently using the <code>imageid</code> and <code>subset</code> parameter. If you wish the results to be all saved with in the same column set this parameter to <code>False</code>. By default, the  function will overwrite the <code>label</code> column. </p> <code>True</code> <code>label</code> <p>string, optional Key for the returned data, stored in <code>adata.obs</code>.</p> <code>'ROI'</code> <code>n_jobs</code> <p>int, optional Number of cores to use. Default is to use all available cores.</p> <code>-1</code> <p>Returns:</p> Type Description <p>adata Modified AnnData object. Check <code>adata.obs</code> for an additional column.</p> <pre><code>    roi = pd.read_csv('ROI/ROI_Z147_1_750.csv')\n    adata = sm.hl.addROI_omero (adata, roi, label='aj_ROI')\n</code></pre> Source code in <code>scimap/helpers/_addROI_omero.py</code> <pre><code>def addROI_omero (adata, roi, x_coordinate='X_centroid',y_coordinate='Y_centroid',\n                   imageid='imageid', subset=None, overwrite=True,\n                   label='ROI', n_jobs=-1, verbose=False):\n\n\"\"\"\nParameters:\n\n    adata : AnnData object\n\n    roi : DataFrame  \n        Pandas dataframe of ROI's that have been extracted from Omero using the following script: https://gist.github.com/Yu-AnChen/58754f960ccd540e307ed991bc6901b0.\n        Please note that the function currently does not handle overlapping ROI's and so make sure the ROI's are mutually exclusive.\n\n    x_coordinate : float, required  \n        Column name containing the x-coordinates values.\n\n    y_coordinate : float, required  \n        Column name containing the y-coordinates values.\n\n    imageid : string, optional  \n        In the event that the adata object contains multiple images, it is\n        important that ROIs are added to each image seperately. Pass the name \n        of the column that contains the `imageid` and use it in conjunction with\n        the `subset` parameter to add ROI's to a specific image.\n\n    subset : list, optional  \n        Name of the image to which the ROI is to be added. Note if you have multiple images in the \n        adata object, you will need to add ROI's to each image one after the other independently. \n\n    overwrite : bool, optional  \n        In the event you have multiple images in the adata object, ROI can be added to each image\n        independently using the `imageid` and `subset` parameter. If you wish the results to be\n        all saved with in the same column set this parameter to `False`. By default, the \n        function will overwrite the `label` column. \n\n    label : string, optional  \n        Key for the returned data, stored in `adata.obs`.\n\n    n_jobs : int, optional  \n        Number of cores to use. Default is to use all available cores.\n\nReturns:\n    adata\n        Modified AnnData object. Check `adata.obs` for an additional column.\n\nExample:\n```python\n    roi = pd.read_csv('ROI/ROI_Z147_1_750.csv')\n    adata = sm.hl.addROI_omero (adata, roi, label='aj_ROI')\n```\n    \"\"\"\n\n    # create data matrix that has the co-ordinates\n    data = pd.DataFrame(adata.obs)[[x_coordinate, y_coordinate, imageid]]\n\n    # subset the data if needed\n    if subset is not None:\n        # convert string to list\n        if isinstance(subset, str): \n            subset = [subset]\n        # subset data\n        sub_data = data[data['imageid'].isin(subset)]\n    else:\n        sub_data = data\n\n\n    def parse_roi_points(all_points):\n        return np.array(\n            re.findall(r'\\d+\\.?\\d+', all_points), dtype=float\n        ).reshape(-1, 2)\n\n    def ellipse_points_to_patch(\n        vertex_1, vertex_2,\n        co_vertex_1, co_vertex_2\n    ):\n\"\"\"\n        Parameters\n        ----------\n        vertex_1, vertex_2, co_vertex_1, co_vertex_2: array like, in the form of (x-coordinate, y-coordinate)\n\n        \"\"\"\n        v_and_co_v = np.array([\n            vertex_1, vertex_2,\n            co_vertex_1, co_vertex_2\n        ])\n        centers = v_and_co_v.mean(axis=0)\n\n        d = sdistance.cdist(v_and_co_v, v_and_co_v, metric='euclidean')\n        width = d[0, 1]\n        height = d[2, 3]\n\n        vector_2 = v_and_co_v[1] - v_and_co_v[0]\n        vector_2 /= np.linalg.norm(vector_2)\n\n        angle = np.degrees(np.arccos([1, 0] @ vector_2))\n\n        ellipse_patch = mpatches.Ellipse(\n            centers, width=width, height=height, angle=angle        \n        )\n        return ellipse_patch\n\n    def get_mpatch(roi):\n        points = parse_roi_points(roi['all_points'])\n\n        roi_type = roi['type']\n        if roi_type in ['Point', 'Line']:\n            roi_mpatch = mpatches.Polygon(points, closed=False)\n        elif roi_type in ['Rectangle', 'Polygon', 'Polyline']:\n            roi_mpatch = mpatches.Polygon(points, closed=True)\n        elif roi_type == 'Ellipse':\n            roi_mpatch = ellipse_points_to_patch(*points)\n        else:\n            raise ValueError\n        return roi_mpatch\n\n    def add_roi_internal (roi_id):\n        roi_subset = roi[roi['Id'] == roi_id].iloc[0]\n\n        roi_mpatch = get_mpatch(roi_subset)\n        inside = sub_data[roi_mpatch.contains_points(sub_data[[x_coordinate, y_coordinate]])]\n        inside['ROI_internal'] = roi_subset['Name']\n\n        # return\n        return inside\n\n    # Apply function to all rows of the ROI dataframe\n    roi_list = roi['Id'].unique()\n    final_roi = Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(add_roi_internal)(roi_id=i) for i in roi_list)   \n\n    # Merge all into a single DF\n    final_roi = pd.concat(final_roi)[['ROI_internal']]\n\n    # Add the list to obs\n    result = pd.merge(data, final_roi, left_index=True, right_index=True, how='outer')\n\n    # Reindex\n    result = result.reindex(adata.obs.index)\n\n    # check if adata already has a column with the supplied label\n    # if avaialble overwrite or append depending on users choice\n    if label in adata.obs.columns:\n        if overwrite is False:\n            # Append\n            # retreive the ROI information\n            old_roi = adata.obs[label]\n            combined_roi = pd.merge(result, old_roi, left_index=True, right_index=True, how='outer')\n            combined_roi['ROI_internal'] = combined_roi['ROI_internal'].fillna(combined_roi[label])\n        else:\n            # Over write\n            combined_roi = result.copy()\n            combined_roi['ROI_internal'] = combined_roi['ROI_internal'].fillna('Other')     \n    else:\n        # if label is not present just create a new one\n        combined_roi = result.copy()\n        combined_roi['ROI_internal'] = combined_roi['ROI_internal'].fillna('Other') \n\n\n    # Add to adata\n    adata.obs[label] = combined_roi['ROI_internal']\n\n    # return\n    return adata\n</code></pre>"},{"location":"Functions/hl/animate/","title":"animate","text":"<p>Short Description</p> <p><code>sm.hl.animate</code>:  The function allows users to generate an animation between UMAP  space and physical X and Y coordinates.  </p> <p>Depending on the computer configuration and how the function is run like jupyter notebook  the live view maynot render smoothly or render at all and hence  saving the animation is highly recommended. However <code>imagemagick</code> needs to be installed to  be able to write the animation to disk. Please follow this link to install <code>imagemagick</code>:  https://imagemagick.org/script/download.php</p>"},{"location":"Functions/hl/animate/#scimap.helpers._animate--function","title":"Function","text":""},{"location":"Functions/hl/animate/#scimap.helpers._animate.animate","title":"<code>animate(adata, color=None, palette=None, embedding='umap', x_coordinate='X_centroid', y_coordinate='Y_centroid', flip_y=True, imageid='imageid', subset=None, use_layer=None, use_raw=False, log=False, subsample=None, random_state=0, n_frames=50, interval=50, reverse=True, final_frame=5, s=None, alpha=1, cmap='vlag', tight_layout=True, plot_legend=False, title=None, fontsize=20, watermark=True, figsize=(5, 5), pltStyle=None, save_animation=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData Object  </p> required <code>color</code> <p>list, optional Keys for annotations of observations in <code>adata.obs.columns</code> or genes in <code>adata.var.index</code>.  e.g. <code>color = ['CD3D']</code> or <code>color = ['phenotype']</code>. Please note only one value can be passed at a time. The default is None.</p> <code>None</code> <code>palette</code> <p>dict, optional Colors to use for plotting categorical annotation groups.  It accepts a <code>dict</code> mapping categories to colors.  e.g. <code>palette = {'T cells': '#000000', 'B cells': '#FFF675'}</code>. Auto color will be generated for categories that are not specified. The default is None.</p> <code>None</code> <code>embedding</code> <p>string, optional The <code>label key</code> used when running <code>sm.tl.umap()</code>. The default is 'umap'.</p> <code>'umap'</code> <code>x_coordinate</code> <p>string, optional Column that contains the <code>x_coordinates</code>. The default is 'X_centroid'.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <p>string, optional Column that contains the <code>y_coordinates</code>. The default is 'Y_centroid'.</p> <code>'Y_centroid'</code> <code>flip_y</code> <p>bool, optional Flip the Y-axis if needed. Some algorithms output the XY with the Y-coordinates flipped. If the image overlays do not align to the cells, try again by setting this to <code>False</code>.</p> <code>True</code> <code>imageid</code> <p>string, optional Name of the column that contains the unique imageid. The default is 'imageid'.</p> <code>'imageid'</code> <code>subset</code> <p>list, optional Unique imageid of a image to be subsetted for plotting. Please note as the coordinate system for each images would be unique, only a single image should be passed at a time.  Please use this parameter in conjuction with <code>imageid</code> to subset a single  image. The Function automatically subsets the <code>UMAP</code> coordinates. The default is None.</p> <code>None</code> <code>use_layer</code> <p>string, optional Pass name of any <code>Layer</code> in AnnData. The default is <code>None</code> and <code>adata.X</code> is used.</p> <code>None</code> <code>use_raw</code> <p>bool, optional If set to <code>True</code>, values in <code>adata.raw.X</code> will be used to color the plot. The default is False.</p> <code>False</code> <code>log</code> <p>bool, optional If set to <code>True</code>, the data will natural log transformed using <code>np.log1p()</code> for coloring. The default is False.</p> <code>False</code> <code>subsample</code> <p>float, optional Accepts a value between 0-1; Randomly subsamples the data if needed for large images. The default is None.</p> <code>None</code> <code>random_state</code> <p>int, optional Seed for random number generator. The default is 0.</p> <code>0</code> <code>n_frames</code> <p>int, optional Number of frames inbetween the UMAP coordinates and the physical coordinates.  Higher numbers create a smoother animation. The default is 50.</p> <code>50</code> <code>interval</code> <p>int, optional interval between frames in milliseconds. The default is 50.</p> <code>50</code> <code>reverse</code> <p>bool, optional If <code>True</code> animation will also include <code>Physical -&gt; UMAP</code>. The default is True.</p> <code>True</code> <code>final_frame</code> <p>int, optional The number of frames at the end. Increasing this can be useful to vizualize the  last frame for a longer time. The default is 5.</p> <code>5</code> <code>s</code> <p>int, optional The marker size in points. The default is None.</p> <code>None</code> <code>alpha</code> <p>float, optional blending value, between 0 (transparent) and 1 (opaque). The default is 1.</p> <code>1</code> <code>cmap</code> <p>string, optional Color map to use for continous variables. Can be a name or a Colormap  instance (e.g. \"magma\u201d, \"viridis\"). The default is 'vlag'.</p> <code>'vlag'</code> <code>tight_layout</code> <p>bool, optional Adjust the padding between and around subplots. If True it will ensure that the legends are visible. The default is True.</p> <code>True</code> <code>plot_legend</code> <p>bool, optional Plots the legend. The default is False.</p> <code>False</code> <code>title</code> <p>bool or string, optional Add a title to your plot. If <code>True</code>, it will add the default name of the plot. However, a custom name can be passed through this parameter as well.  e.g. <code>title = \"custom title\"</code>. The default is None.</p> <code>None</code> <code>fontsize</code> <p>int, optional Font size of the title. The default is 20.</p> <code>20</code> <code>watermark</code> <p>bool, optional Shows <code>made with scimap</code> in the bottom of the plot. The default is True.</p> <code>True</code> <code>figsize</code> <p>tuple, optional Width, height in inches. The default is (10, 10).</p> <code>(5, 5)</code> <code>pltStyle</code> <p>string, optional Plot styles offered by matplotlib. e.g. <code>dark_background</code>. The default is True.</p> <code>None</code> <code>save_animation</code> <p>string, optional Pass path to saving animation. Please note depending on the computer specs the live  view may not be optimal and hence saving the animation is recommended.  e.g <code>\\path      o\\directory\figure</code> The default is None.</p> <code>None</code> <code>**kwargs</code> <p>Other <code>matplotlib</code> parameters.   </p> <code>{}</code> <p>Returns:</p> Type Description <p>Animation Can be saved as <code>gif</code> using save_animation parameter.</p> <pre><code># Run UMAP\nadata = sm.tl.umap(adata)\n\n# Run animation and color it by the identified cell-types\nsm.hl.animate (adata, color='phenotype')\n</code></pre> Source code in <code>scimap/helpers/_animate.py</code> <pre><code>def animate (adata, color=None,\n             palette=None,\n             embedding='umap', \n             x_coordinate='X_centroid', \n             y_coordinate='Y_centroid',\n             flip_y=True,\n             imageid='imageid', subset=None,\n             use_layer=None, use_raw=False, log=False,\n             subsample=None,random_state=0,\n             n_frames=50, interval=50,reverse=True,final_frame=5, \n             s=None, alpha=1,  cmap='vlag',\n             tight_layout=True,plot_legend=False,\n             title=None, fontsize=20,watermark=True,\n             figsize=(5,5), pltStyle=None,\n             save_animation=None,**kwargs):\n\"\"\"\nParameters:\n    ----------\n    adata : AnnData Object  \n\n    color : list, optional\n        Keys for annotations of observations in `adata.obs.columns` or genes in `adata.var.index`. \n        e.g. `color = ['CD3D']` or `color = ['phenotype']`. Please note only one value can be passed at a time.\n        The default is None.\n\n    palette : dict, optional  \n        Colors to use for plotting categorical annotation groups. \n        It accepts a `dict` mapping categories to colors. \n        e.g. `palette = {'T cells': '#000000', 'B cells': '#FFF675'}`.\n        Auto color will be generated for categories that are not specified. The default is None.\n\n    embedding : string, optional  \n        The `label key` used when running `sm.tl.umap()`. The default is 'umap'.\n\n    x_coordinate : string, optional  \n        Column that contains the `x_coordinates`. The default is 'X_centroid'.\n\n    y_coordinate : string, optional  \n        Column that contains the `y_coordinates`. The default is 'Y_centroid'.\n\n    flip_y : bool, optional  \n        Flip the Y-axis if needed. Some algorithms output the XY with the Y-coordinates flipped.\n        If the image overlays do not align to the cells, try again by setting this to `False`.\n\n    imageid : string, optional  \n        Name of the column that contains the unique imageid. The default is 'imageid'.\n\n    subset : list, optional  \n        Unique imageid of a image to be subsetted for plotting. Please note as the coordinate\n        system for each images would be unique, only a single image should be passed at a time. \n        Please use this parameter in conjuction with `imageid` to subset a single \n        image. The Function automatically subsets the `UMAP` coordinates. The default is None.\n\n    use_layer : string, optional  \n        Pass name of any `Layer` in AnnData. The default is `None` and `adata.X` is used.\n\n    use_raw : bool, optional  \n        If set to `True`, values in `adata.raw.X` will be used to color the plot. The default is False.\n\n    log : bool, optional  \n        If set to `True`, the data will natural log transformed using `np.log1p()` for coloring. The default is False.\n\n    subsample : float, optional  \n        Accepts a value between 0-1; Randomly subsamples the data if needed for large images. The default is None.\n\n    random_state : int, optional  \n        Seed for random number generator. The default is 0.\n\n    n_frames : int, optional  \n        Number of frames inbetween the UMAP coordinates and the physical coordinates. \n        Higher numbers create a smoother animation. The default is 50.\n\n    interval : int, optional  \n        interval between frames in milliseconds. The default is 50.\n\n    reverse : bool, optional  \n        If `True` animation will also include `Physical -&gt; UMAP`. The default is True.\n\n    final_frame : int, optional  \n        The number of frames at the end. Increasing this can be useful to vizualize the \n        last frame for a longer time. The default is 5.\n\n    s : int, optional  \n        The marker size in points. The default is None.\n\n    alpha : float, optional  \n        blending value, between 0 (transparent) and 1 (opaque). The default is 1.\n\n    cmap : string, optional  \n        Color map to use for continous variables. Can be a name or a Colormap \n        instance (e.g. \"magma\u201d, \"viridis\"). The default is 'vlag'.\n\n    tight_layout : bool, optional  \n        Adjust the padding between and around subplots. If True it will ensure that\n        the legends are visible. The default is True.\n\n    plot_legend : bool, optional  \n        Plots the legend. The default is False.\n\n    title : bool or string, optional  \n        Add a title to your plot. If `True`, it will add the default name of the plot.\n        However, a custom name can be passed through this parameter as well. \n        e.g. `title = \"custom title\"`. The default is None.\n\n    fontsize : int, optional  \n        Font size of the title. The default is 20.\n\n    watermark : bool, optional  \n        Shows `made with scimap` in the bottom of the plot. The default is True.\n\n    figsize : tuple, optional  \n        Width, height in inches. The default is (10, 10).\n\n    pltStyle : string, optional  \n        Plot styles offered by matplotlib. e.g. `dark_background`. The default is True.\n\n    save_animation : string, optional  \n        Pass path to saving animation. Please note depending on the computer specs the live \n        view may not be optimal and hence saving the animation is recommended. \n        e.g `\\path\\to\\directory\\figure` The default is None.\n\n    **kwargs : Other `matplotlib` parameters.   \n\nReturns:\n\n    Animation\n        Can be saved as `gif` using save_animation parameter.\n\nExample:\n```python\n\n# Run UMAP\nadata = sm.tl.umap(adata)\n\n# Run animation and color it by the identified cell-types\nsm.hl.animate (adata, color='phenotype')\n\n```\n    \"\"\"\n\n    # intrapolation function between co-ordinate sytems\n    def tween(e1, e2, n_frames, final_frame):\n\n        # number of frame to pop\n        #n_frames = int(n_frames + (n_frames*0.3))\n        for i in range(5):\n            yield e1\n        for i in range(n_frames):\n            alpha = i / float(n_frames - 1)\n            yield (1 - alpha) * e1 + alpha * e2\n        for i in range(final_frame):\n            yield e2\n\n        return\n\n\n    # check if umap tool has been run\n    try:\n        adata.obsm[embedding]\n    except KeyError:\n        raise KeyError(\"Please run `sm.tl.umap(adata)` first\")\n\n    # identify the coordinates\n    umap_coordinates = pd.DataFrame(adata.obsm[embedding],index=adata.obs.index, columns=['umap-1','umap-2'])\n    real_coordinates = adata.obs[[x_coordinate,y_coordinate]]\n\n    # other data that the user requests\n    if color is not None:\n        if isinstance(color, str):\n            color = [color]\n\n        # identify if all elemets of color are available        \n        if len(color) &gt; 1:\n            raise ValueError(\"Only a single value in `color` is supported\")\n\n        # identify if all elemets of color are available        \n        if set(color).issubset(list(adata.var.index) + list(adata.obs.columns)) is False:\n            raise ValueError(\"Element passed to `color` is not found in adata, please check!\")\n\n        # organise the data\n        if any(item in color for item in list(adata.obs.columns)):\n            adataobs = adata.obs.loc[:, adata.obs.columns.isin(color)]\n        else:\n            adataobs = None\n\n        if any(item in color for item in list(adata.var.index)):\n            # find the index of the marker\n            marker_index = np.where(np.isin(list(adata.var.index), color))[0]\n            if use_layer is not None:\n                adatavar = adata.layers[use_layer][:, np.r_[marker_index]]\n            elif use_raw is True:\n                adatavar = adata.raw.X[:, np.r_[marker_index]]\n            else:\n                adatavar = adata.X[:, np.r_[marker_index]]\n            adatavar = pd.DataFrame(adatavar, index=adata.obs.index, columns = list(adata.var.index[marker_index]))\n        else:\n            adatavar = None\n\n        # combine all color data\n        if adataobs is not None and adatavar is not None:\n            color_data = pd.concat ([adataobs, adatavar], axis=1)\n        elif adataobs is not None and adatavar is None:\n            color_data = adataobs\n            # convert to string\n            color_data[color] = color_data[color].astype('category')\n        elif adataobs is None and adatavar is not None:\n            color_data = adatavar    \n\n    else:\n        color_data = None\n\n    # combine color data with umap coordinates\n    if color_data is not None:\n        final_data = pd.concat([umap_coordinates, real_coordinates, color_data], axis=1)\n    else:\n        final_data = umap_coordinates\n\n    # subset the final data if nedded\n    if subset is not None:\n        if isinstance(subset, str):\n            subset = [subset]\n        cell_to_keep = adata[adata.obs[imageid].isin(subset)].obs.index\n        final_data = final_data.loc[cell_to_keep]\n\n    # subsample the data if user requests\n    if subsample is not None:\n        final_data = final_data.sample(frac=subsample, replace=False, random_state=random_state)\n\n    # extract the spaces\n    e1 = final_data[['umap-1', 'umap-2']].values.astype(float)\n    e2 = final_data[[x_coordinate,y_coordinate]].values.astype(float)\n\n\n    # rescale to same co-ordinates system\n    e1[:, 0] -= (max(e1[:, 0]) + min(e1[:, 0])) / 2\n    e1[:, 1] -= (max(e1[:, 1]) + min(e1[:, 1])) / 2\n    # scale\n    scale = max(max(e1[:, 0]) - min(e1[:, 0]), max(e1[:, 1]) - min(e1[:, 1]))\n    e1[:, 0] /= scale\n    e1[:, 1] /= scale\n    # Translate\n    e1[:, 0] += 0.5\n    e1[:, 1] += 0.5\n\n    # rescale co-ordinates\n    e2[:, 0] -= (max(e2[:, 0]) + min(e2[:, 0])) / 2\n    e2[:, 1] -= (max(e2[:, 1]) + min(e2[:, 1])) / 2\n    # scale\n    scale = max(max(e2[:, 0]) - min(e2[:, 0]), max(e2[:, 1]) - min(e2[:, 1]))\n    e2[:, 0] /= scale\n    e2[:, 1] /= scale\n    # Translate\n    e2[:, 0] += 0.5\n    e2[:, 1] += 0.5\n\n    # remove the identified indeces\n    def delete_multiple_element(list_object, indices):\n        indices = sorted(indices, reverse=True)\n        for idx in indices:\n            if idx &lt; len(list_object):\n                list_object.pop(idx)\n\n    # run the interpolation\n    interpolation = list(tween(e1, e2, n_frames=n_frames, final_frame=final_frame))\n    # drop x number of frames\n    top_frames = int(n_frames + 5)\n\n    l = np.percentile(range(5,top_frames),30); h = np.percentile(range(5,top_frames),80)\n    index_between = list(range(int(l), int(h)))\n    numElems = int(len(index_between) * 0.5)\n    drop = np.round(np.linspace(0, len(index_between) - 1, numElems)).astype(int)\n    drop_index = [index_between[i] for i in drop] \n\n    # delete frames\n    delete_multiple_element(interpolation, drop_index)\n\n    top20 = np.percentile(range(5,top_frames),20); top30 = np.percentile(range(5,top_frames),30)\n    bottom80 = np.percentile(range(5,top_frames),80); bottom90 = np.percentile(range(5,top_frames),90)\n\n    ib_top = list(range(int(top20), int(top30)))\n    ib_bottom = list(range(int(bottom80), int(bottom90)))\n    ib = ib_top + ib_bottom\n    numElems2 = int(len(ib) * 0.20)\n    drop2 = np.round(np.linspace(0, len(ib) - 1, numElems2)).astype(int)\n    di = [ib[i] for i in drop2] \n    # delete frames\n    delete_multiple_element(interpolation, di)\n\n    top10 = np.percentile(range(5,top_frames),10); top19 = np.percentile(range(5,top_frames),19)\n    bottom91 = np.percentile(range(5,top_frames),91); bottom95 = np.percentile(range(5,top_frames),95)\n\n    ib_top = list(range(int(top10), int(top19)))\n    ib_bottom = list(range(int(bottom91), int(bottom95)))\n    ib = ib_top + ib_bottom\n    numElems2 = int(len(ib) * 0.10)\n    drop2 = np.round(np.linspace(0, len(ib) - 1, numElems2)).astype(int)\n    di = [ib[i] for i in drop2] \n    # delete frames\n    delete_multiple_element(interpolation, di)\n\n\n\n\n    if reverse is True:\n        interpolation = interpolation + interpolation[::-1]\n\n    # generate colors\n    if s is None:\n        s = 130000 / final_data.shape[0]\n\n    # if there are categorical data then assign colors to them\n    if final_data.select_dtypes(exclude=[\"number\",\"bool_\",\"object_\"]).shape[1] &gt; 0:\n        # find all categories in the dataframe\n        cat_data = final_data.select_dtypes(exclude=[\"number\",\"bool_\",\"object_\"])\n        # find all categories\n        all_cat = []\n        for i in cat_data.columns:\n            all_cat.append(list(cat_data[i].cat.categories))\n\n        # generate colormapping for all categories\n        less_9 = [colors.rgb2hex(x) for x in sns.color_palette('Set1')]\n        nineto20 = [colors.rgb2hex(x) for x in sns.color_palette('tab20')]\n        greater20 = [colors.rgb2hex(x) for x in sns.color_palette('gist_ncar', max([len(i) for i in all_cat]))]\n\n        all_cat_colormap = dict()\n        for i in range(len(all_cat)):\n            if len(all_cat[i]) &lt;= 9:\n                dict1 = dict(zip(all_cat[i] , less_9[ : len(all_cat[i]) ]   ))\n            elif len(all_cat[i]) &gt; 9 and len(all_cat[i]) &lt;= 20:\n                dict1 = dict(zip(all_cat[i] , nineto20[ : len(all_cat[i]) ]   ))\n            else:\n                dict1 = dict(zip(all_cat[i] , greater20[ : len(all_cat[i]) ]   ))\n            all_cat_colormap.update(dict1)\n\n        # if user has passed in custom colours update the colors\n        if palette is not None:\n            all_cat_colormap.update(palette)\n    else:\n        all_cat_colormap = None\n\n    # number of plots\n    nplots = len(final_data.columns) - 4 # total number of plots\n    if nplots &gt; 0:\n        column_to_plot = [e for e in list(final_data.columns) if e not in ('umap-1', 'umap-2',x_coordinate,y_coordinate)][0]\n        if all_cat_colormap is not None:\n            custom_color = list(final_data[column_to_plot].map(all_cat_colormap).values)\n\n\n    # plot\n    plt.rcdefaults()\n    if pltStyle is not None:\n        plt.style.use(pltStyle)\n    fig, ax = plt.subplots(figsize=figsize)\n\n\n    ax.set(xlim=(-0.1, 1.1), ylim=(-0.1, 1.1))\n    if flip_y is True:\n        ax.invert_yaxis()\n\n\n\n    if nplots == 0:\n        scat = ax.scatter(x = interpolation[0][:, 0], y = interpolation[0][:, 1], s=s, cmap=cmap, alpha=alpha, **kwargs)\n        plt.tick_params(right= False,top= False,left= False, bottom= False)\n        ax.get_xaxis().set_ticks([]); ax.get_yaxis().set_ticks([])\n        if watermark is True:\n            ax.text(1.08, 1.08, \"made with scimap.xyz\",horizontalalignment=\"right\",\n            verticalalignment=\"bottom\", alpha=0.5,fontsize=fontsize * 0.4)\n        if title is True: \n            plt.title(column_to_plot, fontsize=fontsize)\n        elif isinstance(title, str):\n            plt.title(title, fontsize=fontsize)  \n        if tight_layout is True:\n            plt.tight_layout()\n\n    if nplots &gt; 0:\n        if all_cat_colormap is None:\n            scat = ax.scatter(x = interpolation[0][:, 0], y = interpolation[0][:, 1], s=s, \n                           c=final_data[column_to_plot],\n                           cmap=cmap, alpha=alpha, **kwargs)\n            if plot_legend is True:\n                plt.colorbar(scat, ax=ax)\n        else:\n            scat = ax.scatter(x = interpolation[0][:, 0], y = interpolation[0][:, 1], s=s, \n                           c=custom_color,\n                           cmap=cmap, alpha=alpha, **kwargs)\n            # create legend\n            if plot_legend is True:\n                patchList = []\n                for key in list(final_data[column_to_plot].unique()):\n                    data_key = mpatches.Patch(color=all_cat_colormap[key], label=key)\n                    patchList.append(data_key)    \n                    ax.legend(handles=patchList,bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n\n        if title is True: \n            plt.title(column_to_plot, fontsize=fontsize)\n        elif isinstance(title, str):\n            plt.title(title, fontsize=fontsize) \n        if watermark is True:\n            ax.text(1.08, 1.08, \"made with scimap.xyz\",horizontalalignment=\"right\",\n            verticalalignment=\"bottom\", alpha=0.5,fontsize=fontsize * 0.4)\n        plt.tick_params(right= False,top= False,left= False, bottom= False)\n        ax.set(xticklabels = ([])); ax.set(yticklabels = ([]))\n        if tight_layout is True:\n            plt.tight_layout()\n\n\n\n    def animate(i):\n        scat.set_offsets(interpolation[i])\n\n    anim = FuncAnimation(fig, animate, interval=interval, frames=len(interpolation)-1)\n\n\n\n    if save_animation is not None:\n        print ('Saving file- This can take several minutes to hours for large files')\n        anim.save( save_animation + '_scimap.gif', writer='imagemagick', fps=24)\n\n    # save animation\n    #anim.save('/Users/aj/Downloads/filename.mp4')\n\n    return plt.show(anim, block=False)\n</code></pre>"},{"location":"Functions/hl/classify/","title":"classify","text":"<p>Short Description</p> <p><code>sm.hl.classify</code>: Helper function that allow users to annotate cells based on positivity/negativity  of defined markers. Users can classify the entire data or a subset of data that  has been previously phenotyped or clustered.</p>"},{"location":"Functions/hl/classify/#scimap.helpers._classify--function","title":"Function","text":""},{"location":"Functions/hl/classify/#scimap.helpers._classify.classify","title":"<code>classify(adata, pos=None, neg=None, classify_label='passed_classify', phenotype=None, subclassify_phenotype=None, threshold=0.5, collapse_failed=True, label='classify')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData object</p> required <code>pos</code> <p>list, optional Pass a list of markers that should be expressed in the resultant cells.</p> <code>None</code> <code>neg</code> <p>list, optional Pass a list of markers that should not be expressed in the resultant cells.</p> <code>None</code> <code>classify_label</code> <p>string, optional Provide a name for the calssified cells.</p> <code>'passed_classify'</code> <code>subclassify_phenotype</code> <p>list, optional If only a subset of phenotypes require to classified, pass the name of those phenotypes as a list through this argument.</p> <code>None</code> <code>threshold</code> <p>float, optional Above or below the given value will be considered for positive and negative classification. If the data was scaled using the <code>sm.pp.rescale</code> function, 0.5 is the classification threshold.</p> <code>0.5</code> <code>phenotype</code> <p>string, required Column name of the column containing the phenotype information.  This is important if <code>subclassify_phenotype</code> or <code>collapse_failed</code> arguments are used.</p> <code>None</code> <code>collapse_failed</code> <p>bool, optional If set to true, the cells that were not classified based on the given criteria will be binned into a single category named 'failed_classify'. When False, the phenotype inforamation for other cells will be borrowed from the <code>phenotype</code> argument.</p> <code>True</code> <code>label</code> <p>string, optional Key for the returned data, stored in <code>adata.obs</code>.</p> <code>'classify'</code> <pre><code>adata : AnnData  Updated AnnData Object.\n</code></pre> <p>Example: <pre><code>    # Classify all cells with both pos and neg markers \n    # (Identify cytotoxic T-cells)\n    adata = sm.hl.classify(adata, pos=['CD3D','CD8A'], neg=['ASMA'])\n\n    # Classify specific sub-types of cells\n    adata = sm.hl.classify(adata, pos=['CD3D','FOXP3'], \n    neg=['ASMA'], subclassify_phenotype=['T cells','Regulatory T cells'])\n\n    # Classify specific sub-types of cells and borrow labels \n    # from another column\n    adata = sm.hl.classify(adata, pos=['CD3D'], neg=['ASMA'], \n    subclassify_phenotype=['T cells'], collapse_failed=False, \n    phenotype='phenotype')\n</code></pre></p> Source code in <code>scimap/helpers/_classify.py</code> <pre><code>def classify (adata, pos=None, neg=None, classify_label='passed_classify', \n              phenotype=None, subclassify_phenotype=None, threshold = 0.5,\n              collapse_failed=True, label=\"classify\"):\n\"\"\"\nParameters:\n\n    adata : AnnData object\n\n    pos : list, optional  \n        Pass a list of markers that should be expressed in the resultant cells.\n\n    neg : list, optional  \n        Pass a list of markers that should not be expressed in the resultant cells.\n\n    classify_label : string, optional  \n        Provide a name for the calssified cells.\n\n    subclassify_phenotype : list, optional  \n        If only a subset of phenotypes require to classified, pass the name of those phenotypes as a list\n        through this argument.\n\n    threshold: float, optional  \n        Above or below the given value will be considered for positive and negative classification.\n        If the data was scaled using the `sm.pp.rescale` function, 0.5 is the classification threshold.\n\n    phenotype : string, required  \n        Column name of the column containing the phenotype information. \n        This is important if `subclassify_phenotype` or `collapse_failed` arguments are used.\n\n    collapse_failed : bool, optional  \n        If set to true, the cells that were not classified based on the given criteria will be\n        binned into a single category named 'failed_classify'. When False, the phenotype\n        inforamation for other cells will be borrowed from the `phenotype` argument.\n\n    label : string, optional  \n        Key for the returned data, stored in `adata.obs`.\n\n Returns:\n\n    adata : AnnData  \n        Updated AnnData Object.\n\n\nExample:\n```python\n    # Classify all cells with both pos and neg markers \n    # (Identify cytotoxic T-cells)\n    adata = sm.hl.classify(adata, pos=['CD3D','CD8A'], neg=['ASMA'])\n\n    # Classify specific sub-types of cells\n    adata = sm.hl.classify(adata, pos=['CD3D','FOXP3'], \n    neg=['ASMA'], subclassify_phenotype=['T cells','Regulatory T cells'])\n\n    # Classify specific sub-types of cells and borrow labels \n    # from another column\n    adata = sm.hl.classify(adata, pos=['CD3D'], neg=['ASMA'], \n    subclassify_phenotype=['T cells'], collapse_failed=False, \n    phenotype='phenotype')\n```\n    \"\"\"\n\n    # clean the input\n    if isinstance(pos, str):\n        pos = [pos]\n    if isinstance(neg, str):\n        neg = [neg]\n    if isinstance(subclassify_phenotype, str):\n        subclassify_phenotype = [subclassify_phenotype]\n\n\n    # Create a dataFrame with the necessary inforamtion\n    data = pd.DataFrame(adata.X, index= adata.obs.index, columns = adata.var.index)\n\n    # if user requests to subset a specific phenotype   \n    if subclassify_phenotype is not None:\n        meta = pd.DataFrame(adata.obs[phenotype])\n        subset_index = meta[meta[phenotype].isin(subclassify_phenotype)].index\n        data = data.loc[subset_index]\n\n    # Subset cells that pass the pos criteria\n    if pos is not None:\n        for i in pos:\n            # subset data\n            data = data[data[i] &gt;= threshold]\n\n    # Subset cells that pass the neg criteria \n    if neg is not None and not data.empty:\n        for j in neg:\n            # subset data\n            data = data[data[j] &lt; threshold]\n\n    # cells that passed the classify criteria\n    if data.empty:\n        raise TypeError(\"No cells were found to satisfy your `classify` criteria\")\n    else:\n        classify_idx = data.index\n        classified = pd.DataFrame(np.repeat(classify_label, len(classify_idx)), index = classify_idx)\n        classified.columns = [label]\n        #classified = pd.DataFrame(np.repeat(classify_label, len(classify_idx)), index = classify_idx, columns = [phenotype])\n\n\n    if collapse_failed is True:\n        meta = pd.DataFrame(adata.obs.iloc[:, 0])\n        meta = meta.merge(classified, how='outer', left_index=True, right_index=True)\n        meta[label] = meta[label].fillna('failed_classify')\n        meta = meta[label] \n    else:\n        if phenotype is None:\n            raise ValueError(\"Please pass a column name to the PHENOTYPE argument\")\n        meta = pd.DataFrame(adata.obs[phenotype])\n        classified = pd.DataFrame(np.repeat(classify_label, len(classify_idx)), index = classify_idx, columns = [phenotype])\n        meta.update(classified)\n\n    # Add to Anndata\n    meta = meta.reindex(adata.obs.index)\n    adata.obs[label] = meta\n\n    # return\n    return adata\n</code></pre>"},{"location":"Functions/hl/dropFeatures/","title":"dropFeatures","text":"<p>Short Description</p> <p><code>sm.hl.dropFeatures</code>:  A handy function that allows users to susbet the anndata object.  </p> <p>The function can be used to drop markers, cells, columns in metadata, groups of cells  belonging to a certain category. </p>"},{"location":"Functions/hl/dropFeatures/#scimap.helpers._dropFeatures--function","title":"Function","text":""},{"location":"Functions/hl/dropFeatures/#scimap.helpers._dropFeatures.dropFeatures","title":"<code>dropFeatures(adata, drop_markers=None, drop_cells=None, drop_meta_columns=None, drop_groups=None, groups_column=None, subset_raw=True)</code>","text":"<p>Parameters  </p> <pre><code>adata : AnnData Object\n\ndrop_markers : list, optional  Provide a list of markers to drop. The default is None.\n\ndrop_cells : list, optional  Provide a list of cells (index name) to drop. The default is None.\n\ndrop_meta_columns : list, optional  Provide a list of column names in `adata.obs` to drop. The default is None.\n\ndrop_groups : list, optional  Provide a list of categorical names to drop. Works in conjunction with `groups_column`. The default is None.\n\ngroups_column : str, optional  Pass the column name of the column that contains the categories passed to `drop_groups`. The default is None.\n\nsubset_raw : bool, optional  Generally any subsetting of `AnnData` object does not affect the raw data stored in `adata.raw`. Pass `True` to apply the same transformations to `adata.raw` as well. The default is True.\n</code></pre> <p>Returns  </p> <pre><code>adata : Modified `adata` object\n</code></pre> <p>Example</p> <pre><code># Drop certain genes \ndrop_markers = ['ELANE', 'CD57']\nadata = sm.hl.dropFeatures (adata, drop_markers=drop_markers)\n\n# Drop a few cells\ndrop_cells = ['unmicst-exemplar-001_cell_1', 'unmicst-exemplar-001_cell_2','unmicst-exemplar-001_cell_3']\nadata = sm.hl.dropFeatures (adata, drop_cells=drop_cells)\n\n# Drop a few columns from `adata.obs`\ndrop_meta_columns = ['ROI', 'shapes']\nadata = sm.hl.dropFeatures (adata, drop_meta_columns=drop_meta_columns)\n\n# Drop two cell-types from the 'phenotype' column\ndrop_groups = ['Unknown', 'Treg']\nadata = sm.hl.dropFeatures (adata, drop_groups=drop_groups, groups_column = 'phenotype')\n</code></pre> Source code in <code>scimap/helpers/_dropFeatures.py</code> <pre><code>def dropFeatures (adata, drop_markers=None, drop_cells=None, \n                  drop_meta_columns=None,\n                  drop_groups=None, groups_column=None,\n                  subset_raw=True):\n\"\"\"\nParameters  \n\n    adata : AnnData Object  \n\n    drop_markers : list, optional  \n        Provide a list of markers to drop. The default is None.\n\n    drop_cells : list, optional  \n        Provide a list of cells (index name) to drop. The default is None.\n\n    drop_meta_columns : list, optional  \n        Provide a list of column names in `adata.obs` to drop. The default is None.\n\n    drop_groups : list, optional  \n        Provide a list of categorical names to drop. \n        Works in conjunction with `groups_column`. The default is None.\n\n    groups_column : str, optional  \n        Pass the column name of the column that contains the categories passed to \n        `drop_groups`. The default is None.\n\n    subset_raw : bool, optional  \n        Generally any subsetting of `AnnData` object does not affect the raw data \n        stored in `adata.raw`. Pass `True` to apply the same transformations to \n        `adata.raw` as well. The default is True.\n\nReturns  \n\n    adata : Modified `adata` object\n\nExample\n\n```python\n\n# Drop certain genes \ndrop_markers = ['ELANE', 'CD57']\nadata = sm.hl.dropFeatures (adata, drop_markers=drop_markers)\n\n# Drop a few cells\ndrop_cells = ['unmicst-exemplar-001_cell_1', 'unmicst-exemplar-001_cell_2','unmicst-exemplar-001_cell_3']\nadata = sm.hl.dropFeatures (adata, drop_cells=drop_cells)\n\n# Drop a few columns from `adata.obs`\ndrop_meta_columns = ['ROI', 'shapes']\nadata = sm.hl.dropFeatures (adata, drop_meta_columns=drop_meta_columns)\n\n# Drop two cell-types from the 'phenotype' column\ndrop_groups = ['Unknown', 'Treg']\nadata = sm.hl.dropFeatures (adata, drop_groups=drop_groups, groups_column = 'phenotype')\n\n```\n    \"\"\"\n\n    # Drop Markers\n    if drop_markers is not None:\n        if isinstance(drop_markers, str):\n            drop_markers = [drop_markers]\n        # find the index of the given markers\n        idx_markers = [adata.var.index.get_loc(x) for x in drop_markers]\n        # remove from adata\n        keep_markes = list(set(adata.var.index).difference(drop_markers))\n        adata = adata[:, keep_markes]\n        # remove from raw\n        if subset_raw is True:\n            raw = np.delete(adata.raw.X, idx_markers, axis=1)\n            del adata.raw\n            adata.raw = ad.AnnData (raw)\n\n    # Drop cells\n    if drop_cells is not None:\n        if isinstance(drop_cells, str):\n            drop_cells = [drop_cells]\n        # find the index of the given markers\n        idx_markers = [adata.obs.index.get_loc(x) for x in drop_cells]\n        # remove from adata\n        keep_markes = list(set(adata.obs.index).difference(drop_cells))\n        adata = adata[keep_markes, :]\n        # remove from raw\n        if subset_raw is True:\n            raw = np.delete(adata.raw.X, idx_markers, axis=1)\n            del adata.raw\n            adata.raw = ad.AnnData (raw)\n\n    # Drop meta columns\n    if drop_meta_columns is not None:\n        if isinstance(drop_meta_columns, str):\n            drop_meta_columns = [drop_meta_columns]\n        # remove from adata\n        adata.obs = adata.obs.drop(drop_meta_columns, axis=1)\n\n    # Drop specific categories of cells\n    if drop_groups is not None:\n        if isinstance(drop_groups, str):\n            drop_groups = [drop_groups]\n        if isinstance(groups_column, list):\n            groups_column = groups_column[0]\n        # find the index of the given markers\n        idx = adata[adata.obs[groups_column].isin(drop_groups)].obs.index\n        idx_markers = [adata.obs.index.get_loc(x) for x in idx]\n        # remove from raw\n        if subset_raw is True:\n            raw = np.delete(adata.raw.X, idx_markers, axis=0)\n        # remove from adata\n        adata = adata[~adata.obs[groups_column].isin(drop_groups)]\n        # return adata raw\n        if subset_raw is True:\n            del adata.raw\n            adata.raw = ad.AnnData (raw)\n\n\n    # return\n    return adata\n</code></pre>"},{"location":"Functions/hl/rename/","title":"rename","text":"<p>Short Description</p> <p><code>sm.hl.rename</code>: The function allows users to rename any string within a column to another and saved in a new column.</p>"},{"location":"Functions/hl/rename/#scimap.helpers._rename--function","title":"Function","text":""},{"location":"Functions/hl/rename/#scimap.helpers._rename.rename","title":"<code>rename(adata, rename, from_column='phenotype', to_column='phenotype_renamed')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData object</p> required <code>rename</code> <p>dict Pass a dictionary with 'values' as elements that need to be altered and  'keys' as the elements that they need to be transformed into.</p> required <code>from_column</code> <p>string, required Column that need to be modified.</p> <code>'phenotype'</code> <code>to_column</code> <p>string, required Modified names will be stored in a new column with this name.</p> <code>'phenotype_renamed'</code> <p>Returns:</p> Name Type Description <code>adata</code> <p>Modified AnnData Object  </p> <pre><code>    rename= {'tumor': ['cd45 neg tumor', 'cd8 tumor', 'cd4 tumor'],\n             'macrophages': ['m1 macrophages', 'm2 macrophages']}\n    Here we are renaming cd45 neg tumor, cd8 tumor and cd4 tumor into 'tumor' and \n    m1 macrophages and m2 macrophages into macrophages\n\n    adata = sm.hl.rename_clusters (adata, rename, from_column='phenotype', \n                                    to_column='phenotype_renamed')\n</code></pre> Source code in <code>scimap/helpers/_rename.py</code> <pre><code>def rename (adata, rename, from_column='phenotype', to_column='phenotype_renamed'):\n\"\"\"\nParameters:\n\n    adata : AnnData object\n\n    rename : dict  \n        Pass a dictionary with 'values' as elements that need to be altered and \n        'keys' as the elements that they need to be transformed into.\n\n    from_column : string, required  \n        Column that need to be modified.\n\n    to_column : string, required  \n        Modified names will be stored in a new column with this name.\n\nReturns:\n    adata : Modified AnnData Object  \n\nExample:\n```python\n\n    rename= {'tumor': ['cd45 neg tumor', 'cd8 tumor', 'cd4 tumor'],\n             'macrophages': ['m1 macrophages', 'm2 macrophages']}\n    Here we are renaming cd45 neg tumor, cd8 tumor and cd4 tumor into 'tumor' and \n    m1 macrophages and m2 macrophages into macrophages\n\n    adata = sm.hl.rename_clusters (adata, rename, from_column='phenotype', \n                                    to_column='phenotype_renamed')\n```\n    \"\"\"\n\n    # Sanity check: if the values are not list convert them into list\n    for i in rename:\n        if isinstance(rename[i], str):\n            rename[i] = [rename[i]]\n\n    # Get the from_column\n    rename_from = list(adata.obs[from_column].values)\n\n    # Split multiple renaming events into independent events\n    name = functools.reduce( lambda x,y: dict(x, **y), (dict(map(lambda x: (x,i), rename[i])) for i in rename))\n\n    # Rename\n    for i in name:\n        print ('Renaming ' + str(i) + ' to ' + str(name[i]))\n        #rename_from = [x.replace(i, name[i]) for x in rename_from]\n        s = str(i)\n        s = s.replace('+', '\\+')\n        #rename_from = [re.sub(r'^\\b%s\\b$' % s,  name[i], j) for j in rename_from]\n        rename_from = [re.sub(r'^\\b%s$' % s,  name[i], j) for j in rename_from]\n\n\n    # Append to adata as a new column\n    adata.obs[to_column] = rename_from\n\n    # Return\n    return adata\n</code></pre>"},{"location":"Functions/hl/scimap_to_csv/","title":"scimap_to_csv","text":"<p>Short Description</p> <p><code>sm.hl.scimap_to_csv</code>:  Helper function that allows users to save the contents of the <code>scimap</code> object as a csv file. Please not that anything that it only saves elements that are within <code>adata.X or adata.raw.X</code> and <code>adata.obs</code>.</p>"},{"location":"Functions/hl/scimap_to_csv/#scimap.helpers._scimap_to_csv--function","title":"Function","text":""},{"location":"Functions/hl/scimap_to_csv/#scimap.helpers._scimap_to_csv.scimap_to_csv","title":"<code>scimap_to_csv(adata, data_type='raw', output_dir=None, file_name=None, CellID='CellID')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData object loaded into memory or path to AnnData object.</p> required <code>data_type</code> <p>string, optional Three options are available: 1) 'raw' - The raw data will be returned. 2) 'log' - The raw data converted to log scale using <code>np.log1p</code> will be returned. 3) 'scaled' - If you have scaled the data using the <code>sm.pp.rescale</code>, that will be returned. Please note, if you have not scaled the data, whatever is within <code>adata.X</code> will be returned.</p> <code>'raw'</code> <code>output_dir</code> <p>string, optional Path to output directory.</p> <code>None</code> <code>file_name</code> <p>string, optional Name the output csv file. Use in combination with <code>output_dir</code> parameter. If no file name is provided a default name <code>scimap_to_csv_file.csv</code> will be used. </p> <code>None</code> <code>CellID</code> <p>string, optional Name of the column which contains the CellID. Default is <code>CellID</code>.  </p> <code>'CellID'</code> <p>Returns:</p> Name Type Description <code>merged</code> <p>DataFrame A single dataframe containing the expression and metadata will be returned.</p> <pre><code>    data = sm.hl.scimap_to_csv (adata, data_type='raw')\n</code></pre> Source code in <code>scimap/helpers/_scimap_to_csv.py</code> <pre><code>def scimap_to_csv (adata, data_type='raw', output_dir=None, file_name=None, CellID='CellID'):\n\"\"\"\nParameters:\n    adata : AnnData object loaded into memory or path to AnnData object.\n\n    data_type : string, optional  \n        Three options are available:  \n        1) 'raw' - The raw data will be returned.  \n        2) 'log' - The raw data converted to log scale using `np.log1p` will be returned.  \n        3) 'scaled' - If you have scaled the data using the `sm.pp.rescale`, that will be\n        returned. Please note, if you have not scaled the data, whatever is within\n        `adata.X` will be returned.\n\n    output_dir : string, optional  \n        Path to output directory.\n\n    file_name : string, optional\n        Name the output csv file. Use in combination with `output_dir` parameter. If no\n        file name is provided a default name `scimap_to_csv_file.csv` will be used. \n\n    CellID : string, optional  \n        Name of the column which contains the CellID. Default is `CellID`.  \n\nReturns:\n    merged : DataFrame  \n        A single dataframe containing the expression and metadata will be returned.\n\nExample:\n```python\n    data = sm.hl.scimap_to_csv (adata, data_type='raw')\n```\n    \"\"\"\n\n    # Load the andata object    \n    if isinstance(adata, str):\n        if file_name is None:\n            imid = str(adata.rsplit('/', 1)[-1])\n        else: \n            imid = str(file_name)\n        adata = ad.read(adata)\n    else:\n        if file_name is None:\n            imid = \"scimap_to_csv_file.csv\"\n        else: \n            imid = str(file_name)\n        adata = adata\n\n    # Expression matrix\n    if data_type == 'raw':\n        data = pd.DataFrame(adata.raw.X, index=adata.obs.index, columns=adata.var.index)\n    if data_type == 'log':\n        data = pd.DataFrame(np.log1p(adata.raw.X), index=adata.obs.index, columns=adata.var.index)\n    if data_type == 'scaled':\n        data = pd.DataFrame(adata.X, index=adata.obs.index, columns=adata.var.index)\n\n    # Metadata\n    meta = pd.DataFrame(adata.obs)\n\n    # Merge the two dataframes\n    merged = pd.concat([data, meta], axis=1, sort=False)\n\n    # Add a column to save cell-id\n    #merged['CellID'] = merged.index\n    # make cellID the first column\n    if CellID in merged.columns:\n        first_column = merged.pop(CellID)\n        merged.insert(0, CellID, first_column)\n    else:\n        merged['CellID'] = merged.index\n        first_column = merged.pop(CellID)\n        merged.insert(0, CellID, first_column)\n\n    # reset index\n    merged = merged.reset_index(drop=True)\n\n    # Save data if requested\n    if output_dir is not None:\n        output_dir = pathlib.Path(output_dir)\n        output_dir.mkdir(exist_ok=True, parents=True)\n        merged.to_csv(output_dir / f'{imid}.csv', index=False)\n    else:    \n        # Return data\n        return merged\n</code></pre>"},{"location":"Functions/pl/addROI_image/","title":"addROI_image","text":"<p>Short Description</p> <p><code>sm.pl.addROI_image</code>: The function allows users to add ROIs to the data.  The function opens the image in a <code>napari</code> viewer and allows users to use the  shapes layer to add ROIs.   </p> <p>If the user is interesed in adding different ROI's (e.g. Tumor, Stroma, Tumor-Stromal-interface),  each of these should be drawn in a seperate <code>shape layer</code>. </p> <p>Please note that a single <code>shape layer</code> can contain multiple seperate annotated regions.  All annotated regions within a single shape layer will be pooled into a single ROI. </p> <p>The <code>shape layers</code> can be renamed to users choice of ROI name.  </p> <p>Please note: All ROI's have to be unique and cannot overlap.  </p> <p>This function could also be used as a QC step to annotate regions of poor/ good quality  and later subsetted (keep or remove) for further analysis. </p>"},{"location":"Functions/pl/addROI_image/#scimap.plotting._addROI_image--function","title":"Function","text":""},{"location":"Functions/pl/addROI_image/#scimap.plotting._addROI_image.addROI_image","title":"<code>addROI_image(image_path, adata, subset=None, imageid='imageid', overlay=None, flip_y=True, overlay_category=None, markers=None, channel_names='default', x_coordinate='X_centroid', y_coordinate='Y_centroid', point_size=10, point_color=None, seg_mask=None, n_jobs=-1, verbose=False, overwrite=True, label='ROI', **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>image_path</code> <p>string Location to the image file (TIFF, OME.TIFF, ZARR supported)  </p> required <code>adata</code> <p>AnnData Object  </p> required <code>subset</code> <p>list, optional Name of the image to which the ROI is to be added. Note if you have multiple images in the  adata object, you will need to add ROI's to each image one after the other independently.  </p> <code>None</code> <code>imageid</code> <p>string, optional In the event that the adata object contains multiple images, it is important that ROIs are added to each image seperately. Pass the name  of the column that contains the <code>imageid</code> and use it in conjunction with the <code>subset</code> parameter to add ROI's to a specific image.</p> <code>'imageid'</code> <code>seg_mask</code> <p>string Location to the segmentation mask file.  </p> <code>None</code> <code>overlay</code> <p>string, optional Name of the column with any categorical data such as phenotypes or clusters.</p> <code>None</code> <code>flip_y</code> <p>bool, optional Flip the Y-axis if needed. Some algorithms output the XY with the Y-coordinates flipped. If the image overlays do not align to the cells, try again by setting this to <code>False</code>.</p> <code>True</code> <code>overlay_category</code> <p>list, optional If only specfic categories within the overlay column is needed, pass their names as a list. If None, all categories will be used.</p> <code>None</code> <code>markers</code> <p>list, optional Markers to be included. If none, all markers will be displayed.</p> <code>None</code> <code>channel_names</code> <p>list, optional List of channels in the image in the exact order as image. The default is <code>adata.uns['all_markers']</code></p> <code>'default'</code> <code>x_coordinate</code> <p>string, optional X axis coordinate column name in AnnData object.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <p>string, optional Y axis coordinate column name in AnnData object.</p> <code>'Y_centroid'</code> <code>point_size</code> <p>int, optional point size in the napari plot.</p> <code>10</code> <code>overwrite</code> <p>bool, optional In the event you have multiple images in the adata object, ROI can be added to each image independently using the <code>imageid</code> and <code>subset</code> parameter. If you wish the results to be all saved with in the same column set this parameter to <code>False</code>. By default, the  function will overwrite the <code>label</code> column. </p> <code>True</code> <code>n_jobs</code> <p>int, optional Number of cores to use. Default is to use all available cores.  </p> <code>-1</code> <code>label</code> <p>string, optional Key for the returned data, stored in <code>adata.obs</code>.  </p> <code>'ROI'</code> <p>Returns:</p> Type Description <p>Modified Anndata object.</p> <pre><code>    image_path = '/Users/aj/Desktop/ptcl_tma/image.ome.tif'\n    adata = sm.pl.addROI_image (image_path, adata, label=\"Tumor Regions\")\n</code></pre> Source code in <code>scimap/plotting/_addROI_image.py</code> <pre><code>def addROI_image (image_path, adata, subset=None,imageid='imageid', overlay=None, flip_y=True,\n                    overlay_category=None,markers=None,channel_names='default',\n                    x_coordinate='X_centroid',y_coordinate='Y_centroid',point_size=10,\n                    point_color=None,seg_mask=None,\n                    n_jobs=-1, verbose=False, \n                    overwrite=True, label='ROI', **kwargs):\n\"\"\"\nParameters:\n    image_path : string  \n        Location to the image file (TIFF, OME.TIFF, ZARR supported)  \n\n    adata : AnnData Object  \n\n    subset : list, optional  \n        Name of the image to which the ROI is to be added. Note if you have multiple images in the \n        adata object, you will need to add ROI's to each image one after the other independently.  \n\n    imageid : string, optional  \n        In the event that the adata object contains multiple images, it is\n        important that ROIs are added to each image seperately. Pass the name \n        of the column that contains the `imageid` and use it in conjunction with\n        the `subset` parameter to add ROI's to a specific image.\n\n    seg_mask: string  \n        Location to the segmentation mask file.  \n\n    overlay : string, optional  \n        Name of the column with any categorical data such as phenotypes or clusters.\n\n    flip_y : bool, optional  \n        Flip the Y-axis if needed. Some algorithms output the XY with the Y-coordinates flipped.\n        If the image overlays do not align to the cells, try again by setting this to `False`.\n\n    overlay_category : list, optional  \n        If only specfic categories within the overlay column is needed, pass their names as a list.\n        If None, all categories will be used.\n\n    markers : list, optional  \n        Markers to be included. If none, all markers will be displayed.\n\n    channel_names : list, optional  \n        List of channels in the image in the exact order as image. The default is `adata.uns['all_markers']`\n\n    x_coordinate : string, optional  \n        X axis coordinate column name in AnnData object.\n\n    y_coordinate : string, optional  \n        Y axis coordinate column name in AnnData object.\n\n    point_size : int, optional  \n        point size in the napari plot.\n\n    overwrite : bool, optional  \n        In the event you have multiple images in the adata object, ROI can be added to each image\n        independently using the `imageid` and `subset` parameter. If you wish the results to be\n        all saved with in the same column set this parameter to `False`. By default, the \n        function will overwrite the `label` column. \n\n    n_jobs : int, optional  \n        Number of cores to use. Default is to use all available cores.  \n\n    label : string, optional  \n        Key for the returned data, stored in `adata.obs`.  \n\n    **kwargs  \n        Other arguments that can be passed to napari viewer\n\nReturns:\n    Modified Anndata object.\n\nExample:\n```python\n    image_path = '/Users/aj/Desktop/ptcl_tma/image.ome.tif'\n    adata = sm.pl.addROI_image (image_path, adata, label=\"Tumor Regions\")\n```\n    \"\"\"\n\n    #TODO\n    # - ADD Subset markers for ZARR ssection\n    # - Ability to use ZARR metadata if available\n\n    # create data matrix that has the co-ordinates\n    data = pd.DataFrame(adata.obs)[[x_coordinate, y_coordinate, imageid]]\n\n    # subset the data if needed\n    if subset is not None:\n        # convert string to list\n        if isinstance(subset, str): \n            subset = [subset]\n        # subset data\n        sub_data = data[data['imageid'].isin(subset)]\n    else:\n        sub_data = data\n\n\n    # adding option to load just the image without an adata object\n    if adata is None:\n        channel_names = None\n    else: \n        # All operations on the AnnData object is performed first\n        # Plot only the Image that is requested\n        if subset is not None:\n            adata_subset = adata[adata.obs[imageid].isin(subset)]\n        else:\n            adata_subset = adata.copy()\n\n        # Recover the channel names from adata\n        if channel_names == 'default':\n            channel_names = adata_subset.uns['all_markers']\n        else:\n            channel_names = channel_names\n\n        # Index of the marker of interest and corresponding names\n        if markers is None:\n            idx = list(range(len(channel_names)))\n            channel_names = channel_names\n        else:\n            idx = []\n            for i in markers:\n                idx.append(list(channel_names).index(i))\n            channel_names = markers\n\n\n        # Load the segmentation mask\n        if seg_mask is not None:\n            seg_m = tiff.imread(seg_mask)\n            if (len(seg_m.shape) &gt; 2) and (seg_m.shape[0] &gt; 1):\n                seg_m = seg_m[0]    \n\n    # Operations on the OME TIFF image is performed next\n    # check the format of image\n    if os.path.isfile(image_path) is True:  \n        image = tiff.TiffFile(image_path, is_ome=False) #is_ome=False\n        z = zarr.open(image.aszarr(), mode='r') # convert image to Zarr array\n        # Identify the number of pyramids\n        n_levels = len(image.series[0].levels) # pyramid\n\n        # If and if not pyramids are available\n        if n_levels &gt; 1:\n            pyramid = [da.from_zarr(z[i]) for i in range(n_levels)]\n            multiscale = True\n        else:\n            pyramid = da.from_zarr(z)\n            multiscale = False  \n\n        # subset channels of interest\n        if markers is not None:\n            if n_levels &gt; 1:\n                for i in range(n_levels-1):\n                    pyramid[i] = pyramid[i][idx, :, :]\n                n_channels = pyramid[0].shape[0] # identify the number of channels\n            else:\n                pyramid = pyramid[idx, :, :]\n                n_channels = pyramid.shape[0] # identify the number of channels\n        else:\n            if n_levels &gt; 1:\n                n_channels = pyramid[0].shape[0]\n            else:\n                n_channels = pyramid.shape[0]\n\n        # check if channel names have been passed to all channels\n        if channel_names is not None:\n            assert n_channels == len(channel_names), (\n                f'number of channel names ({len(channel_names)}) must '\n                f'match number of channels ({n_channels})'\n            )\n\n        # Load the viewer\n        viewer = napari.view_image(\n            pyramid, multiscale=multiscale, channel_axis=0,\n            visible=False, \n            name = None if channel_names is None else channel_names,\n            **kwargs\n        )\n\n    # Operations on the ZARR image\n    # check the format of image\n    if os.path.isfile(image_path) is False: \n        #print(image_path)\n        viewer = napari.Viewer()\n        viewer.open(image_path, multiscale=True,\n                    visible=False,\n                    name = None if channel_names is None else channel_names)\n\n    # Add the seg mask\n    if seg_mask is not None:\n        viewer.add_labels(seg_m, name='segmentation mask', visible=False)\n\n    # Add phenotype layer function\n    def add_phenotype_layer (adata, overlay, phenotype_layer,x,y,viewer,point_size,point_color):\n        coordinates = adata[adata.obs[overlay] == phenotype_layer]\n        # Flip Y AXIS if needed\n        if flip_y is True:\n            coordinates = pd.DataFrame({'y': coordinates.obs[y],'x': coordinates.obs[x]})\n        else:  \n            coordinates = pd.DataFrame({'x': coordinates.obs[x],'y': coordinates.obs[y]})\n\n        #points = coordinates.values.tolist()\n        points = coordinates.values\n        if point_color is None:\n            r = lambda: random.randint(0,255) # random color generator\n            point_color = '#%02X%02X%02X' % (r(),r(),r()) # random color generator\n        viewer.add_points(points, size=point_size,face_color=point_color,visible=False,name=phenotype_layer)\n\n    if overlay is not None:\n        # categories under investigation\n        if overlay_category is None:\n            available_phenotypes = list(adata_subset.obs[overlay].unique())\n        else:\n            available_phenotypes = overlay_category\n\n        # Run the function on all phenotypes\n        for i in available_phenotypes:\n            add_phenotype_layer (adata=adata_subset, overlay=overlay,\n                                    phenotype_layer=i, x=x_coordinate, y=y_coordinate, viewer=viewer,\n                                    point_size=point_size,point_color=point_color)\n\n    # Intiate an ROI layer\n    shape_layer = viewer.add_shapes(name=label)\n    shape_layer.mode = 'add_polygon'\n    #_ = show_info('Draw ROIs')\n\n\n    # helper functions\n    def ellipse_points_to_patch(vertex_1, vertex_2,co_vertex_1, co_vertex_2):\n\n\"\"\"\n        Parameters\n        ----------\n        vertex_1, vertex_2, co_vertex_1, co_vertex_2: array like, in the form of (x-coordinate, y-coordinate)\n        \"\"\"\n        v_and_co_v = np.array([\n            vertex_1, vertex_2,\n            co_vertex_1, co_vertex_2\n        ])\n        centers = v_and_co_v.mean(axis=0)\n\n        d = sdistance.cdist(v_and_co_v, v_and_co_v, metric='euclidean')\n        width = d[0, 1]\n        height = d[2, 3]\n\n        vector_2 = v_and_co_v[1] - v_and_co_v[0]\n        vector_2 /= np.linalg.norm(vector_2)\n\n        angle = np.degrees(np.arccos([1, 0] @ vector_2))\n\n        ellipse_patch = mpatches.Ellipse(\n            centers, width=width, height=height, angle=angle\n        )\n        return ellipse_patch\n\n    # block the viewer until ROI is added\n    a = \"\"\"\n        Opening Napari;\n        Add shape layers (on left) to draw ROI's. \n        Rename the shape layer to give a name to your ROI\n        Multiple shape layers are supported\n        ROI's should not overlap\n        Close Napari to save ROI's.\n        \"\"\"\n    print(a)\n    viewer.show(block=True)    \n\n\n    # Find all the shape layers\n    my_shapes = [layer for layer in viewer.layers if isinstance(layer, Shapes)]\n    # loop through the layers to find their names\n    shape_names = []\n    added_rois = []\n    for i in my_shapes:\n        shape_names.append(i.name)\n        added_rois.append(len(viewer.layers[i.name].data))\n\n    if any(y &gt; 0 for y in added_rois):\n        # Loop through all the Shape layers and extract the vertices and shape type\n        all_rois = pd.DataFrame()\n        for i in shape_names:\n            # return shape vertices\n            ver = viewer.layers[i].data\n            # return shape shape\n            structure = viewer.layers[i].shape_type\n            # Each layer may contain multiple ROI's with different shapes (handle that)\n            napari_roi_table = pd.DataFrame(dict(vertices=[np.fliplr(v) for v in ver], type=[str(s) for s in structure], ROI=i))\n\n            # convert gathered ROIs into mpatches\n            for i in range(len(napari_roi_table.index)):\n                # ellipse\n                if napari_roi_table['type'][i] == 'ellipse':\n                    napari_roi_table.loc[i:, 'mpatch'] = ellipse_points_to_patch(napari_roi_table['vertices'][i][0],\n                                                                                napari_roi_table['vertices'][i][1],\n                                                                                napari_roi_table['vertices'][i][2],\n                                                                                napari_roi_table['vertices'][i][3])\n                # polygon, rectangle, line\n                elif napari_roi_table['type'][i] in ['rectangle', 'polygon', 'path']:\n                    napari_roi_table.loc[i:, 'mpatch'] = mpatches.Polygon(napari_roi_table['vertices'][i], closed=True)\n                else:\n                    raise ValueError\n\n            # merge the final ROI's across all shape layers\n            all_rois = pd.concat ([all_rois, napari_roi_table])\n            all_rois['id'] = range(all_rois.shape[0])\n            all_rois.index = all_rois['id']\n\n        # Find cells within ROI and add it to the dataframe\n        def add_roi_internal (roi_id):\n            roi_mpatch = all_rois[all_rois['id'] == roi_id]['mpatch'][roi_id]\n            inside = sub_data[roi_mpatch.contains_points(sub_data[[x_coordinate, y_coordinate]])]\n            inside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n            # return\n            return inside\n\n        print(\"Identifying cells within selected ROI's\")\n        # all ROI cells\n        roi_list = all_rois['id'].unique()\n        #final_roi = list()\n        #for i in roi_list: \n        #    roi_mpatch = all_rois[all_rois['id'] == i]['mpatch'][i]\n        #    inside = sub_data[roi_mpatch.contains_points(sub_data[[x_coordinate, y_coordinate]])]\n        #    inside['ROI_internal'] = all_rois[all_rois['id'] == i]['ROI'][i]\n        #    final_roi.append(inside)\n\n        final_roi = Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(add_roi_internal)(roi_id=i) for i in roi_list)  \n\n        # Merge all into a single DF\n        final_roi = pd.concat(final_roi)[['ROI_internal']]\n\n        # Add the list to obs\n        result = pd.merge(data, final_roi, left_index=True, right_index=True, how='outer')\n\n        # Reindex\n        result = result.reindex(adata.obs.index)\n\n        # check if adata already has a column with the supplied label\n        # if avaialble overwrite or append depending on users choice\n        if label in adata.obs.columns:\n            if overwrite is False:\n                # Append\n                # retreive the ROI information\n                old_roi = adata.obs[label]\n                combined_roi = pd.merge(result, old_roi, left_index=True, right_index=True, how='outer')\n                combined_roi['ROI_internal'] = combined_roi['ROI_internal'].fillna(combined_roi[label])\n            else:\n                # Over write\n                combined_roi = result.copy()\n                combined_roi['ROI_internal'] = combined_roi['ROI_internal'].fillna('Other')     \n        else:\n            # if label is not present just create a new one\n            combined_roi = result.copy()\n            combined_roi['ROI_internal'] = combined_roi['ROI_internal'].fillna('Other')     \n\n        # Add to adata\n        adata.obs[label] = combined_roi['ROI_internal']    \n\n        # return\n        return adata\n</code></pre>"},{"location":"Functions/pl/cluster_plots/","title":"cluster_plots","text":"<p>Short Description</p> <p><code>sm.pl.cluster_plots</code>: A quick meta function that outputs umap plots, heatmap of the expression matrix and ranked makers for each group provided by the user (generally run after using the <code>sm.tl.cluster</code> function)</p>"},{"location":"Functions/pl/cluster_plots/#scimap.plotting._cluster_plots--function","title":"Function","text":""},{"location":"Functions/pl/cluster_plots/#scimap.plotting._cluster_plots.cluster_plots","title":"<code>cluster_plots(adata, group_by, subsample=100000, palette='viridis', use_raw=False, size=None, output_dir=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData object loaded into memory or path to AnnData object.</p> required <code>group_by</code> <p>string, required   Name of the categorical column that contains the clustering results.</p> required <code>subsample</code> <p>string, optional Subsample number of observations.</p> <code>100000</code> <code>palette</code> <p>string, optional Colors to use for plotting categorical annotation groups.</p> <code>'viridis'</code> <code>size</code> <p>string, optional Point size of UMAP plot.</p> <code>None</code> <code>use_raw</code> <p>string, optional Use <code>.raw</code> attribute of adata for coloring the matrixplot expression matrix.</p> <code>False</code> <code>output_dir</code> <p>string, optional Path to output directory.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>plots</code> <p>UMAP, matrixplot and ranked makers per group.</p> <pre><code>    sm.pl.cluster_plots (adata, group_by='spatial_kmeans')\n</code></pre> Source code in <code>scimap/plotting/_cluster_plots.py</code> <pre><code>def cluster_plots (adata, group_by, subsample=100000, palette ='viridis', \n                   use_raw=False,\n                   size=None, output_dir=None):\n\"\"\"\nParameters:\n    adata : AnnData object loaded into memory or path to AnnData object.\n\n    group_by : string, required    \n        Name of the categorical column that contains the clustering results.\n\n    subsample : string, optional  \n        Subsample number of observations.\n\n    palette : string, optional  \n        Colors to use for plotting categorical annotation groups.\n\n    size : string, optional  \n        Point size of UMAP plot.\n\n    use_raw : string, optional  \n        Use `.raw` attribute of adata for coloring the matrixplot expression matrix.\n\n    output_dir : string, optional  \n        Path to output directory.\n\nReturns:\n    plots :   \n        UMAP, matrixplot and ranked makers per group.\n\nExample:\n```python\n    sm.pl.cluster_plots (adata, group_by='spatial_kmeans')\n```\n    \"\"\"\n\n    # Load the data \n    if isinstance(adata, str):\n        imid = pathlib.Path(adata).stem\n        adata = ad.read(adata)  \n    else:\n        adata = adata\n        imid = \"\"\n\n    # Subset data if needed\n    if subsample is not None:\n        if adata.shape[0] &gt; subsample:\n            sc.pp.subsample(adata, n_obs=subsample)\n\n\n    # UMAP\n    try:\n        sc.pp.neighbors(adata) # Computing the neighborhood graph\n        sc.tl.umap(adata)\n        fig = sc.pl.umap(adata, color=group_by, palette = palette, size=size, return_fig=True, show=False) # View the clustering\n        fig.tight_layout()\n        # save figure\n        if output_dir is not None:\n            output_dir = pathlib.Path(output_dir)\n            output_dir.mkdir(exist_ok=True, parents=True)\n            #fig.savefig(output_dir / f\"{imid}_umap.pdf\")\n            fig.savefig(pathlib.Path(output_dir) / f\"{imid}_umap.pdf\")\n\n    except Exception as exc:\n        print('UMAP could not be generated')\n        print (exc)\n\n    # Matrix plot\n    try:\n        mat_fig = sc.pl.matrixplot(adata, var_names=adata.var.index, groupby=group_by, use_raw=use_raw,\n                         cmap='RdBu_r', dendrogram=True, title = group_by,\n                         return_fig=True\n                         )\n        if output_dir is not None:\n            #mat_fig.savefig(output_dir / 'matrixplot.pdf')\n            mat_fig.savefig(pathlib.Path(output_dir) / f\"{imid}_matrixplot.pdf\")\n\n    except Exception as exc:\n        print('Heatmap could not be generated')\n        print (exc)\n\n    # Marker expression per group\n    try:\n        sc.tl.rank_genes_groups(adata, group_by, method='t-test')\n\n        # find number of genes in dataset\n        if len(adata.var.index) &gt; 20:\n            n_genes = 20\n        else:\n            n_genes = len(adata.var.index)\n\n        if output_dir is not None:\n            sc.pl.rank_genes_groups(adata, sharey=False, n_genes=n_genes, fontsize=12, show=False)\n            plt.suptitle(group_by, fontsize=20)\n            #plt.savefig(output_dir / 'ranked_markers_per_cluster.pdf')\n            plt.savefig(pathlib.Path(output_dir) / f\"{imid}_ranked_markers_per_cluster.pdf\")\n        else:\n            sc.pl.rank_genes_groups(adata, sharey=False, n_genes=n_genes, fontsize=12)\n\n    except Exception as exc:\n        print('Finding differential markers per group cannot be completed')\n        print (exc)\n</code></pre>"},{"location":"Functions/pl/densityPlot2D/","title":"densityPlot2D","text":"<p>Short Description</p> <p>The <code>sm.pl.densityPlot2D</code> function generates a 2D density plot of the expression  of one or more specified markers. The function can be called with one or two  marker names to generate a 2D density plot of expression of the first  marker against the second marker or against all other markers in the dataset.</p>"},{"location":"Functions/pl/densityPlot2D/#scimap.plotting.densityPlot2D--function","title":"Function","text":""},{"location":"Functions/pl/densityPlot2D/#scimap.plotting.densityPlot2D.densityPlot2D","title":"<code>densityPlot2D(adata, markerA, markerB=None, layer=None, subset=None, imageid='imageid', ncols=None, cmap='jet', figsize=(3, 3), hline='auto', vline='auto', fontsize=None, dpi=100, xticks=None, yticks=None, outputDir=None, outputFileName='densityPlot2D.pdf')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>anndata</code> <p>Annotated data matrix containing single-cell gene expression data.</p> required <code>markerA</code> <code>str</code> <p>The name of the first marker whose expression will be plotted.</p> required <code>markerB</code> <code>list</code> <p>The name of the second marker or a list of second markers whose expression will be plotted.  If not provided, a 2D density plot of <code>markerA</code> against all markers in the dataset will be plotted.</p> <code>None</code> <code>layer</code> <code>str or list of str</code> <p>The layer in adata.layers that contains the expression data to use.  If None, adata.X is used. use <code>raw</code> to use the data stored in <code>adata.raw.X</code></p> <code>None</code> <code>subset</code> <code>list</code> <p><code>imageid</code> of a single or multiple images to be subsetted for plotting purposes.</p> <code>None</code> <code>imageid</code> <code>str</code> <p>Column name of the column containing the image id. Use in conjunction with <code>subset</code>.</p> <code>'imageid'</code> <code>ncols</code> <code>int</code> <p>The number of columns in the grid of density plots.</p> <code>None</code> <code>cmap</code> <code>str</code> <p>The name of the colormap to use. Defaults to 'jet'.</p> <code>'jet'</code> <code>figsize</code> <code>tuple</code> <p>The size of the figure in inches.</p> <code>(3, 3)</code> <code>hline</code> <code>float or 'auto'</code> <p>The y-coordinate of the horizontal line to plot. If set to <code>None</code>, a horizontal line is not plotted.  Use 'auto' to draw a vline at the center point. </p> <code>'auto'</code> <code>vline</code> <code>float or 'auto'</code> <p>The x-coordinate of the vertical line to plot. If set to <code>None</code>, a vertical line is not plotted.  Use 'auto' to draw a vline at the center point. </p> <code>'auto'</code> <code>fontsize</code> <code>int</code> <p>The size of the font of the axis labels.</p> <code>None</code> <code>dpi</code> <code>int</code> <p>The DPI of the figure. Use this to control the point size. Lower the dpi, larger the point size.</p> <code>100</code> <code>xticks</code> <code>list of float</code> <p>Custom x-axis tick values.</p> <code>None</code> <code>yticks</code> <code>list of float</code> <p>Custom y-axis tick values.</p> <code>None</code> <code>outputDir</code> <code>str</code> <p>The directory to save the output plot.</p> <code>None</code> <code>outputFileName</code> <code>str</code> <p>The name of the output file. Use desired file format as suffix (e.g. <code>.png</code> or <code>.pdf</code>).</p> <code>'densityPlot2D.pdf'</code> <p>Returns:</p> Name Type Description <code>Plot</code> <code>image</code> <p>If <code>outputDir</code> is not provided, the plot is displayed on the screen.  Otherwise, the plot is saved in the provided <code>outputDir</code> directory.</p> Example <pre><code># create a 2D density plot of the expression of 'CD3D' against 'CD8A' in the dataset 'adata'\ndensityPlot2D(adata, markerA='CD3D', markerB='CD8A')\n\n# create a 2D density plot of the expression of 'CD3D' against all markers in the dataset 'adata'\ndensityPlot2D(adata, markerA='CD3D')\n</code></pre> Source code in <code>scimap/plotting/densityPlot2D.py</code> <pre><code>def densityPlot2D (adata, \n                   markerA,  markerB=None, \n                   layer=None, \n                   subset=None, \n                   imageid='imageid', \n                   ncols=None, \n                   cmap='jet', \n                   figsize=(3, 3), \n                   hline = 'auto', vline = 'auto',\n                   fontsize=None, \n                   dpi=100, \n                   xticks=None,\n                   yticks=None,\n                   outputDir=None, \n                   outputFileName='densityPlot2D.pdf'):\n\n\"\"\"\nParameters:\n    adata (anndata): \n        Annotated data matrix containing single-cell gene expression data.\n\n    markerA (str): \n        The name of the first marker whose expression will be plotted.\n\n    markerB (list, optional): \n        The name of the second marker or a list of second markers whose expression will be plotted. \n        If not provided, a 2D density plot of `markerA` against all markers in the dataset will be plotted.\n\n    layer (str or list of str, optional): \n        The layer in adata.layers that contains the expression data to use. \n        If None, adata.X is used. use `raw` to use the data stored in `adata.raw.X`\n\n    subset (list, optional):  \n        `imageid` of a single or multiple images to be subsetted for plotting purposes.\n\n    imageid (str, optional):  \n        Column name of the column containing the image id. Use in conjunction with `subset`.\n\n    ncols (int, optional):  \n        The number of columns in the grid of density plots.\n\n    cmap (str, optional):  \n        The name of the colormap to use. Defaults to 'jet'.\n\n    figsize (tuple, optional):  \n        The size of the figure in inches.\n\n    hline (float or 'auto', optional):  \n        The y-coordinate of the horizontal line to plot. If set to `None`, a horizontal line is not plotted. \n        Use 'auto' to draw a vline at the center point. \n\n    vline (float or 'auto', optional):  \n        The x-coordinate of the vertical line to plot. If set to `None`, a vertical line is not plotted. \n        Use 'auto' to draw a vline at the center point. \n\n    fontsize (int, optional):  \n        The size of the font of the axis labels.\n\n    dpi (int, optional):  \n        The DPI of the figure. Use this to control the point size. Lower the dpi, larger the point size.\n\n    xticks (list of float, optional):  \n        Custom x-axis tick values.\n\n    yticks (list of float, optional):  \n        Custom y-axis tick values.\n\n    outputDir (str, optional):  \n        The directory to save the output plot.\n\n    outputFileName (str, optional):  \n        The name of the output file. Use desired file format as suffix (e.g. `.png` or `.pdf`).\n\nReturns:\n    Plot (image):  \n        If `outputDir` is not provided, the plot is displayed on the screen. \n        Otherwise, the plot is saved in the provided `outputDir` directory.\n\nExample:\n    ```\n    # create a 2D density plot of the expression of 'CD3D' against 'CD8A' in the dataset 'adata'\n    densityPlot2D(adata, markerA='CD3D', markerB='CD8A')\n\n    # create a 2D density plot of the expression of 'CD3D' against all markers in the dataset 'adata'\n    densityPlot2D(adata, markerA='CD3D')\n    ```\n\n    \"\"\"\n    # testing\n    # import anndata as ad\n    # adata = ad.read(r\"C:\\Users\\aj\\Dropbox (Partners HealthCare)\\nirmal lab\\softwares\\scimap\\scimap\\tests\\_data\\example_data.h5ad\")\n    # adata = ad.read('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/softwares/scimap/scimap/tests/_data/example_data.h5ad')\n    # markerA ='CD3E'; layers=None; markerB='CD163'; plotGrid=True; ncols=None; color=None; figsize=(10, 10); fontsize=None; subset=None; imageid='imageid'; xticks=None; dpi=200; outputDir=None; \n    # hline = 'auto'; vline = 'auto'\n    # outputFileName='densityPlot2D.png'\n    # color = {'markerA': '#000000', 'markerB': '#FF0000'}\n    # outputDir = r\"C:\\Users\\aj\\Downloads\"\n\n    #densityPlot2D (adata, markerA='CD3D', markerB=['CD2', 'CD10', 'CD163'], dpi=50, outputDir=r\"C:\\Users\\aj\\Downloads\")\n\n\n    # set color\n    cp = copy.copy(cm.get_cmap(cmap))\n    cp.set_under(alpha=0)\n\n    # subset data if neede\n    if subset is not None:\n        if isinstance (subset, str):\n            subset = [subset]\n        if layer == 'raw':\n            bdata=adata.copy()\n            bdata.X = adata.raw.X\n            bdata = bdata[bdata.obs[imageid].isin(subset)]\n        else:\n            bdata=adata.copy()\n            bdata = bdata[bdata.obs[imageid].isin(subset)]\n    else:\n        bdata=adata.copy()\n\n    # isolate the data\n    if layer is None:\n        data = pd.DataFrame(bdata.X, index=bdata.obs.index, columns=bdata.var.index)\n    elif layer == 'raw':\n        data = pd.DataFrame(bdata.raw.X, index=bdata.obs.index, columns=bdata.var.index)\n    else:\n        data = pd.DataFrame(bdata.layers[layer], index=bdata.obs.index, columns=bdata.var.index)\n\n    # keep only columns that are required\n    x = data[markerA]\n\n    if markerB is None:\n        y = data.drop(markerA, axis=1)\n    else:\n        if isinstance(markerB, str):\n            markerB = [markerB]\n        y = data[markerB]\n\n    # auto identify rows and columns in the grid plot\n    def calculate_grid_dimensions(num_items, num_columns=None):\n\"\"\"\n        Calculates the number of rows and columns for a square grid\n        based on the number of items.\n        \"\"\"\n        if num_columns is None:\n            num_rows_columns = int(math.ceil(math.sqrt(num_items)))\n            return num_rows_columns, num_rows_columns\n        else:\n            num_rows = int(math.ceil(num_items / num_columns))\n            return num_rows, num_columns\n\n    # calculate the number of rows and columns\n    num_rows, num_cols = calculate_grid_dimensions(len(y.columns), num_columns = ncols)\n\n\n\n    fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(num_cols*figsize[0],num_rows*figsize[0]), subplot_kw={'projection': 'scatter_density'})\n    if num_rows == 1 and num_cols == 1:\n        axs = [axs]  # wrap single subplot in a list\n    else:\n        axs = axs.flatten()\n    for i, col in enumerate(y.columns):\n        ax = axs[i]\n        ax.scatter_density(x, y[col], dpi=dpi, cmap=cp, norm=LogNorm(vmin=0.5, vmax=x.size))\n        ax.set_xlabel(markerA, size = fontsize)\n        ax.set_ylabel(col, size = fontsize)\n\n        if hline == 'auto':\n            ax.axhline((y[col].max() + y[col].min()) / 2, color='grey')\n        elif hline is None:\n            pass\n        else:\n            ax.axhline(hline, color='grey')\n\n        if vline == 'auto':\n            ax.axvline((x.max() + x.min()) / 2, color='grey')\n        elif vline is None:\n            pass\n        else:\n            ax.axvline(vline, color='grey')\n\n        # control and x and y ticks\n        if xticks is not None:\n            ax.set_xticks(xticks)\n            ax.set_xticklabels([str(x) for x in xticks])\n\n        if yticks is not None:\n            ax.set_yticks(yticks)\n            ax.set_yticklabels([str(x) for x in yticks])\n\n\n    # Remove any empty subplots\n    num_plots = len(y.columns)\n    for i in range(num_plots, num_rows * num_cols):\n        ax = axs[i]\n        fig.delaxes(ax)\n\n    plt.tick_params(axis='both', labelsize=fontsize)\n    plt.tight_layout()\n\n    # Save the figure to a file\n    # save figure\n    if outputDir is not None:\n        plt.savefig(pathlib.Path(outputDir) / outputFileName)\n</code></pre>"},{"location":"Functions/pl/distPlot/","title":"distPlot","text":"<p>Short Description</p> <p>The <code>sm.pl.distPlot</code> function is used to create distribution plots of  marker intensity data.</p>"},{"location":"Functions/pl/distPlot/#scimap.plotting.distPlot--function","title":"Function","text":""},{"location":"Functions/pl/distPlot/#scimap.plotting.distPlot.distPlot","title":"<code>distPlot(adata, layer=None, markers=None, subset=None, imageid='imageid', vline=None, plotGrid=True, ncols=None, color=None, xticks=None, figsize=(5, 5), fontsize=None, dpi=200, outputDir=None, outputFileName='scimapDistPlot.png')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data object.</p> required <code>layer</code> <code>str</code> <p>Layer of data to plot.</p> <code>None</code> <code>markers</code> <code>list</code> <p>List of marker genes to plot.</p> <code>None</code> <code>subset</code> <code>list or None</code> <p><code>imageid</code> of a single or multiple images to be subsetted for plotting purposes.</p> <code>None</code> <code>imageid</code> <code>str</code> <p>The column name in <code>spatial feature table</code> that contains the image ID  for each cell. </p> <code>'imageid'</code> <code>vline</code> <code>float or 'auto'</code> <p>The x-coordinate of the vertical line to plot. If set to <code>None</code>, a vertical line is not plotted. Use 'auto' to draw a vline at the center point. </p> <code>None</code> <code>plotGrid</code> <code>bool</code> <p>Whether to plot each marker in it's own sub plot. If <code>False</code> and multiple markers  are passed in via <code>markers</code>, all distributions will be plotted within a single plot.</p> <code>True</code> <code>ncols</code> <code>int</code> <p>The number of columns in the final plot when multiple variables are plotted.</p> <code>None</code> <code>color</code> <code>str</code> <p>Color of the distribution plot. </p> <code>None</code> <code>xticks</code> <code>list of float</code> <p>Custom x-axis tick values.</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>Figure size. Defaults to (5, 5).</p> <code>(5, 5)</code> <code>fontsize</code> <code>int</code> <p>The size of the font of the axis labels.</p> <code>None</code> <code>dpi</code> <code>int</code> <p>The DPI of the figure. Use this to control the point size. Lower the dpi, larger the point size.</p> <code>200</code> <code>outputDir</code> <code>str</code> <p>The directory to save the output plot.</p> <code>None</code> <code>outputFileName</code> <code>str</code> <p>The name of the output file. Use desired file format as suffix (e.g. <code>.png</code> or <code>.pdf</code>).</p> <code>'scimapDistPlot.png'</code> <p>Returns:</p> Name Type Description <code>Plot</code> <code>image</code> <p>If <code>outputDir</code> is provided the plot will saved within the provided outputDir.</p> Example <pre><code>sm.pl.distPlot(adata, \n             layer=None, \n             markers=['CD45','CD3D','CD20'], \n             plotGrid=True, \n             ncols=5)\n</code></pre> Source code in <code>scimap/plotting/distPlot.py</code> <pre><code>def distPlot(adata, \n             layer=None, \n             markers=None, \n             subset=None, \n             imageid='imageid',\n             vline=None,\n             plotGrid=True, \n             ncols=None, \n             color=None, \n             xticks=None, \n             figsize=(5, 5), \n             fontsize=None, \n             dpi=200, \n             outputDir=None, \n             outputFileName='scimapDistPlot.png'):\n\n\"\"\"\nParameters:\n    adata (AnnData): \n        Annotated data object.\n\n    layer (str, optional): \n        Layer of data to plot.\n\n    markers (list, optional): \n        List of marker genes to plot.\n\n    subset (list or None, optional):  \n        `imageid` of a single or multiple images to be subsetted for plotting purposes.\n\n    imageid (str, optional):  \n        The column name in `spatial feature table` that contains the image ID \n        for each cell. \n\n    vline (float or 'auto', optional):  \n        The x-coordinate of the vertical line to plot. If set to `None`, a vertical line is not plotted.\n        Use 'auto' to draw a vline at the center point. \n\n    plotGrid (bool, optional):  \n        Whether to plot each marker in it's own sub plot. If `False` and multiple markers \n        are passed in via `markers`, all distributions will be plotted within a single plot.\n\n    ncols (int, optional):  \n        The number of columns in the final plot when multiple variables are plotted.\n\n    color (str, optional):   \n        Color of the distribution plot. \n\n    xticks (list of float, optional):  \n        Custom x-axis tick values.\n\n    figsize (tuple, optional):   \n        Figure size. Defaults to (5, 5).\n\n    fontsize (int, optional):  \n        The size of the font of the axis labels.\n\n    dpi (int, optional):  \n        The DPI of the figure. Use this to control the point size. Lower the dpi, larger the point size.\n\n    outputDir (str, optional):  \n        The directory to save the output plot.\n\n    outputFileName (str, optional):  \n        The name of the output file. Use desired file format as suffix (e.g. `.png` or `.pdf`).\n\nReturns:\n    Plot (image):\n        If `outputDir` is provided the plot will saved within the\n        provided outputDir.\n\nExample:\n\n        ```python\n\n        sm.pl.distPlot(adata, \n                     layer=None, \n                     markers=['CD45','CD3D','CD20'], \n                     plotGrid=True, \n                     ncols=5)\n        ```\n\n    \"\"\"\n\n    # testing\n    # layers=None; markers=None; plotGrid=True; ncols=None; color=None; figsize=(10, 10); fontsize=None; subset=None; imageid='imageid'; xticks=None; dpi=200; outputDir=None; \n    # outputFileName='distPlot.png'\n    # color = {'markerA': '#000000', 'markerB': '#FF0000'}\n    # outputDir = r\"C:\\Users\\aj\\Downloads\"\n\n    # subset data if neede\n    if subset is not None:\n        if isinstance (subset, str):\n            subset = [subset]\n        if layer == 'raw':\n            bdata=adata.copy()\n            bdata.X = adata.raw.X\n            bdata = bdata[bdata.obs[imageid].isin(subset)]\n        else:\n            bdata=adata.copy()\n            bdata = bdata[bdata.obs[imageid].isin(subset)]\n    else:\n        bdata=adata.copy()\n\n    # isolate the data\n    if layer is None:\n        data = pd.DataFrame(bdata.X, index=bdata.obs.index, columns=bdata.var.index)\n    elif layer == 'raw':\n        data = pd.DataFrame(bdata.raw.X, index=bdata.obs.index, columns=bdata.var.index)\n    else:\n        data = pd.DataFrame(bdata.layers[layer], index=bdata.obs.index, columns=bdata.var.index)\n\n    # keep only columns that are required\n    if markers is not None:\n        if isinstance(markers, str):\n            markers = [markers]\n        # subset the list\n        data = data[markers]\n\n    # auto identify rows and columns in the grid plot\n    def calculate_grid_dimensions(num_items, num_columns=None):\n\"\"\"\n        Calculates the number of rows and columns for a square grid\n        based on the number of items.\n        \"\"\"\n        if num_columns is None:\n            num_rows_columns = int(math.ceil(math.sqrt(num_items)))\n            return num_rows_columns, num_rows_columns\n        else:\n            num_rows = int(math.ceil(num_items / num_columns))\n            return num_rows, num_columns\n\n\n    if plotGrid is False:\n        # Create a figure and axis object\n        fig, ax = plt.subplots(figsize=figsize, dpi=dpi)           \n        # Loop through each column in the DataFrame and plot a KDE with the\n        # user-defined color or the default color (grey)\n        if color is None:\n            for column in data.columns:\n                data[column].plot.kde(ax=ax, label=column)\n        else:\n            for column in data.columns:\n                c = color.get(column, 'grey')\n                data[column].plot.kde(ax=ax, label=column, color=c)\n        ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5), fontsize=fontsize)\n        ax.tick_params(axis='both', which='major', width=1, labelsize=fontsize)\n        plt.tight_layout()\n        if xticks is not None:\n            ax.set_xticks(xticks)\n            ax.set_xticklabels([str(x) for x in xticks])       \n\n\n        if vline == 'auto':\n            ax.axvline((data[column].max() + data[column].min()) / 2, color='black')\n        elif vline is None:\n            pass\n        else:\n            ax.axvline(vline, color='black')\n\n\n        # save figure\n        if outputDir is not None:\n            plt.savefig(pathlib.Path(outputDir) / outputFileName)\n\n    else:\n        # calculate the number of rows and columns\n        num_rows, num_cols = calculate_grid_dimensions(len(data.columns), num_columns = ncols)\n\n        # set colors\n        if color is None:\n            # Define a color cycle of 10 colors\n            color_cycle = itertools.cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n            # Assign a different color to each column\n            color = {col: next(color_cycle) for col in data.columns}\n\n        # Set the size of the figure\n        fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=figsize, dpi=dpi)\n        # Set the spacing between subplots\n        #fig.subplots_adjust(bottom=0.1, hspace=0.1)\n\n        # Loop through each column in the DataFrame and plot a KDE with the\n        # user-defined color or the default color (grey) in the corresponding subplot\n        for i, column in enumerate(data.columns):\n            c = color.get(column, 'grey')\n            row_idx = i // num_cols\n            col_idx = i % num_cols\n            data[column].plot.kde(ax=axes[row_idx, col_idx], label=column, color=c)\n            axes[row_idx, col_idx].set_title(column)\n            axes[row_idx, col_idx].tick_params(axis='both', which='major', width=1, labelsize=fontsize)\n            axes[row_idx, col_idx].set_ylabel('')\n\n            if vline == 'auto':\n                axes[row_idx, col_idx].axvline((data[column].max() + data[column].min()) / 2, color='black')\n            elif vline is None:\n                pass\n            else:\n                axes[row_idx, col_idx].axvline(vline, color='black')\n\n            if xticks is not None:\n                axes[row_idx, col_idx].set_xticks(xticks)\n                axes[row_idx, col_idx].set_xticklabels([str(x) for x in xticks])\n\n        # Remove any empty subplots\n        num_plots = len(data.columns)\n        for i in range(num_plots, num_rows * num_cols):\n            row_idx = i // num_cols\n            col_idx = i % num_cols\n            fig.delaxes(axes[row_idx, col_idx])\n\n        # Set font size for tick labels on both axes\n        plt.tick_params(axis='both', labelsize=fontsize)\n        plt.tight_layout()\n\n        # Save the figure to a file\n        # save figure\n        if outputDir is not None:\n            plt.savefig(pathlib.Path(outputDir) / outputFileName)\n</code></pre>"},{"location":"Functions/pl/foldchange/","title":"foldchange","text":"<p>Short Description</p> <p><code>sm.pl.foldchange</code>: The Function allows users to visualize foldchange in abundance of celltypes between samples/ROI's.  Run <code>sm.tl.foldchange</code> first to compute the foldchange.</p>"},{"location":"Functions/pl/foldchange/#scimap.plotting._foldchange--function","title":"Function","text":""},{"location":"Functions/pl/foldchange/#scimap.plotting._foldchange.foldchange","title":"<code>foldchange(adata, label='foldchange', p_val=0.05, nonsig_color='grey', subset_xaxis=None, subset_yaxis=None, cmap='vlag', log=True, center=0, method='heatmap', invert_axis=None, parallel_coordinates_color=None, matplotlib_bbox_to_anchor=(1.04, 1), matplotlib_legend_loc='upper left', xticks_rotation=90, return_data=False, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>Anndata object</p> required <code>label</code> <p>strong, optional label used when running <code>sm.tl.foldchange</code>.</p> <code>'foldchange'</code> <code>p_val</code> <p>float, optional p_val cut-off above which is considered not-significant. The cells containing non-significant changes will be highlighted in the heatmap.</p> <code>0.05</code> <code>nonsig_color</code> <p>string, optional Color used to highlight non-significant fold changes in the heatmap.</p> <code>'grey'</code> <code>subset_xaxis</code> <p>list, optional Subset x-axis before plotting. Pass in a list of categories. eg- subset_xaxis = ['CelltypeA', 'CellTypeB']. </p> <code>None</code> <code>subset_yaxis</code> <p>list, optional Subset y-axis before plotting. Pass in a list of categories. eg- subset_yaxis = ['ROI_1', 'ROI_5']. </p> <code>None</code> <code>cmap</code> <p>string, optional Color map. Can be a name or a Colormap instance (e.g. 'magma', 'viridis').</p> <code>'vlag'</code> <code>log</code> <p>bool, optional Convert foldchange to log2 scale.</p> <code>True</code> <code>center</code> <p>float, optional The center value to be used in heatmap.</p> <code>0</code> <code>method</code> <p>string, optional Two methods are available for plotting the foldchanges a) Heatmap: Use <code>heatmap</code> b) parallel coordinates plot : Use <code>parallel_coordinates</code> </p> <code>'heatmap'</code> <code>invert_axis</code> <p>bool, optional Flip the axis of the plot.</p> <code>None</code> <code>parallel_coordinates_color</code> <p>list, optional Custom colors for each category.</p> <code>None</code> <code>matplotlib_bbox_to_anchor</code> <p>tuple, optional Bounding box argument used along with matplotlib_legend_loc to control the legend location when using the matplotlib method.</p> <code>(1.04, 1)</code> <code>matplotlib_legend_loc</code> <p>TYPE, optional Location of legend used along with matplotlib_bbox_to_anchor to control the legend location when using the matplotlib method.</p> <code>'upper left'</code> <code>xticks_rotation</code> <p>int, optional Angle the x-axis ticks.</p> <code>90</code> <code>return_data</code> <p>bool, optional Return the final data used for plotting.</p> <code>False</code> <code>**kwargs</code> <p>Additional keyword arguments passed to: a) sns.clustermap b) pandas.parallel_coordinates  </p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Plot</code> <p>Data used for the plot if <code>return_data = True</code></p> <pre><code>    # Heatmap of foldchnage  \n    sm.pl.foldchange (adata, label='foldchange', method='heatmap',\n                     p_val=0.05, nonsig_color='grey',\n                     cmap = 'vlag', log=True, center=0, linecolor='black',linewidths=0.7,\n                     vmin=-5, vmax=5, row_cluster=False)\n\n    # Parallel_coordinates plot of the foldchanges\n    foldchange (adata, label='foldchange', \n                log=True, method='parallel_coordinates', invert_axis=True,\n                parallel_coordinates_color=['black','blue','green','red','#000000'],\n                matplotlib_bbox_to_anchor=(1.04,1),\n                matplotlib_legend_loc='upper left',\n                xticks_rotation=90,\n                return_data = False\n</code></pre> Source code in <code>scimap/plotting/_foldchange.py</code> <pre><code>def foldchange (adata, label='foldchange', \n                p_val=0.05, nonsig_color='grey',subset_xaxis=None,subset_yaxis=None,\n                cmap = 'vlag', log=True,center=0, \n                method='heatmap', invert_axis=None,\n                parallel_coordinates_color=None,matplotlib_bbox_to_anchor=(1.04,1),\n                matplotlib_legend_loc='upper left',xticks_rotation=90,\n                return_data = False,\n                **kwargs):\n\"\"\"\nParameters:\n    adata : Anndata object\n\n    label : strong, optional  \n        label used when running `sm.tl.foldchange`.\n\n    p_val : float, optional  \n        p_val cut-off above which is considered not-significant. The cells containing\n        non-significant changes will be highlighted in the heatmap.\n\n    nonsig_color : string, optional  \n        Color used to highlight non-significant fold changes in the heatmap.\n\n    subset_xaxis : list, optional  \n        Subset x-axis before plotting. Pass in a list of categories. eg- subset_xaxis = ['CelltypeA', 'CellTypeB']. \n\n    subset_yaxis : list, optional  \n        Subset y-axis before plotting. Pass in a list of categories. eg- subset_yaxis = ['ROI_1', 'ROI_5']. \n\n    cmap : string, optional  \n        Color map. Can be a name or a Colormap instance (e.g. 'magma', 'viridis').\n\n    log : bool, optional  \n        Convert foldchange to log2 scale.\n\n    center : float, optional  \n        The center value to be used in heatmap.\n\n    method : string, optional  \n        Two methods are available for plotting the foldchanges  \n        a) Heatmap: Use `heatmap`  \n        b) parallel coordinates plot : Use `parallel_coordinates`  \n\n    invert_axis : bool, optional  \n        Flip the axis of the plot.\n\n    parallel_coordinates_color : list, optional  \n        Custom colors for each category.\n\n    matplotlib_bbox_to_anchor : tuple, optional  \n        Bounding box argument used along with matplotlib_legend_loc to control\n        the legend location when using the matplotlib method.\n\n    matplotlib_legend_loc : TYPE, optional  \n        Location of legend used along with matplotlib_bbox_to_anchor to control\n        the legend location when using the matplotlib method.\n\n    xticks_rotation : int, optional  \n        Angle the x-axis ticks.\n\n    return_data: bool, optional  \n        Return the final data used for plotting.\n\n    **kwargs : Additional keyword arguments passed to:  \n        a) sns.clustermap  \n        b) pandas.parallel_coordinates  \n\nReturns:\n    Plot:  \n        Data used for the plot if `return_data = True`\n\nExample:\n```python\n    # Heatmap of foldchnage  \n    sm.pl.foldchange (adata, label='foldchange', method='heatmap',\n                     p_val=0.05, nonsig_color='grey',\n                     cmap = 'vlag', log=True, center=0, linecolor='black',linewidths=0.7,\n                     vmin=-5, vmax=5, row_cluster=False)\n\n    # Parallel_coordinates plot of the foldchanges\n    foldchange (adata, label='foldchange', \n                log=True, method='parallel_coordinates', invert_axis=True,\n                parallel_coordinates_color=['black','blue','green','red','#000000'],\n                matplotlib_bbox_to_anchor=(1.04,1),\n                matplotlib_legend_loc='upper left',\n                xticks_rotation=90,\n                return_data = False\n```\n    \"\"\"\n\n    # set color for heatmap\n    #cmap_updated = copy.copy(matplotlib.cm.get_cmap(cmap))\n    cmap_updated = matplotlib.cm.get_cmap(cmap)\n    cmap_updated.set_bad(color=nonsig_color)\n\n\n    # get the data\n    fc = adata.uns[str(label)+'_fc']\n    p = adata.uns[str(label)+'_pval']\n\n    #fold\n    fold = fc.copy()\n    p_mask = p.copy()\n\n    # reference image\n    ref = fold.index.name\n\n    # log\n    if log is True:\n        fold = np.log2(fold)\n\n    # create a mask for non-sig values\n    p_mask[p_mask &gt; p_val] = np.nan\n\n    # subset x axis data\n    if subset_xaxis is not None:\n        if isinstance (subset_xaxis, str):\n            subset_xaxis = [subset_xaxis]\n        fold = fold [subset_xaxis]\n        p_mask = p_mask [subset_xaxis]\n        #reorder\n\n    # subset y axis data\n    if subset_yaxis is not None:\n        if isinstance (subset_yaxis, str):\n            subset_yaxis = [subset_yaxis]\n        fold = fold.loc [subset_yaxis]\n        p_mask = p_mask.loc [subset_yaxis]\n        #reorder\n\n    # invert axis if user requests\n    if invert_axis is True:\n        fold = fold.T\n        p_mask = p_mask.T\n\n    #mask\n    mask = p_mask.isnull() # identify the NAN's for masking \n\n    if method == 'heatmap':\n        # heatmap of the foldchange\n        #g= sns.clustermap(fold, cmap=cmap, mask=mask, center=center, col_cluster=False, row_cluster=False)\n        g= sns.clustermap(fold, cmap=cmap, mask=mask, center=center, **kwargs)\n        plt.suptitle('reference: '+ str(ref))\n        plt.setp(g.ax_heatmap.get_xticklabels(), rotation=xticks_rotation)\n        plt.tight_layout()\n\n\n    if method == 'parallel_coordinates':\n        fold['sample'] = fold.index\n        # plotting\n        fig, axes = plt.subplots()\n        if parallel_coordinates_color is not None:\n            parallel_coordinates(fold, 'sample', color=parallel_coordinates_color, **kwargs)\n        else:\n            #parallel_coordinates(fold, 'sample', colormap=cmap_updated)\n            parallel_coordinates(fold, 'sample', colormap=cmap_updated, **kwargs)\n        axes.grid(False)\n        plt.legend(bbox_to_anchor=matplotlib_bbox_to_anchor, loc=matplotlib_legend_loc)\n        plt.axhline(y=0, color='black', linestyle='-')\n        plt.xticks(rotation = xticks_rotation)\n        plt.suptitle('reference: '+ str(ref))\n        fig.tight_layout()\n\n    # return data\n    if return_data is True:\n        return fold\n</code></pre>"},{"location":"Functions/pl/gate_finder/","title":"gate_finder","text":"<p>Short Description</p> <p><code>sm.pl.gate_finder</code>: The function opens the OME-TIFF image inside Napari and overlays points to help with the  identifying manual gates for each marker. Use the <code>sm.pp.rescale</code> function to apply the identified gates to your data.</p>"},{"location":"Functions/pl/gate_finder/#scimap.plotting._gate_finder--function","title":"Function","text":""},{"location":"Functions/pl/gate_finder/#scimap.plotting._gate_finder.gate_finder","title":"<code>gate_finder(image_path, adata, marker_of_interest, layer='raw', log=True, from_gate=6, to_gate=8, increment=0.1, markers=None, channel_names='default', flip_y=True, x_coordinate='X_centroid', y_coordinate='Y_centroid', point_size=10, imageid='imageid', subset=None, seg_mask=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>Location to the image file.</p> required <code>adata</code> <p>Ann Data Object  </p> required <code>marker_of_interest</code> <code>str</code> <p>Marker for which gate is to be defined e.g. 'CD45'.</p> required <code>layer</code> <code>str</code> <p>The layer in adata.layers that contains the expression data to gate.  If None, adata.X is used. use <code>raw</code> to use the data stored in <code>adata.raw.X</code></p> <code>'raw'</code> <code>log</code> <code>bool</code> <p>Log transform the data before gating.</p> <code>True</code> <code>from_gate</code> <code>int</code> <p>Start value gate of interest.</p> <code>6</code> <code>to_gate</code> <code>int</code> <p>End value of the gate of interest.</p> <code>8</code> <code>flip_y</code> <code>bool</code> <p>Flip the Y-axis if needed. Some algorithms output the XY with the Y-coordinates flipped. If the image overlays do not align to the cells, try again by setting this to <code>False</code>.</p> <code>True</code> <code>increment</code> <code>float</code> <p>Increments between the start and end values.</p> <code>0.1</code> <code>markers</code> <code>str</code> <p>Additional markers to be included in the plot for evaluation.</p> <code>None</code> <code>channel_names</code> <code>list</code> <p>List of channels in the image in the exact order as image. The default is <code>adata.uns['all_markers']</code></p> <code>'default'</code> <code>x_coordinate</code> <code>str</code> <p>X axis coordinate column name in AnnData object.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <code>str</code> <p>Y axis coordinate column name in AnnData object.</p> <code>'Y_centroid'</code> <code>point_size</code> <code>int</code> <p>point size in the napari plot.</p> <code>10</code> <code>imageid</code> <code>str</code> <p>Column name of the column containing the image id.</p> <code>'imageid'</code> <code>subset</code> <code>str</code> <p>imageid of a single image to be subsetted for analyis.</p> <code>None</code> <code>seg_mask</code> <code>str</code> <p>Location to the segmentation mask file.</p> <code>None</code> <pre><code>    image_path = '/Users/aj/Desktop/ptcl_tma/image.ome.tif'\n    sm.pl.gate_finder (image_path, adata, marker_of_interest='CD45',\n                 from_gate = 6, to_gate = 8, increment = 0.1,\n                 markers=['DNA10'], channel_names = 'default',\n                 x_coordinate='X_position',y_coordinate='Y_position',point_size=10,\n                 subset= '77', seg_mask=None)\n</code></pre> Source code in <code>scimap/plotting/_gate_finder.py</code> <pre><code>def gate_finder (image_path, adata, marker_of_interest, layer='raw', log=True,\n                 from_gate = 6, to_gate = 8, increment = 0.1,\n                 markers=None, channel_names = 'default', flip_y=True,\n                 x_coordinate='X_centroid',y_coordinate='Y_centroid',\n                 point_size=10,imageid='imageid',subset=None,seg_mask=None,**kwargs):\n\"\"\"\nParameters:\n    image_path (str):  \n        Location to the image file.\n\n    adata : Ann Data Object  \n\n    marker_of_interest (str):  \n        Marker for which gate is to be defined e.g. 'CD45'.\n\n    layer (str): \n        The layer in adata.layers that contains the expression data to gate. \n        If None, adata.X is used. use `raw` to use the data stored in `adata.raw.X`\n\n    log (bool):  \n        Log transform the data before gating.\n\n    from_gate (int):   \n        Start value gate of interest.\n\n    to_gate (int):    \n        End value of the gate of interest.\n\n    flip_y (bool):  \n        Flip the Y-axis if needed. Some algorithms output the XY with the Y-coordinates flipped.\n        If the image overlays do not align to the cells, try again by setting this to `False`.\n\n    increment (float):  \n        Increments between the start and end values.\n\n    markers (str):  \n        Additional markers to be included in the plot for evaluation.\n\n    channel_names (list):  \n        List of channels in the image in the exact order as image. The default is `adata.uns['all_markers']`\n\n    x_coordinate (str):  \n        X axis coordinate column name in AnnData object.\n\n    y_coordinate (str):  \n        Y axis coordinate column name in AnnData object.\n\n    point_size (int):  \n        point size in the napari plot.\n\n    imageid (str):  \n        Column name of the column containing the image id.\n\n    subset (str):  \n        imageid of a single image to be subsetted for analyis.\n\n    seg_mask (str):  \n        Location to the segmentation mask file.\n\n    **kwargs  \n        Other arguments that can be passed to napari viewer.\n\nExample:\n```python\n    image_path = '/Users/aj/Desktop/ptcl_tma/image.ome.tif'\n    sm.pl.gate_finder (image_path, adata, marker_of_interest='CD45',\n                 from_gate = 6, to_gate = 8, increment = 0.1,\n                 markers=['DNA10'], channel_names = 'default',\n                 x_coordinate='X_position',y_coordinate='Y_position',point_size=10,\n                 subset= '77', seg_mask=None)\n```\n    \"\"\"\n\n    # If no raw data is available make a copy\n    if adata.raw is None:\n        adata.raw = adata\n\n    # subset data if neede\n    if subset is not None:\n        if isinstance (subset, str):\n            subset = [subset]\n        if layer == 'raw':\n            bdata=adata.copy()\n            bdata.X = adata.raw.X\n            bdata = bdata[bdata.obs[imageid].isin(subset)]\n        else:\n            bdata=adata.copy()\n            bdata = bdata[bdata.obs[imageid].isin(subset)]\n    else:\n        bdata=adata.copy()\n\n    # isolate the data\n    if layer is None:\n        data = pd.DataFrame(bdata.X, index=bdata.obs.index, columns=bdata.var.index)[[marker_of_interest]]\n    elif layer == 'raw':\n        data = pd.DataFrame(bdata.raw.X, index=bdata.obs.index, columns=bdata.var.index)[[marker_of_interest]]\n    else:\n        data = pd.DataFrame(bdata.layers[layer], index=bdata.obs.index, columns=bdata.var.index)[[marker_of_interest]]\n\n    if log is True:\n        data = np.log1p(data)\n\n\n    # Copy of the raw data if it exisits\n    #if adata.raw is not None:\n    #    adata.X = adata.raw.X\n\n    # Plot only the Image that is requested\n    #if subset is not None:\n    #    adata = adata[adata.obs[imageid] == subset]\n\n    # Make a copy of the data with the marker of interest\n    #data = pd.DataFrame(np.log1p(adata.X), columns = adata.var.index, index= adata.obs.index)[[marker_of_interest]]\n\n    # Generate a dataframe with various gates\n    def gate (g, d):\n        dd = d.values\n        dd = np.where(dd &lt; g, np.nan, dd)\n        np.warnings.filterwarnings('ignore')\n        dd = np.where(dd &gt; g, 1, dd)\n        dd = pd.DataFrame(dd, index = d.index, columns = ['gate-' + str(g)])\n        return dd\n\n    # Identify the list of increments\n    inc = list(np.arange (from_gate, to_gate, increment))\n    inc = [round(num,3) for num in inc]\n\n    # Apply the function\n    r_gate = lambda x: gate(g=x, d=data) # Create lamda function\n    gated_data = list(map(r_gate, inc)) # Apply function\n    # Concat all the results into a single dataframe\n    gates = pd.concat(gated_data, axis=1)\n\n\n    # Recover the channel names from adata\n    if channel_names == 'default':\n        channel_names = adata.uns['all_markers']\n    else:\n        channel_names = channel_names\n\n    # if markers is a string convert to list\n    if isinstance(markers, str):\n        markers = [markers]\n\n    # Index of the marker of interest and corresponding names\n    if markers is not None:\n        markers.extend([marker_of_interest])\n        idx = np.where(np.isin(channel_names,markers))[0]\n        channel_names = [channel_names[i] for i in idx]\n    else:\n        idx = list(range(len(channel_names)))\n        channel_names = channel_names\n\n\n    # Load the segmentation mask\n    if seg_mask is not None:\n        seg_m = tiff.imread(seg_mask)\n        if (len(seg_m.shape) &gt; 2) and (seg_m.shape[0] &gt; 1):\n            seg_m = seg_m[0]\n\n\n    ##########################################################################\n    # Visulaisation using Napari\n\n    # load OME TIFF\n    if os.path.isfile(image_path) is True: \n        # Load the image    \n        image = tiff.TiffFile(image_path, is_ome=False)\n        z = zarr.open(image.aszarr(), mode='r') # convert image to Zarr array\n        # Identify the number of pyramids and number of channels\n        n_levels = len(image.series[0].levels) # pyramid  \n        # If and if not pyramids are available\n        if n_levels &gt; 1:\n            pyramid = [da.from_zarr(z[i]) for i in range(n_levels)]\n            multiscale = True\n        else:\n            pyramid = da.from_zarr(z)\n            multiscale = False   \n        # subset channels of interest\n        if markers is not None:\n            if n_levels &gt; 1:\n                for i in range(n_levels-1):\n                    pyramid[i] = pyramid[i][idx, :, :]\n                n_channels = pyramid[0].shape[0] # identify the number of channels\n            else:\n                pyramid = pyramid[idx, :, :]\n                n_channels = pyramid.shape[0] # identify the number of channels\n        else:\n            if n_levels &gt; 1:\n                n_channels = pyramid[0].shape[0]\n            else:\n                n_channels = pyramid.shape[0]\\\n        # check if channel names have been passed to all channels\n        if channel_names is not None:\n            assert n_channels == len(channel_names), (\n                f'number of channel names ({len(channel_names)}) must '\n                f'match number of channels ({n_channels})'\n            )\n\n        # Load the viewer\n        viewer = napari.view_image(\n        pyramid,\n        channel_axis = 0,\n        multiscale=multiscale,\n        name = None if channel_names is None else channel_names,\n        visible = False, **kwargs)\n\n\n    # Operations on the ZARR image\n    # check the format of image\n    if os.path.isfile(image_path) is False: \n        #print(image_path)\n        viewer = napari.Viewer()\n        viewer.open(image_path, multiscale=True,\n                    visible=False,\n                    name = None if channel_names is None else channel_names)\n\n    # Add the seg mask\n    if seg_mask is not None:\n        viewer.add_labels(seg_m, name='segmentation mask', visible=False)\n\n    # subset the gates to include only the image of interest\n    gates = gates.loc[bdata.obs.index,]\n\n    # Add gating layer\n    def add_phenotype_layer (adata, gates, phenotype_layer,x,y,viewer,point_size):\n        cells = gates[gates[phenotype_layer] == 1].index\n        coordinates = adata[cells]\n        # Flip Y axis if needed\n        if flip_y is True:\n            coordinates = pd.DataFrame({'y': coordinates.obs[y],'x': coordinates.obs[x]})\n        else:  \n            coordinates = pd.DataFrame({'x': coordinates.obs[x],'y': coordinates.obs[y]})\n        #points = coordinates.values.tolist()\n        points = coordinates.values\n        #import time\n        #start = time.time()\n        viewer.add_points(points, size=point_size, face_color='white',visible=False,name=phenotype_layer)\n        #stop = time.time()\n        #print(stop-start)\n\n\n    # Run the function on all gating layer\n    for i in gates.columns:\n        add_phenotype_layer (adata=bdata, gates=gates, \n                             phenotype_layer=i, x=x_coordinate, y=y_coordinate, \n                             viewer=viewer, point_size=point_size)\n</code></pre>"},{"location":"Functions/pl/image_viewer/","title":"image_viewer","text":"<p>Short Description</p> <p><code>sm.pl.image_viewer</code>: The function allows users to open OME-TIFF images inside  Napari and overlay any any categorical column such as cluster annotation or phenotypes.</p>"},{"location":"Functions/pl/image_viewer/#scimap.plotting._image_viewer--function","title":"Function","text":""},{"location":"Functions/pl/image_viewer/#scimap.plotting._image_viewer.image_viewer","title":"<code>image_viewer(image_path, adata, overlay=None, flip_y=True, overlay_category=None, markers=None, channel_names='default', x_coordinate='X_centroid', y_coordinate='Y_centroid', point_size=10, point_color=None, subset=None, imageid='imageid', seg_mask=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>Location to the image file (TIFF, OME.TIFF, ZARR supported)</p> required <code>seg_mask</code> <code>str</code> <p>Location to the segmentation mask file.</p> <code>None</code> <code>adata</code> <code>Ann Data Object</code> required <code>flip_y</code> <code>bool</code> <p>Flip the Y-axis if needed. Some algorithms output the XY with the Y-coordinates flipped. If the image overlays do not align to the cells, try again by setting this to <code>False</code>.</p> <code>True</code> <code>overlay</code> <code>str</code> <p>Name of the column with any categorical data such as phenotypes or clusters.</p> <code>None</code> <code>overlay_category</code> <code>list</code> <p>If only specfic categories within the overlay column is needed, pass their names as a list. If None, all categories will be used.</p> <code>None</code> <code>markers</code> <code>list</code> <p>Markers to be included. If none, all markers will be displayed.</p> <code>None</code> <code>channel_names</code> <code>list</code> <p>List of channels in the image in the exact order as image. The default is <code>adata.uns['all_markers']</code></p> <code>'default'</code> <code>x_coordinate</code> <code>str</code> <p>X axis coordinate column name in AnnData object.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <code>str</code> <p>Y axis coordinate column name in AnnData object.</p> <code>'Y_centroid'</code> <code>point_size</code> <code>int</code> <p>point size in the napari plot.</p> <code>10</code> <code>point_color</code> <code>str, dict</code> <p>The default behavior is to assign auto colors, but you can also provide a color mapping using the point_color parameter. For instance, you can pass a dictionary that maps color values to specific categories (provided in the <code>overlay</code> parameter). Here is an example of such a color mapping: <code>point_color = {'cellTypeA': '#FFFFFF', 'cellTypeB': '#000000'}</code>. A single color can also be provided like <code>point_color = 'white'</code></p> <code>None</code> <code>imageid</code> <code>str</code> <p>Column name of the column containing the image id.</p> <code>'imageid'</code> <code>subset</code> <code>str</code> <p>imageid of a single image to be subsetted for analyis. Only useful when multiple images are being analyzed together.</p> <code>None</code> <p>Returns:</p> Type Description <p>Napari Viewer (image viewer):</p> <pre><code>    image_path = '/Users/aj/Desktop/ptcl_tma/image.ome.tif'\n    sm.pl.image_viewer (image_path, adata, overlay='phenotype',overlay_category=None,\n                markers=['CD31', \"CD3D\",\"DNA11\",'CD19','CD45','CD163','FOXP3'],\n                point_size=7,point_color='white')\n</code></pre> Source code in <code>scimap/plotting/_image_viewer.py</code> <pre><code>def image_viewer(\n    image_path,\n    adata,\n    overlay=None,\n    flip_y=True,\n    overlay_category=None,\n    markers=None,\n    channel_names='default',\n    x_coordinate='X_centroid',\n    y_coordinate='Y_centroid',\n    point_size=10,\n    point_color=None,\n    subset=None,\n    imageid='imageid',\n    seg_mask=None,\n    **kwargs,\n):\n\"\"\"\n    Parameters:\n        image_path (str):\n            Location to the image file (TIFF, OME.TIFF, ZARR supported)\n\n        seg_mask (str, optional):\n            Location to the segmentation mask file.\n\n        adata (Ann Data Object):\n\n        flip_y (bool, optional):\n            Flip the Y-axis if needed. Some algorithms output the XY with the Y-coordinates flipped.\n            If the image overlays do not align to the cells, try again by setting this to `False`.\n\n        overlay (str, optional):\n            Name of the column with any categorical data such as phenotypes or clusters.\n\n        overlay_category (list, optional):\n            If only specfic categories within the overlay column is needed, pass their names as a list.\n            If None, all categories will be used.\n\n        markers (list, optional):\n            Markers to be included. If none, all markers will be displayed.\n\n        channel_names (list, optional):\n            List of channels in the image in the exact order as image. The default is `adata.uns['all_markers']`\n\n        x_coordinate (str, optional):\n            X axis coordinate column name in AnnData object.\n\n        y_coordinate (str, optional):\n            Y axis coordinate column name in AnnData object.\n\n        point_size (int, optional):\n            point size in the napari plot.\n\n        point_color (str, dict, optional):\n            The default behavior is to assign auto colors, but you can also provide\n            a color mapping using the point_color parameter. For instance, you can pass a\n            dictionary that maps color values to specific categories (provided in the `overlay` parameter).\n            Here is an example of such a color mapping: `point_color = {'cellTypeA': '#FFFFFF', 'cellTypeB': '#000000'}`.\n            A single color can also be provided like `point_color = 'white'`\n\n        imageid (str, optional):\n            Column name of the column containing the image id.\n\n        subset (str, optional):\n            imageid of a single image to be subsetted for analyis. Only useful when multiple images are being analyzed together.\n\n        **kwargs\n            Other arguments that can be passed to napari viewer\n\n    Returns:\n        Napari Viewer (image viewer):\n\n    Example:\n    ```python\n        image_path = '/Users/aj/Desktop/ptcl_tma/image.ome.tif'\n        sm.pl.image_viewer (image_path, adata, overlay='phenotype',overlay_category=None,\n                    markers=['CD31', \"CD3D\",\"DNA11\",'CD19','CD45','CD163','FOXP3'],\n                    point_size=7,point_color='white')\n    ```\n    \"\"\"\n\n    # TODO\n    # - ADD Subset markers for ZARR ssection\n    # - Ability to use ZARR metadata if available\n\n    # adding option to load just the image without an adata object\n    if adata is None:\n        channel_names = None\n    else:\n        # All operations on the AnnData object is performed first\n        # Plot only the Image that is requested\n        if subset is not None:\n            adata = adata[adata.obs[imageid] == subset]\n\n        # Recover the channel names from adata\n        if channel_names == 'default':\n            channel_names = adata.uns['all_markers']\n        else:\n            channel_names = channel_names\n\n        # Index of the marker of interest and corresponding names\n        if markers is None:\n            idx = list(range(len(channel_names)))\n            channel_names = channel_names\n        else:\n            idx = []\n            for i in markers:\n                idx.append(list(channel_names).index(i))\n            channel_names = markers\n\n        # Load the segmentation mask\n        if seg_mask is not None:\n            seg_m = tiff.imread(seg_mask)\n            if (len(seg_m.shape) &gt; 2) and (seg_m.shape[0] &gt; 1):\n                seg_m = seg_m[0]\n\n    # Operations on the OME TIFF image is performed next\n    # check the format of image\n    if os.path.isfile(image_path) is True:\n        image = tiff.TiffFile(image_path, is_ome=False)  # is_ome=False\n        z = zarr.open(image.aszarr(), mode='r')  # convert image to Zarr array\n        # Identify the number of pyramids\n        n_levels = len(image.series[0].levels)  # pyramid\n\n        # If and if not pyramids are available\n        if n_levels &gt; 1:\n            pyramid = [da.from_zarr(z[i]) for i in range(n_levels)]\n            multiscale = True\n        else:\n            pyramid = da.from_zarr(z)\n            multiscale = False\n\n        # subset channels of interest\n        if markers is not None:\n            if n_levels &gt; 1:\n                for i in range(n_levels - 1):\n                    pyramid[i] = pyramid[i][idx, :, :]\n                n_channels = pyramid[0].shape[0]  # identify the number of channels\n            else:\n                pyramid = pyramid[idx, :, :]\n                n_channels = pyramid.shape[0]  # identify the number of channels\n        else:\n            if n_levels &gt; 1:\n                n_channels = pyramid[0].shape[0]\n            else:\n                n_channels = pyramid.shape[0]\n\n        # check if channel names have been passed to all channels\n        if channel_names is not None:\n            assert n_channels == len(channel_names), (\n                f'number of channel names ({len(channel_names)}) must '\n                f'match number of channels ({n_channels})'\n            )\n\n        # Load the viewer\n        viewer = napari.view_image(\n            pyramid,\n            multiscale=multiscale,\n            channel_axis=0,\n            visible=False,\n            name=None if channel_names is None else channel_names,\n            **kwargs,\n        )\n\n    # Operations on the ZARR image\n    # check the format of image\n    if os.path.isfile(image_path) is False:\n        # print(image_path)\n        viewer = napari.Viewer()\n        viewer.open(\n            image_path,\n            multiscale=True,\n            visible=False,\n            name=None if channel_names is None else channel_names,\n        )\n\n    # Add the seg mask\n    if seg_mask is not None:\n        viewer.add_labels(seg_m, name='segmentation mask', visible=False)\n\n    # Add phenotype layer function\n    def add_phenotype_layer(\n        adata,\n        overlay,\n        phenotype_layer,\n        x,\n        y,\n        viewer,\n        point_size,\n        point_color,\n        available_phenotypes,\n    ):\n        coordinates = adata[adata.obs[overlay] == phenotype_layer]\n        # Flip Y AXIS if needed\n        if flip_y is True:\n            coordinates = pd.DataFrame(\n                {'y': coordinates.obs[y], 'x': coordinates.obs[x]}\n            )\n        else:\n            coordinates = pd.DataFrame(\n                {'x': coordinates.obs[x], 'y': coordinates.obs[y]}\n            )\n\n        # points = coordinates.values.tolist()\n        points = coordinates.values\n        if point_color is None:\n            r = lambda: random.randint(0, 255)  # random color generator\n            point_color = '#%02X%02X%02X' % (r(), r(), r())  # random color generator\n        elif isinstance(point_color, dict):\n            # if dict identify the color for the given phenotype\n            # also if a color is not provided in the dict assign it to white\n            try:\n                point_color = point_color[available_phenotypes]\n            except KeyError:\n                point_color = 'white'\n                # if the dict has list, we need to account for it and so the following two lines\n                if isinstance(point_color, list):\n                    point_color = point_color[0]\n\n        # check if point_color is a dict and if so isolate the color to the specific categoty\n        viewer.add_points(\n            points,\n            size=point_size,\n            face_color=point_color,\n            visible=False,\n            name=phenotype_layer,\n        )\n\n    if overlay is not None:\n        # categories under investigation\n        if overlay_category is None:\n            available_phenotypes = list(adata.obs[overlay].unique())\n        else:\n            available_phenotypes = overlay_category\n\n        # Run the function on all phenotypes\n        for i in available_phenotypes:\n            add_phenotype_layer(\n                adata=adata,\n                overlay=overlay,\n                phenotype_layer=i,\n                x=x_coordinate,\n                y=y_coordinate,\n                viewer=viewer,\n                point_size=point_size,\n                point_color=point_color,\n                available_phenotypes=i,\n            )\n</code></pre>"},{"location":"Functions/pl/pie/","title":"pie","text":"<p>Short Description</p> <p><code>sm.pl.pie</code>: The function allows users to plot a pie plot for any categorical column of interest. </p>"},{"location":"Functions/pl/pie/#scimap.plotting._pie--function","title":"Function","text":""},{"location":"Functions/pl/pie/#scimap.plotting._pie.pie","title":"<code>pie(adata, phenotype='phenotype', group_by='imageid', ncols=None, subset_phenotype=None, subset_groupby=None, label='auto', title='auto', colors=None, autopct='%1.1f%%', legend=False, legend_loc='upper right', wedgeprops={'linewidth': 0}, return_data=False, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData object</p> required <code>phenotype</code> <p>string, optional Column contaning the cell-type inforamtion or any categorical data to be displayed in the form of a pie plot.</p> <code>'phenotype'</code> <code>group_by</code> <p>string, optional Column that contains inforamtion on data groupings which leads to generation of pie plot for each group (e.g. image-id). If <code>None</code> is passed, the entire data is considered as a single group.</p> <code>'imageid'</code> <code>ncols</code> <p>int, optional In case group_by is used, a grid of plots are returned. This paramenter controls the number of columns in that grid.</p> <code>None</code> <code>subset_phenotype</code> <p>list, optional User can subset a list of categories within <code>phenotype</code> before plotting.</p> <code>None</code> <code>subset_groupby</code> <p>list, optional User can subset a list of categories within <code>group_by</code> before plotting.</p> <code>None</code> <code>label</code> <p>list, optional A list of strings providing the labels for each wedge.</p> <code>'auto'</code> <code>title</code> <p>string, optional If <code>None</code>, the title of the pieplot is not plotted.</p> <code>'auto'</code> <code>colors</code> <p>list, optional A sequence of colors through which the pie chart will cycle. If None, will use the  colors in the currently active cycle.</p> <code>None</code> <code>legend</code> <p>bool, optional If True, color legends are plotted seperately.</p> <code>False</code> <code>legend_loc</code> <p>string, optional Place a legend on the Axes.</p> <code>'upper right'</code> <code>autopct</code> <p>None or str or callable, optional If not None, is a string or function used to label the wedges with their numeric value.  The label will be placed inside the wedge. If it is a format string,  the label will be fmt % pct. If it is a function, it will be called.</p> <code>'%1.1f%%'</code> <code>wedgeprops</code> <p>dict, optional Dict of arguments passed to the wedge objects making the pie. For example, you can pass in  wedgeprops = {'linewidth': 3} to set the width of the wedge border lines equal to 3.  For more details, look at the doc/arguments of the wedge object. By default clip_on=False.</p> <code>{'linewidth': 0}</code> <code>return_data</code> <p>bool, optional Returns the data used for plotting.</p> <code>False</code> <code>**kwargs</code> <p>Keyword arguments to pass on to <code>matplotlib.pyplot.pie</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <p>Returns data used for plotting if <code>return_data = True</code></p> <pre><code>    # pie plot showing stromal tumor content among the different samples\n    sm.pl.pie (adata, phenotype='Tumor_Stroma', group_by='imageid', \n               autopct='%1.1f%%',\n               textprops={'fontsize': 8, 'color': '#1d3557', 'fontweight': 'bold'},\n               ncols=5, label=None, title=None, \n               colors=['#a8dadc','#e63946'], \n               wedgeprops = {'linewidth': 0.8})\n</code></pre> Source code in <code>scimap/plotting/_pie.py</code> <pre><code>def pie (adata, phenotype='phenotype', group_by='imageid', ncols=None,\n         subset_phenotype=None, subset_groupby=None,\n         label='auto', title='auto', colors=None, autopct='%1.1f%%',\n         legend=False,legend_loc='upper right',\n         wedgeprops = {'linewidth': 0}, return_data=False, **kwargs):\n\"\"\"\nParameters:\n\n    adata : AnnData object\n\n    phenotype : string, optional  \n        Column contaning the cell-type inforamtion or any categorical data to be displayed\n        in the form of a pie plot.\n\n    group_by : string, optional  \n        Column that contains inforamtion on data groupings which leads to generation of\n        pie plot for each group (e.g. image-id). If `None` is passed,\n        the entire data is considered as a single group.\n\n    ncols : int, optional  \n        In case group_by is used, a grid of plots are returned. This paramenter\n        controls the number of columns in that grid.\n\n    subset_phenotype : list, optional  \n        User can subset a list of categories within `phenotype` before plotting.\n\n    subset_groupby : list, optional  \n        User can subset a list of categories within `group_by` before plotting.\n\n    label : list, optional  \n        A list of strings providing the labels for each wedge.\n\n    title : string, optional  \n        If `None`, the title of the pieplot is not plotted.\n\n    colors : list, optional  \n        A sequence of colors through which the pie chart will cycle. If None, will use the \n        colors in the currently active cycle.\n\n    legend : bool, optional  \n        If True, color legends are plotted seperately.\n\n    legend_loc: string, optional  \n        Place a legend on the Axes.\n\n    autopct : None or str or callable, optional  \n        If not None, is a string or function used to label the wedges with their numeric value. \n        The label will be placed inside the wedge. If it is a format string, \n        the label will be fmt % pct. If it is a function, it will be called.\n\n    wedgeprops : dict, optional  \n        Dict of arguments passed to the wedge objects making the pie. For example, you can pass in \n        wedgeprops = {'linewidth': 3} to set the width of the wedge border lines equal to 3. \n        For more details, look at the doc/arguments of the wedge object. By default clip_on=False.\n\n    return_data : bool, optional  \n        Returns the data used for plotting.\n\n    **kwargs :  \n        Keyword arguments to pass on to `matplotlib.pyplot.pie`.\n\nReturns:  \n    Returns data used for plotting if `return_data = True`\n\nExample:\n```python\n    # pie plot showing stromal tumor content among the different samples\n    sm.pl.pie (adata, phenotype='Tumor_Stroma', group_by='imageid', \n               autopct='%1.1f%%',\n               textprops={'fontsize': 8, 'color': '#1d3557', 'fontweight': 'bold'},\n               ncols=5, label=None, title=None, \n               colors=['#a8dadc','#e63946'], \n               wedgeprops = {'linewidth': 0.8})\n```\n    \"\"\"\n\n\n    # convert subset into list\n    if subset_phenotype is not None:\n        if isinstance (subset_phenotype, str): \n            subset_phenotype = [subset_phenotype]\n    if subset_groupby is not None:\n        if isinstance (subset_groupby, str):\n            subset_groupby = [subset_groupby]\n\n    # create copy of the required data\n    if group_by is not None:\n        data = adata.obs[[phenotype,group_by]]\n    else:\n        data = adata.obs[[phenotype]]\n\n    # subset data if needed\n    if subset_groupby is not None:\n        data = data[data[group_by].isin(subset_groupby)]\n        data[group_by] = data[group_by].astype('str').astype('category')\n        data[group_by] = data[group_by].cat.reorder_categories(subset_groupby)\n        data = data.sort_values(group_by)\n    if subset_phenotype is not None:\n        data = data[data[phenotype].isin(subset_phenotype)]\n        data[phenotype] = data[phenotype].astype('str').astype('category')      \n        data[phenotype] = data[phenotype].cat.reorder_categories(subset_phenotype)\n        data = data.sort_values(phenotype)\n    if group_by and phenotype is not None:\n        data = data.sort_values([phenotype, group_by])\n\n\n    # calculate the proportion\n    if group_by is None:\n        prop = data[phenotype].value_counts().reset_index(inplace=False)\n        prop.columns = [phenotype, 'value']\n        prop['group_by'] = phenotype\n        labels = np.unique(prop[phenotype])\n\n    else:\n        # if group_by is provided\n        prop = pd.DataFrame(data.groupby([group_by,phenotype]).size()).reset_index(inplace=False)\n        prop.columns = ['group_by',phenotype,'value']\n        labels = np.unique(prop[phenotype])\n        #\n        if ncols is not None:\n            g = prop.groupby('group_by')\n            rows = int(np.ceil(len(g)/ncols))\n        else:\n            g = prop.groupby('group_by')\n            rows = 1\n            ncols = len(g)\n\n    # remove label if requested \n    if label == 'auto':\n        label = labels\n    elif label is None:\n        label = None\n    else:\n        label = label\n\n\n    # plot\n    if group_by is None:\n        fig, ax = plt.subplots()\n        ax.pie(prop.value, labels=label,colors=colors, wedgeprops = wedgeprops)\n        #ax.pie(prop.value, labels=label,colors=colors, wedgeprops = wedgeprops, **kwargs)\n        if title is None:\n            pass\n        else:\n            ax.set_title(phenotype)\n    else:\n        # plot the figure\n        # Ground work for removing unwanted axes\n        total_axes = list(range(ncols * rows))\n        required_axes = list(range(len(np.unique(prop['group_by']))))\n        final_axes = list(set(total_axes) ^ set(required_axes))      \n        # Plot\n        fig, axes = plt.subplots(ncols=ncols, nrows=rows)\n        for (c, grp), ax in zip(g, axes.flat):\n            ax.pie(grp.value, labels=label, colors=colors, wedgeprops =wedgeprops)\n            #ax.pie(grp.value, labels=label, colors=colors, wedgeprops = wedgeprops, **kwargs)\n            if title is None:\n                pass\n            else:\n                ax.set_title(c)        \n        # removing unwanted axis\n        for i in final_axes:\n            fig.delaxes(axes.flatten()[i])\n\n        if legend is True:\n            plt.legend(labels, loc=legend_loc, framealpha=1)\n\n    plt.show()\n\n\n    # return data\n    if return_data is True:\n        return prop\n</code></pre>"},{"location":"Functions/pl/spatial_distance/","title":"spatial_distance","text":"<p>Short Description</p> <p><code>sm.pl.spatial_distance</code>: The function allows users to visualize the average shortest distance between phenotypes of interest. Run <code>sm.tl.spatial_distance</code> before running this function.</p>"},{"location":"Functions/pl/spatial_distance/#scimap.plotting._spatial_distance--function","title":"Function","text":""},{"location":"Functions/pl/spatial_distance/#scimap.plotting._spatial_distance.spatial_distance","title":"<code>spatial_distance(adata, spatial_distance='spatial_distance', phenotype='phenotype', imageid='imageid', log=False, method='heatmap', heatmap_summarize=True, heatmap_na_color='grey', heatmap_cmap='vlag_r', heatmap_row_cluster=False, heatmap_col_cluster=False, heatmap_standard_scale=0, distance_from=None, distance_to=None, x_axis=None, y_axis=None, facet_by=None, plot_type=None, return_data=False, subset_col=None, subset_value=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData object</p> required <code>spatial_distance</code> <p>string, optional In order to locate the spatial_distance data within the AnnData object please provide the output label/columnname of <code>sm.tl.spatial_distance</code> function.</p> <code>'spatial_distance'</code> <code>phenotype</code> <p>string, required Column name of the column containing the phenotype information. It could also be any categorical assignment given to single cells.</p> <code>'phenotype'</code> <code>imageid</code> <p>string, optional Column name of the column containing the image id.</p> <code>'imageid'</code> <code>log</code> <p>bool, optional Convert distance to log scale.</p> <code>False</code> <code>method</code> <p>string, optional Three options are available. 1) heatmap - generates a heatmap of average shortest distance between all phenotypes. 2) numeric - can be used to generate boxplot, violin plot etc between a given set of phenotypes. 3) distribution - can be used to generate distribution plots between a given set of phenotypes.</p> <code>'heatmap'</code> <code>heatmap_summarize</code> <p>bool, optional In the event multiple images are present in the dataset, True allows to calculate the average across all the images.</p> <code>True</code> <code>heatmap_na_color</code> <p>string, optional Color for NA values within the heatmap.</p> <code>'grey'</code> <code>heatmap_cmap</code> <p>string, optional Color map to use for continous variables. Can be a name or a Colormap instance (e.g. 'magma', 'viridis').</p> <code>'vlag_r'</code> <code>heatmap_row_cluster</code> <p>bool, optional Cluster Rows.</p> <code>False</code> <code>heatmap_col_cluster</code> <p>bool, optional Cluster Columns.</p> <code>False</code> <code>heatmap_standard_scale</code> <p>int, optional Either 0 (rows) or 1 (columns). Whether or not to standardize that dimension, meaning for each row or column, subtract the minimum and divide each by its maximum.</p> <code>0</code> <code>distance_from</code> <p>string, optional In the event of using method = 'numeric' or 'distribution', this argument is required. Pass a phenotype of interest. If distance_from is provided and distance_to is not provided, the function will plot the average distance from the phenotype of interest to all phenotypes present within the dataset.</p> <code>None</code> <code>distance_to</code> <p>string, optional In the event of using method = 'numeric' or 'distribution', this argument is required. Pass a phenotype of interest. The function will plot the average shortest between two phenotypes of interest (distance_from and distance_to).</p> <code>None</code> <code>x_axis</code> <p>string, optional In the event of using method = 'numeric' or 'distribution', this argument is required. This determines the elements present in the x-axis of the resultant plot. Allowed arguments are: 'group', 'distance', 'imageid'.</p> <code>None</code> <code>y_axis</code> <p>string, optional In the event of using method = 'numeric' or 'distribution', this argument is required. This determines the elements present in the y-axis of the numeric plot and if the user uses the distribution plot this argument is used to overlaying multiple categories within the same distribution plot. Allowed arguments are: 'group', 'distance', 'imageid'.</p> <code>None</code> <code>facet_by</code> <p>string, optional  In the event of using method = 'numeric' or 'distribution', this argument can be used to  generate sub-plots. Allowed arguments are: 'group', 'imageid'.</p> <code>None</code> <code>plot_type</code> <p>string, optional In the event of using method = 'numeric' or 'distribution', this argument is required. For <code>numeric</code> plot, the following options are available: \u201cstrip\u201d, \u201cswarm\u201d, \u201cbox\u201d, \u201cviolin\u201d, \u201cboxen\u201d, \u201cpoint\u201d, \u201cbar\u201d, or \u201ccount\u201d. For <code>distribution</code> plot, the following options are available: \u201chist\u201d, \u201ckde\u201d, \u201cecdf\u201d. The default for <code>numeric</code> plot is 'boxen'. The default for <code>distribution</code> plot is 'kde`.</p> <code>None</code> <code>subset_col</code> <p>string, optional If the users wants to consider only a subset of observations while plotting, this argument in conjuction to <code>subset_value</code> can be used. For example, in the event of a multi-image dataset, the <code>sm.tl.spatial_distance</code> was run on all images but the user is interested in plotting only a subset of images. Pass the name of the column which contains the categories to be subsetted.</p> <code>None</code> <code>subset_value</code> <p>list, optional If the users wants to consider only a subset of observations while plotting, this argument in conjuction to <code>subset_col</code> can be used. Pass a list of the categories to be subsetted.</p> <code>None</code> <code>**kwargs</code> <p>dict Are passed to sns.clustermap. Pass other parameters that works with <code>sns.clustermap</code>, <code>sns.catplot</code> or <code>sns.displot</code> e.g. <code>linecolor='black'</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <p>Heatmap or Numeric Plot or Distribution Plot.</p> <pre><code>    # summary heatmap\n    sm.pl.spatial_distance (adata)\n\n    # Heatmap without summarizing the individual images\n    sm.pl.spatial_distance (adata, heatmap_summarize=False,\n    imageid='ImageId')\n\n    # Numeric plot of shortest distance of phenotypes\n    # from tumor cells\n    sm.pl.spatial_distance (adata, method='numeric',\n    distance_from='Tumor CD30+',imageid='ImageId')\n\n    # Distribution plot of shortest distance of phenotypes\n    # from tumor cells\n    sm.pl.spatial_distance (adata, method='distribution',\n    distance_from='Tumor CD30+',imageid='ImageId',\n    x_axis=\"distance\", y_axis=\"imageid\", plot_type=\"kde\")\n\n    # Numeric plot of shortest distance of phenotypes from\n    # tumor cells to M2 Macrophages\n    sm.pl.spatial_distance (adata, method='numeric',\n    distance_from='Tumor CD30+',distance_to = 'M2 Macrophages',\n    imageid='ImageId')\n\n    # Distribution plot of shortest distance of phenotypes from\n    # tumor cells to M2 Macrophages\n    sm.pl.spatial_distance (adata, method='distribution',\n    distance_from='Tumor CD30+',distance_to = 'M2 Macrophages',\n    imageid='ImageId')\n</code></pre> Source code in <code>scimap/plotting/_spatial_distance.py</code> <pre><code>def spatial_distance (adata, spatial_distance='spatial_distance',phenotype='phenotype',imageid='imageid',log=False,\n                      method='heatmap',heatmap_summarize=True,heatmap_na_color='grey',heatmap_cmap='vlag_r',\n                      heatmap_row_cluster=False,heatmap_col_cluster=False,heatmap_standard_scale=0,\n                      distance_from=None,distance_to=None,x_axis = None,y_axis = None,facet_by = None,plot_type = None,\n                      return_data = False, subset_col=None, subset_value=None,\n                      **kwargs):\n\"\"\"\nParameters:\n\n    adata : AnnData object\n\n    spatial_distance : string, optional\n        In order to locate the spatial_distance data within the AnnData object please provide the output\n        label/columnname of `sm.tl.spatial_distance` function.\n\n    phenotype : string, required\n        Column name of the column containing the phenotype information.\n        It could also be any categorical assignment given to single cells.\n\n    imageid : string, optional\n        Column name of the column containing the image id.\n\n    log : bool, optional\n        Convert distance to log scale.\n\n    method : string, optional\n        Three options are available.\n        1) heatmap - generates a heatmap of average shortest distance between all phenotypes.\n        2) numeric - can be used to generate boxplot, violin plot etc between a given set of phenotypes.\n        3) distribution - can be used to generate distribution plots between a given set of phenotypes.\n\n    heatmap_summarize : bool, optional\n        In the event multiple images are present in the dataset, True allows to calculate the\n        average across all the images.\n\n    heatmap_na_color : string, optional\n        Color for NA values within the heatmap.\n\n    heatmap_cmap : string, optional\n        Color map to use for continous variables.\n        Can be a name or a Colormap instance (e.g. 'magma', 'viridis').\n\n    heatmap_row_cluster : bool, optional\n        Cluster Rows.\n\n    heatmap_col_cluster : bool, optional\n        Cluster Columns.\n\n    heatmap_standard_scale : int, optional\n        Either 0 (rows) or 1 (columns). Whether or not to standardize that dimension,\n        meaning for each row or column, subtract the minimum and divide each by its maximum.\n\n    distance_from : string, optional\n        In the event of using method = 'numeric' or 'distribution', this argument is required.\n        Pass a phenotype of interest. If distance_from is provided and distance_to is not provided,\n        the function will plot the average distance from the phenotype of interest to all\n        phenotypes present within the dataset.\n\n    distance_to : string, optional\n        In the event of using method = 'numeric' or 'distribution', this argument is required.\n        Pass a phenotype of interest. The function will plot the average shortest between two phenotypes of\n        interest (distance_from and distance_to).\n\n    x_axis : string, optional\n        In the event of using method = 'numeric' or 'distribution', this argument is required.\n        This determines the elements present in the x-axis of the resultant plot.\n        Allowed arguments are: 'group', 'distance', 'imageid'.\n\n    y_axis : string, optional\n        In the event of using method = 'numeric' or 'distribution', this argument is required.\n        This determines the elements present in the y-axis of the numeric plot and if the user uses the distribution\n        plot this argument is used to overlaying multiple categories within the same distribution plot.\n        Allowed arguments are: 'group', 'distance', 'imageid'.\n\n    facet_by : string, optional\n         In the event of using method = 'numeric' or 'distribution', this argument can be used to\n         generate sub-plots. Allowed arguments are: 'group', 'imageid'.\n\n    plot_type : string, optional\n        In the event of using method = 'numeric' or 'distribution', this argument is required.\n        For `numeric` plot, the following options are available: \u201cstrip\u201d, \u201cswarm\u201d, \u201cbox\u201d, \u201cviolin\u201d, \u201cboxen\u201d, \u201cpoint\u201d, \u201cbar\u201d, or \u201ccount\u201d.\n        For `distribution` plot, the following options are available: \u201chist\u201d, \u201ckde\u201d, \u201cecdf\u201d.\n        The default for `numeric` plot is 'boxen'.\n        The default for `distribution` plot is 'kde`.\n\n    subset_col : string, optional\n        If the users wants to consider only a subset of observations while plotting, this argument in conjuction to\n        `subset_value` can be used.\n        For example, in the event of a multi-image dataset, the `sm.tl.spatial_distance` was run on all images\n        but the user is interested in plotting only a subset of images. Pass the name of the column which contains\n        the categories to be subsetted.\n\n    subset_value : list, optional\n        If the users wants to consider only a subset of observations while plotting, this argument in conjuction to\n        `subset_col` can be used. Pass a list of the categories to be subsetted.\n\n    **kwargs : dict\n        Are passed to sns.clustermap. Pass other parameters that works with `sns.clustermap`, `sns.catplot` or `sns.displot`\n        e.g. `linecolor='black'`.\n\nReturns:\n    Heatmap or Numeric Plot or Distribution Plot.\n\nExample:\n```python\n    # summary heatmap\n    sm.pl.spatial_distance (adata)\n\n    # Heatmap without summarizing the individual images\n    sm.pl.spatial_distance (adata, heatmap_summarize=False,\n    imageid='ImageId')\n\n    # Numeric plot of shortest distance of phenotypes\n    # from tumor cells\n    sm.pl.spatial_distance (adata, method='numeric',\n    distance_from='Tumor CD30+',imageid='ImageId')\n\n    # Distribution plot of shortest distance of phenotypes\n    # from tumor cells\n    sm.pl.spatial_distance (adata, method='distribution',\n    distance_from='Tumor CD30+',imageid='ImageId',\n    x_axis=\"distance\", y_axis=\"imageid\", plot_type=\"kde\")\n\n    # Numeric plot of shortest distance of phenotypes from\n    # tumor cells to M2 Macrophages\n    sm.pl.spatial_distance (adata, method='numeric',\n    distance_from='Tumor CD30+',distance_to = 'M2 Macrophages',\n    imageid='ImageId')\n\n    # Distribution plot of shortest distance of phenotypes from\n    # tumor cells to M2 Macrophages\n    sm.pl.spatial_distance (adata, method='distribution',\n    distance_from='Tumor CD30+',distance_to = 'M2 Macrophages',\n    imageid='ImageId')\n```\n    \"\"\"\n\n\n    # set color for heatmap\n    cmap_updated = matplotlib.cm.get_cmap(heatmap_cmap)\n    cmap_updated.set_bad(color=heatmap_na_color)\n\n\n    # Copy the spatial_distance results from anndata object\n    try:\n        diatance_map = adata.uns[spatial_distance].copy()\n    except KeyError:\n        raise ValueError('spatial_distance not found- Please run sm.tl.spatial_distance first')\n\n    # subset the data if user requests\n    if subset_col is not None:\n        if isinstance(subset_value, str):\n            subset_value = [subset_value]\n        # find the cell names to be subsetted out\n        obs = adata.obs[[subset_col]]\n        cells_to_subset = obs[obs[subset_col].isin(subset_value)].index\n\n        # subset the diatance_map\n        diatance_map = diatance_map.loc[diatance_map.index.intersection(cells_to_subset)]\n        #diatance_map = diatance_map.loc[cells_to_subset]\n\n\n    # Convert distance to log scale if user requests\n    if log is True:\n        diatance_map = np.log1p(diatance_map)\n\n    # Method\n    if method=='heatmap':\n        if heatmap_summarize is True:\n            # create the necessary data\n            data = pd.DataFrame({'phenotype': adata.obs[phenotype]})\n            data = pd.merge(data, diatance_map, how='outer',left_index=True, right_index=True) # merge with the distance map\n            k = data.groupby(['phenotype']).mean() # collapse the whole dataset into mean expression\n            d = k[k.index]\n        else:\n            # create new naming scheme for the phenotypes\n            non_summary = pd.DataFrame({'imageid': adata.obs[imageid], 'phenotype': adata.obs[phenotype]})\n            non_summary['imageid'] = non_summary['imageid'].astype(str) # convert the column to string\n            non_summary['phenotype'] = non_summary['phenotype'].astype(str) # convert the column to string\n            non_summary['image_phenotype'] = non_summary['imageid'].str.cat(non_summary['phenotype'],sep=\"_\")\n            # Merge distance map with phenotype\n            data = pd.DataFrame(non_summary[['image_phenotype']])\n            data = pd.merge(data, diatance_map, how='outer',left_index=True, right_index=True)\n            k = data.groupby(['image_phenotype']).mean()\n            d = k.sort_index(axis=1)\n        # Generate the heatmap\n        mask = d.isnull() # identify the NAN's for masking \n        d = d.fillna(0) # replace nan's with 0 so that clustering will work\n        # Heatmap\n        sns.clustermap(d, cmap=heatmap_cmap, row_cluster=heatmap_row_cluster,\n                       col_cluster=heatmap_col_cluster, mask=mask,\n                       standard_scale=heatmap_standard_scale, **kwargs)\n    else:\n\n        # condition-1\n        if distance_from is None and distance_to is None:\n            raise ValueError('Please include distance_from and/or distance_to parameters to use this method')\n\n        # condition-2\n        if distance_from is None and distance_to is not None:\n            raise ValueError('Please `distance_from` parameters to use this method')\n\n        # condition-3\n        if distance_to is not None:\n            # convert input to list if needed\n            if isinstance(distance_to, str):\n                distance_to = [distance_to]\n\n        # Start\n        pheno_df = pd.DataFrame({'imageid': adata.obs[imageid], 'phenotype': adata.obs[phenotype]}) #image id and phenotype\n        data = pd.merge(pheno_df, diatance_map, how='outer',left_index=True, right_index=True) # merge with the distance map\n        data = data[data['phenotype'] == distance_from] # subset the pheno of interest\n\n        if distance_to is not None:\n            data = data[distance_to] # drop columns that are not requested in distance_to\n        else:\n            data = data.drop(['phenotype','imageid'], axis=1) # drop the phenotype column before stacking\n\n        d = data.stack().reset_index() # collapse everything to one column\n        d.columns = ['cellid', 'group', 'distance']\n        d = pd.merge(d, pheno_df, left_on='cellid', right_index=True) # bring back the imageid and phenotype\n\n        # Convert columns to str\n        for col in ['imageid', 'group','phenotype']:\n            d[col] = d[col].astype(str)\n\n        # Convert columns to categorical so that it drops unused categories\n        for col in ['imageid', 'group','phenotype']:\n            d[col] = d[col].astype('category')\n\n        # re arrange the order based on from and to list provided\n        if distance_to is not None:\n            d['group'] = d['group'].cat.reorder_categories(distance_to)\n            d = d.sort_values('group')\n\n        # Plotting\n        if method=='numeric':\n            if x_axis is None and y_axis is None and facet_by is None and plot_type is None:\n                sns.catplot(data=d, x=\"distance\", y=\"group\", col=\"imageid\", kind=\"boxen\", **kwargs)\n            else:\n                sns.catplot(data=d, x=x_axis, y=y_axis, col=facet_by, kind=plot_type, **kwargs)\n\n        if method=='distribution':\n            if x_axis is None and y_axis is None and facet_by is None and plot_type is None:\n                sns.displot(data=d, x=\"distance\", hue=\"imageid\",  col=\"group\", kind=\"kde\", **kwargs)\n            else:\n                sns.displot(data=d, x=x_axis, hue=y_axis, col=facet_by, kind=plot_type,**kwargs)\n\n    # return\n    if return_data is True:\n        return d\n</code></pre>"},{"location":"Functions/pl/spatial_interaction/","title":"spatial_interaction","text":"<p>Short Description</p> <p><code>sm.pl.spatial_interaction</code>: The function allows users to plot a heatmap to visualize spatial interaction output.  The intensity represents abundance of co-occurrence (scaled) observed and blank regions represent non-significant results.</p>"},{"location":"Functions/pl/spatial_interaction/#scimap.plotting._spatial_interaction--function","title":"Function","text":""},{"location":"Functions/pl/spatial_interaction/#scimap.plotting._spatial_interaction.spatial_interaction","title":"<code>spatial_interaction(adata, spatial_interaction='spatial_interaction', summarize_plot=True, p_val=0.05, row_cluster=False, col_cluster=False, cmap='vlag', nonsig_color='grey', subset_phenotype=None, subset_neighbour_phenotype=None, binary_view=False, return_data=False, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData object</p> required <code>spatial_interaction</code> <p>string, optional In order to locate the spatial_interaction data within the AnnData object please provide the output  label/columnname of <code>sm.tl.spatial_interaction</code> function.</p> <code>'spatial_interaction'</code> <code>summarize_plot</code> <p>bool, optional In the event of analyzing multiple images, this argument allows users to plot the average cell-cell interaction across all images.</p> <code>True</code> <code>p_val</code> <p>float, optional P-value cut-off above which interactions are not considered significant.</p> <code>0.05</code> <code>row_cluster</code> <p>bool, optional Cluster Rows.</p> <code>False</code> <code>col_cluster</code> <p>bool, optional Cluster Columns.</p> <code>False</code> <code>subset_phenotype</code> <p>list, optional If user requires to visualize a subset of phenotypes, it can be passed here.  e.g.  <code>subset_phenotype = ['celltype_A', 'celltype_B']</code>.</p> <code>None</code> <code>subset_neighbour_phenotype</code> <p>list, optional If user requires to visualize a subset of interacting phenotypes, it can be passed here.  e.g.  <code>subset_neighbour_phenotype = ['celltype_C', 'celltype_D']</code>.</p> <code>None</code> <code>cmap</code> <p>string, optional Color map to use for continous variables.  Can be a name or a Colormap instance (e.g. 'magma', 'viridis').</p> <code>'vlag'</code> <code>nonsig_color</code> <p>string, optional Color for non-significant interactions (Interactions above the P-value cut-off will use this color).</p> <code>'grey'</code> <code>binary_view</code> <p>bool, optional Removes the intensity of intreaction and plots significant interactions and avoidance in a binary format.</p> <code>False</code> <code>return_data</code> <p>bool, optional When True, return the data used for plotting.</p> <code>False</code> <code>**kwargs</code> <p>Pass other parameters that works with <code>sns.clustermap</code>. e.g. <code>linecolor='black'</code></p> <code>{}</code> <pre><code>    # spatial_interaction heatmap for a single image\n    sm.pl.spatial_interaction(adata, summarize_plot=True, \n    row_cluster=True, linewidths=0.75, linecolor='black')\n\n    # spatial_interaction heatmap for multiple images\n    sns.set(font_scale=0.6)\n    sm.pl.spatial_interaction(adata, summarize_plot=False, \n    row_cluster=True, col_cluster=True, yticklabels=True)\n</code></pre> Source code in <code>scimap/plotting/_spatial_interaction.py</code> <pre><code>def spatial_interaction (adata, spatial_interaction='spatial_interaction',\n                         summarize_plot=True, p_val=0.05,\n                         row_cluster=False, col_cluster=False,\n                         cmap = 'vlag', nonsig_color='grey', \n                         subset_phenotype=None, subset_neighbour_phenotype=None,\n                         binary_view=False, return_data=False, **kwargs):\n\"\"\"\nParameters:\n    adata : AnnData object\n\n    spatial_interaction : string, optional  \n        In order to locate the spatial_interaction data within the AnnData object please provide the output \n        label/columnname of `sm.tl.spatial_interaction` function.\n\n    summarize_plot : bool, optional  \n        In the event of analyzing multiple images, this argument allows users to\n        plot the average cell-cell interaction across all images.\n\n    p_val : float, optional  \n        P-value cut-off above which interactions are not considered significant.\n\n    row_cluster : bool, optional  \n        Cluster Rows.\n\n    col_cluster : bool, optional  \n        Cluster Columns.\n\n    subset_phenotype : list, optional  \n        If user requires to visualize a subset of phenotypes, it can be passed here. \n        e.g.  `subset_phenotype = ['celltype_A', 'celltype_B']`.\n\n    subset_neighbour_phenotype : list, optional  \n        If user requires to visualize a subset of interacting phenotypes, it can be passed here. \n        e.g.  `subset_neighbour_phenotype = ['celltype_C', 'celltype_D']`.\n\n    cmap : string, optional  \n        Color map to use for continous variables. \n        Can be a name or a Colormap instance (e.g. 'magma', 'viridis').\n\n    nonsig_color : string, optional  \n        Color for non-significant interactions (Interactions above the P-value cut-off will use this color).\n\n    binary_view : bool, optional  \n        Removes the intensity of intreaction and plots significant interactions and avoidance in a binary format.\n\n    return_data : bool, optional  \n        When True, return the data used for plotting.\n\n    **kwargs : key:value pairs  \n        Pass other parameters that works with `sns.clustermap`. e.g. `linecolor='black'`\n\nExample:\n```python\n    # spatial_interaction heatmap for a single image\n    sm.pl.spatial_interaction(adata, summarize_plot=True, \n    row_cluster=True, linewidths=0.75, linecolor='black')\n\n    # spatial_interaction heatmap for multiple images\n    sns.set(font_scale=0.6)\n    sm.pl.spatial_interaction(adata, summarize_plot=False, \n    row_cluster=True, col_cluster=True, yticklabels=True)\n```\n    \"\"\"\n\n    # set color for heatmap\n    #cmap_updated = copy.copy(matplotlib.cm.get_cmap(cmap))\n    cmap_updated = matplotlib.cm.get_cmap(cmap)\n    cmap_updated.set_bad(color=nonsig_color)\n\n\n    # Copy the interaction results from anndata object\n    try:\n        interaction_map = adata.uns[spatial_interaction].copy()\n    except KeyError:\n        raise ValueError('spatial_interaction not found- Please run sm.tl.spatial_interaction first')\n\n    # subset the data if user requests\n    if subset_phenotype is not None:\n        if isinstance(subset_phenotype, str):\n            subset_phenotype = [subset_phenotype]\n        # subset the phenotype\n        interaction_map = interaction_map[interaction_map['phenotype'].isin(subset_phenotype)]\n\n    if subset_neighbour_phenotype is not None:\n        if isinstance(subset_neighbour_phenotype, str):\n            subset_neighbour_phenotype = [subset_neighbour_phenotype]\n        # subset the phenotype\n        interaction_map = interaction_map[interaction_map['neighbour_phenotype'].isin(subset_neighbour_phenotype)]\n\n    # Seperate Interaction intensity from P-value\n    p_value = interaction_map.filter(regex='pvalue_')    \n    p_val_df = pd.concat([interaction_map[['phenotype','neighbour_phenotype']], p_value], axis=1, join='outer')\n    p_val_df = p_val_df.set_index(['phenotype','neighbour_phenotype'])\n    interaction_map = interaction_map[interaction_map.columns.difference(p_value.columns)]\n    interaction_map = interaction_map.set_index(['phenotype','neighbour_phenotype'])\n\n    # Binarize the values if user requests\n    if binary_view == True:\n        interaction_map[interaction_map &gt; 0] = 1\n        interaction_map[interaction_map &lt;= 0] = -1\n\n\n    if summarize_plot == True:\n        # convert first two columns to multi-index column\n        #interaction_map = interaction_map.set_index(['phenotype','neighbour_phenotype'])\n        #p_val_df = p_val_df.set_index(['phenotype','neighbour_phenotype'])\n\n        # If multiple images are present, take the average of interactions\n        interaction_map['mean'] = interaction_map.mean(axis=1).values\n        interaction_map = interaction_map[['mean']] # keep only the mean column\n        interaction_map = interaction_map['mean'].unstack()\n        # Do the same for P-values\n        p_val_df['mean'] = p_val_df.mean(axis=1).values\n        p_val_df = p_val_df[['mean']] # keep only the mean column\n        # set the P-value threshold\n        p_val_df.loc[p_val_df[p_val_df['mean'] &gt; p_val].index,'mean'] = np.NaN       \n        p_val_df = p_val_df['mean'].unstack()\n\n        # change to the order passed in subset\n        if subset_phenotype is not None:\n            interaction_map = interaction_map.reindex(subset_phenotype)\n            p_val_df = p_val_df.reindex(subset_phenotype)\n        if subset_neighbour_phenotype is not None:\n            interaction_map = interaction_map.reindex(columns=subset_neighbour_phenotype)\n            p_val_df = p_val_df.reindex(columns=subset_neighbour_phenotype)\n\n        # Plotting heatmap\n        mask = p_val_df.isnull() # identify the NAN's for masking \n        im = interaction_map.fillna(0) # replace nan's with 0 so that clustering will work\n        # heatmap\n        sns.clustermap(im, cmap=cmap, row_cluster=row_cluster, col_cluster=col_cluster,  mask=mask, **kwargs)\n\n    else:\n        if len(interaction_map.columns) &lt; 2:\n            raise ValueError('Data for only a single image is available please set summarize_plot=True and try again')\n        # convert first two columns to multi-index column\n        #interaction_map = interaction_map.set_index(['phenotype','neighbour_phenotype'])\n        #p_val_df = p_val_df.set_index(['phenotype','neighbour_phenotype'])\n\n        # P value threshold\n        p_val_df = p_val_df.apply(lambda x: np.where(x &gt; p_val,np.nan,x))\n\n        # Remove rows that are all nan\n        idx = p_val_df.index[p_val_df.isnull().all(1)] # Find all nan rows\n        interaction_map = interaction_map.loc[interaction_map.index.difference(idx)] # clean intensity data\n        p_val_df = p_val_df.loc[p_val_df.index.difference(idx)] # clean p-value data\n\n        # order the plot as needed\n        if subset_phenotype or subset_neighbour_phenotype is not None:\n            interaction_map.reset_index(inplace=True)\n            p_val_df.reset_index(inplace=True)\n            if subset_phenotype is not None:\n                interaction_map['phenotype'] = interaction_map['phenotype'].astype('category')\n                interaction_map['phenotype'] = interaction_map['phenotype'].cat.reorder_categories(subset_phenotype)\n                interaction_map = interaction_map.sort_values('phenotype')\n                # Do same for Pval\n                p_val_df['phenotype'] = p_val_df['phenotype'].astype('category')\n                p_val_df['phenotype'] = p_val_df['phenotype'].cat.reorder_categories(subset_phenotype)\n                p_val_df = p_val_df.sort_values('phenotype')\n            if subset_neighbour_phenotype is not None:\n                interaction_map['neighbour_phenotype'] = interaction_map['neighbour_phenotype'].astype('category')\n                interaction_map['neighbour_phenotype'] = interaction_map['neighbour_phenotype'].cat.reorder_categories(subset_neighbour_phenotype)\n                interaction_map = interaction_map.sort_values('neighbour_phenotype')\n                # Do same for Pval\n                p_val_df['neighbour_phenotype'] = p_val_df['neighbour_phenotype'].astype('category')\n                p_val_df['neighbour_phenotype'] = p_val_df['neighbour_phenotype'].cat.reorder_categories(subset_neighbour_phenotype)\n                p_val_df = p_val_df.sort_values('neighbour_phenotype')\n            if subset_phenotype and subset_neighbour_phenotype is not None:\n                 interaction_map = interaction_map.sort_values(['phenotype', 'neighbour_phenotype'])\n                 p_val_df = p_val_df.sort_values(['phenotype', 'neighbour_phenotype'])\n\n            # convert the data back into multi-index\n            interaction_map = interaction_map.set_index(['phenotype', 'neighbour_phenotype'])\n            p_val_df = p_val_df.set_index(['phenotype', 'neighbour_phenotype'])\n\n        # Plotting heatmap\n        mask = p_val_df.isnull() # identify the NAN's for masking \n        im = interaction_map.fillna(0) # replace nan's with 0 so that clustering will work\n        mask.columns = im.columns\n\n        # covert the first two columns into index\n        # Plot\n        sns.clustermap(im, cmap=cmap, row_cluster=row_cluster, col_cluster=col_cluster, mask=mask, **kwargs)\n\n    if return_data is True:\n        # perpare data for export\n        map_data = interaction_map.copy()\n        p_val_data = mask.copy()\n        map_data.reset_index(inplace=True)\n        p_val_data.reset_index(inplace=True)\n        # remove the first two colums\n        map_data = map_data.drop(['phenotype','neighbour_phenotype'],axis=1)\n        p_val_data = p_val_data.drop(['phenotype','neighbour_phenotype'],axis=1)\n        p_val_data.columns = map_data.columns\n        # remove the mased values\n        final_Data = map_data.where(~p_val_data, other=np.nan)\n        final_Data.index = interaction_map.index\n        return final_Data\n</code></pre>"},{"location":"Functions/pl/spatial_pscore/","title":"spatial_pscore","text":"<p>Short Description</p> <p><code>sm.pl.spatial_pscore</code>: The function allows users to plot proximity volume and density scores.  Run <code>sm.tl.spatial_pscore</code> before running this function. </p>"},{"location":"Functions/pl/spatial_pscore/#scimap.plotting._spatial_pscore--function","title":"Function","text":""},{"location":"Functions/pl/spatial_pscore/#scimap.plotting._spatial_pscore.spatial_pscore","title":"<code>spatial_pscore(adata, label='spatial_pscore', plot_score='both', order_xaxis=None, color='grey', **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData object</p> required <code>label</code> <p>string, optional The label under which the data is saved. This is the same <code>label</code> parameter  passed when running the <code>sm.tl.spatial_pscore</code> function.</p> <code>'spatial_pscore'</code> <code>plot_score</code> <p>string, optional Three option are available.  A) Plot only the Proximity Density by passing in <code>Proximity Density</code> B) Plot only the Proximity Volume by passing in <code>Proximity Volume</code> C) Plot both side by side by passing <code>both</code></p> <code>'both'</code> <code>order_xaxis</code> <p>list, optional If the user wants to re-order the x-axis, pass all the names in the x-axis in the desired order as a list. e.g. ['ROI2', 'ROI4', \"ROI1\"] </p> <code>None</code> <code>color</code> <p>string, optional Color of the bars.</p> <code>'grey'</code> <code>**kwargs</code> <p>string Other arguments that can be passed into <code>sns.barplot</code></p> <code>{}</code> <pre><code>    # Plot only `Proximity Volume` scores\n    sm.pl.spatial_pscore (adata, color='Black', \n    plot_score='Proximity Volume', order_xaxis=['ROI2', 'ROI4', \"ROI1\"])\n</code></pre> Source code in <code>scimap/plotting/_spatial_pscore.py</code> <pre><code>def spatial_pscore (adata, label='spatial_pscore', plot_score='both', \n                    order_xaxis = None,\n                    color='grey', **kwargs):\n\"\"\"\nParameters:\n\n    adata : AnnData object\n\n    label : string, optional  \n        The label under which the data is saved. This is the same `label` parameter \n        passed when running the `sm.tl.spatial_pscore` function.\n\n    plot_score : string, optional  \n        Three option are available. \n        A) Plot only the *Proximity Density* by passing in `Proximity Density`  \n        B) Plot only the *Proximity Volume* by passing in `Proximity Volume`  \n        C) Plot both side by side by passing `both`\n\n    order_xaxis : list, optional  \n        If the user wants to re-order the x-axis, pass all the names in the x-axis\n        in the desired order as a list. e.g. ['ROI2', 'ROI4', \"ROI1\"] \n\n    color : string, optional  \n        Color of the bars.\n\n    **kwargs : string  \n        Other arguments that can be passed into `sns.barplot`\n\nExample:\n```python\n    # Plot only `Proximity Volume` scores\n    sm.pl.spatial_pscore (adata, color='Black', \n    plot_score='Proximity Volume', order_xaxis=['ROI2', 'ROI4', \"ROI1\"])\n```\n    \"\"\"\n\n\n    # Isolate the data from anndata object\n    data = adata.uns[label]\n\n    # Order the x-axis if needed\n    if order_xaxis is not None:\n        data = data.reindex(order_xaxis)\n\n\n    # Generate the x and y axis\n    x  = data.index\n    y_pd = data['Proximity Density'].values\n    y_pv = data['Proximity Volume'].values\n\n    # Plot what user requests\n    if plot_score == 'Proximity Density':\n        ax = sns.barplot(x=x, y=y_pd, color=color, **kwargs).set_title('Proximity Density')\n        ax = plt.xticks(rotation=90)\n        plt.tight_layout()\n    if plot_score == 'Proximity Volume':\n        ax = sns.barplot(x=x, y=y_pv, color=color, **kwargs).set_title('Proximity Volume')\n        ax = plt.xticks(rotation=90)\n        plt.tight_layout()\n    if plot_score == 'both':\n        fig, ax = plt.subplots(1,2)\n        sns.barplot(x=x, y=y_pd, color=color, ax=ax[0], **kwargs).set_title('Proximity Density')\n        ax[0].tick_params(axis='x', rotation=90)\n        sns.barplot(x=x, y=y_pv, color=color, ax=ax[1], **kwargs).set_title('Proximity Volume')\n        ax[1].tick_params(axis='x', rotation=90)\n        plt.tight_layout()\n        fig.show()\n</code></pre>"},{"location":"Functions/pl/spatial_scatterPlot/","title":"spatial_scatterPlot","text":"<p>Short Description</p> <p>The scatterPlot function offers a convenient way to generate scatter plots  for visualizing single-cell spatial data. By utilizing this function,  users can effectively visualize the spatial distribution of cells while  overlaying expression levels or categorical columns onto the plot.  This functionality allows for a comprehensive understanding of the  relationship between cell location and specific features of interest  within the dataset.</p>"},{"location":"Functions/pl/spatial_scatterPlot/#scimap.plotting.spatial_scatterPlot--function","title":"Function","text":""},{"location":"Functions/pl/spatial_scatterPlot/#scimap.plotting.spatial_scatterPlot.spatial_scatterPlot","title":"<code>spatial_scatterPlot(adata, colorBy, x_coordinate='X_centroid', y_coordinate='Y_centroid', imageid='imageid', layer=None, subset=None, s=None, ncols=None, alpha=1, dpi=200, fontsize=None, plotLegend=True, cmap='RdBu_r', catCmap='tab20', vmin=None, vmax=None, customColors=None, figsize=(5, 5), invert_yaxis=True, outputDir=None, outputFileName='scimapScatterPlot.png', **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>anndata</code> <p>Pass the <code>adata</code> loaded into memory or a path to the <code>adata</code>  file (.h5ad).</p> required <code>colorBy</code> <code>str</code> required <code>x_coordinate</code> <code>str</code> <p>The column name in <code>spatial feature table</code> that records the X coordinates for each cell.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <code>str</code> <p>The column name in <code>single-cell spatial table</code> that records the Y coordinates for each cell. </p> <code>'Y_centroid'</code> <code>imageid</code> <code>str</code> <p>The column name in <code>spatial feature table</code> that contains the image ID  for each cell. </p> <code>'imageid'</code> <code>layer</code> <code>str or None</code> <p>The layer in <code>adata.layers</code> that contains the expression data to use.  If <code>None</code>, <code>adata.X</code> is used. use <code>raw</code> to use the data stored in <code>adata.raw.X</code>.</p> <code>None</code> <code>subset</code> <code>list or None</code> <p><code>imageid</code> of a single or multiple images to be subsetted for plotting purposes.</p> <code>None</code> <code>s</code> <code>float</code> <p>The size of the markers. </p> <code>None</code> <code>ncols</code> <code>int</code> <p>The number of columns in the final plot when multiple variables are plotted.</p> <code>None</code> <code>alpha</code> <code>float</code> <p>The alpha value of the points (controls opacity).</p> <code>1</code> <code>dpi</code> <code>int</code> <p>The DPI of the figure.</p> <code>200</code> <code>fontsize</code> <code>int</code> <p>The size of the fonts in plot.</p> <code>None</code> <code>plotLegend</code> <code>bool</code> <p>Whether to include a legend. </p> <code>True</code> <code>cmap</code> <code>str</code> <p>The colormap to use for continuous data.</p> <code>'RdBu_r'</code> <code>catCmap</code> <code>str</code> <p>The colormap to use for categorical data.</p> <code>'tab20'</code> <code>vmin</code> <code>float or None</code> <p>The minimum value of the color scale. </p> <code>None</code> <code>vmax</code> <code>float or None</code> <p>The maximum value of the color scale. </p> <code>None</code> <code>customColors</code> <code>dict or None</code> <p>A dictionary mapping color categories to colors. </p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>The size of the figure. Default is (5, 5).</p> <code>(5, 5)</code> <code>invert_yaxis</code> <code>bool</code> <p>Invert the Y-axis of the plot. </p> <code>True</code> <code>outputDir</code> <code>str or None</code> <p>The directory to save the output plot. If None, the plot will not be saved. </p> <code>None</code> <code>outputFileName</code> <code>str</code> <p>The name of the output file. Use desired file format as  suffix (e.g. <code>.png</code> or <code>.pdf</code>). Default is 'scimapScatterPlot.png'.</p> <code>'scimapScatterPlot.png'</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to the matplotlib scatter function.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Plot</code> <code>image</code> <p>If <code>outputDir</code> is provided the plot will saved within the provided outputDir.</p> Example <pre><code>customColors = { 'Unknown' : '#e5e5e5',\n                'CD8+ T' : '#ffd166',\n                'Non T CD4+ cells' : '#06d6a0',\n                'CD4+ T' : '#118ab2',\n                'ECAD+' : '#ef476f',\n                'Immune' : '#073b4c',\n                'KI67+ ECAD+' : '#000000'               \n    }\n\nsm.pl.scatterPlot (adata=core6, \n                 colorBy = ['ECAD', 'phenotype_gator'], \n                 subset = 'unmicst-6_cellMask',\n                 figsize=(4,4),\n                 s=0.5,\n                 plotLegend=True,\n                 fontsize=3,\n                 dpi=300,\n                 vmin=0,\n                 vmax=1,\n                 customColors=customColors,\n                 outputFileName='scimapScatterPlot.svg',\n                 outputDir='/Users/aj/Downloads')\n</code></pre> Source code in <code>scimap/plotting/spatial_scatterPlot.py</code> <pre><code>def spatial_scatterPlot (adata, \n                         colorBy, \n                         x_coordinate='X_centroid',\n                         y_coordinate='Y_centroid',\n                         imageid='imageid',\n                         layer=None,\n                         subset=None,\n                         s=None,\n                         ncols=None,\n                         alpha=1,\n                         dpi=200,\n                         fontsize=None,\n                         plotLegend=True,\n                         cmap='RdBu_r',\n                         catCmap='tab20',\n                         vmin=None,\n                         vmax=None,\n                         customColors=None,\n                         figsize=(5, 5),\n                         invert_yaxis=True,\n                         outputDir=None,\n                         outputFileName='scimapScatterPlot.png',\n                         **kwargs):\n\"\"\"\nParameters:\n    adata (anndata):   \n        Pass the `adata` loaded into memory or a path to the `adata` \n        file (.h5ad).\n\n    colorBy (str):  \n    The column name that will be used for color-coding the points. This can be \n    either markers (data stored in `adata.var`) or observations (data stored in `adata.obs`).\n\n    x_coordinate (str, optional):  \n        The column name in `spatial feature table` that records the\n        X coordinates for each cell.\n\n    y_coordinate (str, optional):  \n        The column name in `single-cell spatial table` that records the\n        Y coordinates for each cell. \n\n    imageid (str, optional):  \n        The column name in `spatial feature table` that contains the image ID \n        for each cell. \n\n    layer (str or None, optional):  \n        The layer in `adata.layers` that contains the expression data to use. \n        If `None`, `adata.X` is used. use `raw` to use the data stored in `adata.raw.X`.\n\n    subset (list or None, optional):  \n        `imageid` of a single or multiple images to be subsetted for plotting purposes.\n\n    s (float, optional):  \n        The size of the markers. \n\n    ncols (int, optional):  \n        The number of columns in the final plot when multiple variables are plotted.\n\n    alpha (float, optional):   \n        The alpha value of the points (controls opacity).\n\n    dpi (int, optional):   \n        The DPI of the figure.\n\n    fontsize (int, optional):    \n        The size of the fonts in plot.\n\n    plotLegend (bool, optional):   \n        Whether to include a legend. \n\n    cmap (str, optional):   \n        The colormap to use for continuous data.\n\n    catCmap (str, optional):   \n        The colormap to use for categorical data.\n\n    vmin (float or None, optional):   \n        The minimum value of the color scale. \n\n    vmax (float or None, optional):   \n        The maximum value of the color scale. \n\n    customColors (dict or None, optional):   \n        A dictionary mapping color categories to colors. \n\n    figsize (tuple, optional):   \n        The size of the figure. Default is (5, 5).\n\n    invert_yaxis (bool, optional):  \n        Invert the Y-axis of the plot. \n\n    outputDir (str or None, optional):   \n        The directory to save the output plot. If None, the plot will not be saved. \n\n    outputFileName (str, optional):   \n        The name of the output file. Use desired file format as \n        suffix (e.g. `.png` or `.pdf`). Default is 'scimapScatterPlot.png'.\n\n    **kwargs:  \n        Additional keyword arguments to be passed to the matplotlib scatter function.\n\n\nReturns:\n    Plot (image):\n        If `outputDir` is provided the plot will saved within the\n        provided outputDir.\n\nExample:\n\n        ```python\n\n        customColors = { 'Unknown' : '#e5e5e5',\n                        'CD8+ T' : '#ffd166',\n                        'Non T CD4+ cells' : '#06d6a0',\n                        'CD4+ T' : '#118ab2',\n                        'ECAD+' : '#ef476f',\n                        'Immune' : '#073b4c',\n                        'KI67+ ECAD+' : '#000000'               \n            }\n\n        sm.pl.scatterPlot (adata=core6, \n                         colorBy = ['ECAD', 'phenotype_gator'], \n                         subset = 'unmicst-6_cellMask',\n                         figsize=(4,4),\n                         s=0.5,\n                         plotLegend=True,\n                         fontsize=3,\n                         dpi=300,\n                         vmin=0,\n                         vmax=1,\n                         customColors=customColors,\n                         outputFileName='scimapScatterPlot.svg',\n                         outputDir='/Users/aj/Downloads')\n\n\n        ```\n\n    \"\"\"\n\n    # Load the andata object\n    if isinstance(adata, str):\n        adata = ad.read(adata)\n    else:\n        adata = adata.copy()\n\n    # subset data if neede\n    if subset is not None:\n        if isinstance (subset, str):\n            subset = [subset]\n        if layer == 'raw':\n            bdata=adata.copy()\n            bdata.X = adata.raw.X\n            bdata = bdata[bdata.obs[imageid].isin(subset)]\n        else:\n            bdata=adata.copy()\n            bdata = bdata[bdata.obs[imageid].isin(subset)]\n    else:\n        bdata=adata.copy()\n\n    # isolate the data\n    if layer is None:\n        data = pd.DataFrame(bdata.X, index=bdata.obs.index, columns=bdata.var.index)\n    elif layer == 'raw':\n        data = pd.DataFrame(bdata.raw.X, index=bdata.obs.index, columns=bdata.var.index)\n    else:\n        data = pd.DataFrame(bdata.layers[layer], index=bdata.obs.index, columns=bdata.var.index)\n\n    # isolate the meta data\n    meta = bdata.obs\n\n    # identify the things to color\n    if isinstance (colorBy, str):\n        colorBy = [colorBy]   \n    # extract columns from data and meta\n    data_cols = [col for col in data.columns if col in colorBy]\n    meta_cols = [col for col in meta.columns if col in colorBy]\n    # combine extracted columns from data and meta\n    colorColumns = pd.concat([data[data_cols], meta[meta_cols]], axis=1)\n\n    # identify the x and y coordinates\n    x = meta[x_coordinate]\n    y = meta[y_coordinate]\n\n\n    # auto identify rows and columns in the grid plot\n    def calculate_grid_dimensions(num_items, num_columns=None):\n\"\"\"\n        Calculates the number of rows and columns for a square grid\n        based on the number of items.\n        \"\"\"\n        if num_columns is None:\n            num_rows_columns = int(math.ceil(math.sqrt(num_items)))\n            return num_rows_columns, num_rows_columns\n        else:\n            num_rows = int(math.ceil(num_items / num_columns))\n            return num_rows, num_columns\n\n    # calculate the number of rows and columns\n    nrows, ncols = calculate_grid_dimensions(len(colorColumns.columns), num_columns = ncols)\n\n\n    # resolve figsize\n    #figsize = (figsize[0]*ncols, figsize[1]*nrows)\n\n    # Estimate point size\n    if s is None:\n        s = (10000 / bdata.shape[0]) / len(colorColumns.columns)\n\n    # Define the categorical colormap (optional)\n    cmap_cat = plt.get_cmap(catCmap)\n\n    # FIIGURE\n    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, dpi=dpi)\n\n    # Flatten the axs array for easier indexing\n    if nrows == 1 and ncols == 1:\n        axs = [axs]  # wrap single subplot in a list\n    else:\n        axs = axs.flatten()\n\n\n    # Loop over the columns of the DataFrame\n    for i, col in enumerate(colorColumns):\n        # Select the current axis\n        ax = axs[i]\n\n        # invert y-axis\n        if invert_yaxis is True:\n            ax.invert_yaxis()\n\n        # Scatter plot for continuous data\n        if colorColumns[col].dtype.kind in 'iufc':\n            scatter = ax.scatter(x=x, y=y, \n                                 c=colorColumns[col], \n                                 cmap=cmap, \n                                 s=s,\n                                 vmin=vmin,\n                                 vmax=vmax,\n                                 linewidths=0,\n                                 alpha=alpha, **kwargs)\n            if plotLegend is True:\n                cbar = plt.colorbar(scatter, ax=ax, pad=0)\n                cbar.ax.tick_params(labelsize=fontsize)\n\n        # Scatter plot for categorical data\n        else:\n            # Get the unique categories in the column\n            categories = colorColumns[col].unique()\n\n            # Map the categories to colors using either the custom colors or the categorical colormap\n            if customColors:\n                colors = [customColors.get(cat, cmap_cat(i)) for i, cat in enumerate(categories)]\n            else:\n                colors = [cmap_cat(i) for i in np.linspace(0, 1, len(categories))]\n\n            # Map the categories to numeric codes for plotting\n            codes = [np.where(categories == cat)[0][0] for cat in colorColumns[col]]\n\n\n            # Plot the scatter plot with categorical colors\n            c = [colors[code] for code in codes]\n            scatter = ax.scatter(x=x, y=y, c=c, s=s, linewidths=0, alpha=alpha, **kwargs)\n            if plotLegend is True:\n                # Create the categorical legend outside the plot\n                handles = [mpatches.Patch(color=colors[i], label=cat) for i, cat in enumerate(categories)]\n                ax.legend(handles=handles, bbox_to_anchor=(1.0, 1.0), loc='upper left', bbox_transform=ax.transAxes, fontsize=fontsize)\n\n        ax.set_title(col) # fontsize=fontsize\n        ax.set_yticklabels([])\n        ax.set_xticklabels([])\n        ax.set_xticks([])\n        ax.set_yticks([])\n\n    # Remove any empty subplots\n    num_plots = len(colorColumns.columns)\n    for i in range(num_plots, nrows * ncols):\n        ax = axs[i]\n        fig.delaxes(ax)\n\n    # Adjust the layout of the subplots grid\n    plt.tick_params(axis='both', labelsize=fontsize)\n    plt.tight_layout()\n\n    # save figure\n    if outputDir is not None:\n        plt.savefig(pathlib.Path(outputDir) / outputFileName, dpi=dpi)\n</code></pre>"},{"location":"Functions/pl/stacked_barplot/","title":"stacked_barplot","text":"<p>Short Description</p> <p><code>sm.pl.stacked_barplot</code>: The function allows users to generate a stacked bar plot of a categorical column.  The function can generate the plots using matplotlib and Plotly libraries. Plotly is browser based and so  it can be used for interactive data exploration.</p>"},{"location":"Functions/pl/stacked_barplot/#scimap.plotting._stacked_barplot--function","title":"Function","text":""},{"location":"Functions/pl/stacked_barplot/#scimap.plotting._stacked_barplot.stacked_barplot","title":"<code>stacked_barplot(adata, x_axis='imageid', y_axis='phenotype', subset_xaxis=None, subset_yaxis=None, order_xaxis=None, order_yaxis=None, method='percent', plot_tool='matplotlib', matplotlib_cmap=None, matplotlib_bbox_to_anchor=(1, 1.02), matplotlib_legend_loc=2, return_data=False, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData Object</p> required <code>x_axis</code> <p>string, required Column name of the data that need to be plotted in the x-axis.</p> <code>'imageid'</code> <code>y_axis</code> <p>string, required Column name of the data that need to be plotted in the y-axis.</p> <code>'phenotype'</code> <code>subset_xaxis</code> <p>list, optional Subset x-axis before plotting. Pass in a list of categories. eg- subset_xaxis = ['ROI_1', 'ROI_5']</p> <code>None</code> <code>subset_yaxis</code> <p>list, optional Subset y-axis before plotting. Pass in a list of categories. eg- subset_yaxis = ['Celltype_A', 'Celltype_B']</p> <code>None</code> <code>order_xaxis</code> <p>list, optional Order the x-axis of the plot as needed. Pass in a list of categories. eg- order_xaxis = ['ROI_5', 'ROI_1'] The default is None and will be plotted based on alphabetic order. Please note that if you change the order, pass all categories, failure to do so will generate NaN's.</p> <code>None</code> <code>order_yaxis</code> <p>list, optional Order the y-axis of the plot as needed. Pass in a list of categories. eg- order_yaxis = ['Celltype_B', 'Celltype_A'] The default is None and will be plotted based on alphabetic order. Please note that if you change the order, pass all categories, failure to do so will generate NaN's.</p> <code>None</code> <code>method</code> <p>string, optional Available options: 'percent' and 'absolute'.  1) Use Percent to plot the percent proportion. 2) Use 'absolute' to plot the plot the absolute number.  </p> <code>'percent'</code> <code>plot_tool</code> <p>string, optional Available options: 'matplotlib' and 'plotly'. 1) matplotlib uses the standard python plotting method 2) plotly opens the plot in a local browser. Advantage is to be able  to hover over the plot and retreive data for plots with large number of categories.</p> <code>'matplotlib'</code> <code>matplotlib_cmap</code> <p>string, optional Colormap to select colors from. If string, load colormap with that name from matplotlib. </p> <code>None</code> <code>matplotlib_bbox_to_anchor</code> <p>tuple, optional Bounding box argument used along with matplotlib_legend_loc to control the legend location when using the matplotlib method.</p> <code>(1, 1.02)</code> <code>matplotlib_legend_loc</code> <p>int, optional Location of legend used along with matplotlib_bbox_to_anchor to control the legend location when using the matplotlib method.</p> <code>2</code> <code>return_data</code> <p>bool, optional When True, return the data used for plotting.</p> <code>False</code> <code>**kwargs</code> <p>Additional keyword arguments passed to: 1) Pandas DataFrame.plot() when using the <code>matplotlib</code> method (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html#pandas.DataFrame.plot)) 2) Plotly.bar() when using the <code>plotly</code> method (https://plotly.com/python-api-reference/generated/plotly.express.bar.html))  </p> <code>{}</code> <p>Returns:</p> Type Description <p>Stacked bar plot. If return_data is set to <code>True</code> also returns a dataframe of the data used for the plot.</p> <pre><code>    # Plot the absolute number of phenotypes using the matplotlib \n    # tool across differnt ROI's\n    # ROI column is `epidermis_roi` and phenotypes are stored under `phenotype`\n\n    sm.pl.stacked_barplot (adata,x_axis='epidermis_roi',y_axis='phenotype',\n                     method='absolute',plot_tool='matplotlib',\n                     figsize=(10, 10))\n\n    # Plot the number of cells normalized to 100% using the plotly \n    # tool across differnt ROI's\n\n    sm.pl.stacked_barplot (adata,x_axis='epidermis_roi',y_axis='phenotype',\n                     method='percent',plot_tool='plotly',\n                     color_discrete_sequence=px.colors.qualitative.Alphabet)\n\n    # Same as above but visualize only a subset of ROI's and a subset of \n    # phenotypes\n    subset_xaxis = ['epidermis_1', 'epidermis_5', 'epidermis_6']\n    subset_yaxis = ['APCs', 'Keratinocytes', 'Macrophages']\n\n    sm.pl.stacked_barplot (adata,x_axis='epidermis_roi',y_axis='phenotype',\n                            subset_xaxis=subset_xaxis,subset_yaxis=subset_yaxis,\n                            method='percent',plot_tool='plotly')\n\n    # Visualize absolute number of phenotypes and return the data into a \n    # dataframe `absolute_number`\n    absolute_number = sm.pl.stacked_barplot (adata,x_axis='epidermis_roi',\n                      y_axis='phenotype', method='absolute',\n                      plot_tool='matplotlib', return_data=True)\n</code></pre> Source code in <code>scimap/plotting/_stacked_barplot.py</code> <pre><code>def stacked_barplot (adata, x_axis='imageid', y_axis='phenotype', subset_xaxis=None, subset_yaxis=None, \n                     order_xaxis=None, order_yaxis=None,\n                     method='percent', plot_tool='matplotlib', matplotlib_cmap=None, \n                     matplotlib_bbox_to_anchor=(1,1.02), matplotlib_legend_loc=2, \n                     return_data=False, **kwargs):\n\"\"\"\nParameters:\n    adata : AnnData Object\n\n    x_axis : string, required  \n        Column name of the data that need to be plotted in the x-axis.\n\n    y_axis : string, required  \n        Column name of the data that need to be plotted in the y-axis.\n\n    subset_xaxis : list, optional  \n        Subset x-axis before plotting. Pass in a list of categories. eg- subset_xaxis = ['ROI_1', 'ROI_5']\n\n    subset_yaxis : list, optional  \n        Subset y-axis before plotting. Pass in a list of categories. eg- subset_yaxis = ['Celltype_A', 'Celltype_B']\n\n    order_xaxis : list, optional  \n        Order the x-axis of the plot as needed. Pass in a list of categories. eg- order_xaxis = ['ROI_5', 'ROI_1']\n        The default is None and will be plotted based on alphabetic order. Please note that if you change the order, pass all categories, failure to do so\n        will generate NaN's.\n\n    order_yaxis : list, optional  \n        Order the y-axis of the plot as needed. Pass in a list of categories. eg- order_yaxis = ['Celltype_B', 'Celltype_A']\n        The default is None and will be plotted based on alphabetic order. Please note that if you change the order, pass all categories, failure to do so\n        will generate NaN's.\n\n    method : string, optional  \n        Available options: 'percent' and 'absolute'. \n        1) Use Percent to plot the percent proportion.  \n        2) Use 'absolute' to plot the plot the absolute number.  \n\n    plot_tool : string, optional  \n        Available options: 'matplotlib' and 'plotly'.  \n        1) matplotlib uses the standard python plotting method  \n        2) plotly opens the plot in a local browser. Advantage is to be able   \n        to hover over the plot and retreive data for plots with large number of categories.\n\n    matplotlib_cmap : string, optional  \n        Colormap to select colors from. If string, load colormap with that name from matplotlib. \n\n    matplotlib_bbox_to_anchor : tuple, optional  \n        Bounding box argument used along with matplotlib_legend_loc to control\n        the legend location when using the matplotlib method.\n\n    matplotlib_legend_loc : int, optional  \n        Location of legend used along with matplotlib_bbox_to_anchor to control\n        the legend location when using the matplotlib method.\n\n    return_data : bool, optional  \n        When True, return the data used for plotting.\n\n    **kwargs : Additional keyword arguments passed to:  \n        1) Pandas DataFrame.plot() when using the `matplotlib` method (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html#pandas.DataFrame.plot))  \n        2) Plotly.bar() when using the `plotly` method (https://plotly.com/python-api-reference/generated/plotly.express.bar.html))  \n\nReturns:  \n    Stacked bar plot. If return_data is set to `True` also returns a dataframe of the data used for the plot.\n\n\nExample:\n```python\n    # Plot the absolute number of phenotypes using the matplotlib \n    # tool across differnt ROI's\n    # ROI column is `epidermis_roi` and phenotypes are stored under `phenotype`\n\n    sm.pl.stacked_barplot (adata,x_axis='epidermis_roi',y_axis='phenotype',\n                     method='absolute',plot_tool='matplotlib',\n                     figsize=(10, 10))\n\n    # Plot the number of cells normalized to 100% using the plotly \n    # tool across differnt ROI's\n\n    sm.pl.stacked_barplot (adata,x_axis='epidermis_roi',y_axis='phenotype',\n                     method='percent',plot_tool='plotly',\n                     color_discrete_sequence=px.colors.qualitative.Alphabet)\n\n    # Same as above but visualize only a subset of ROI's and a subset of \n    # phenotypes\n    subset_xaxis = ['epidermis_1', 'epidermis_5', 'epidermis_6']\n    subset_yaxis = ['APCs', 'Keratinocytes', 'Macrophages']\n\n    sm.pl.stacked_barplot (adata,x_axis='epidermis_roi',y_axis='phenotype',\n                            subset_xaxis=subset_xaxis,subset_yaxis=subset_yaxis,\n                            method='percent',plot_tool='plotly')\n\n    # Visualize absolute number of phenotypes and return the data into a \n    # dataframe `absolute_number`\n    absolute_number = sm.pl.stacked_barplot (adata,x_axis='epidermis_roi',\n                      y_axis='phenotype', method='absolute',\n                      plot_tool='matplotlib', return_data=True)\n\n```\n    \"\"\"\n\n\n    # create the dataframe with details\n    data = pd.DataFrame(adata.obs)[[x_axis,y_axis]].astype(str)\n\n    # subset the data if needed\n    #if subset_data is not None:data = data[data[list(subset_data.keys())[0]].isin(list(subset_data.values())[0])]\n\n    if subset_xaxis is not None:\n        if isinstance(subset_xaxis, str):\n            subset_xaxis = [subset_xaxis]\n        data = data[data[x_axis].isin(subset_xaxis)]\n    if subset_yaxis is not None:\n        if isinstance(subset_yaxis, str):\n            subset_yaxis = [subset_yaxis]\n        data = data[data[y_axis].isin(subset_yaxis)]\n\n\n    # Method: Absolute or Percentile\n    if method == 'percent':\n        total = data.groupby([x_axis,y_axis]).size().unstack().fillna(0).sum(axis=1)\n        rg = pd.DataFrame(data.groupby([x_axis,y_axis]).size().unstack().fillna(0).div(total, axis=0).stack())\n    elif method == 'absolute':\n        rg = pd.DataFrame(data.groupby([x_axis,y_axis]).size().unstack().fillna(0).stack())\n    else:\n        raise ValueError('method should be either percent or absolute')\n\n    # change column name\n    rg.columns = ['count']\n\n    # Add the index as columns in the data frame    \n    rg.reset_index(inplace=True)  \n\n    # re-order the x oy y axis if requested by user\n    if order_xaxis is not None:\n        rg[x_axis] = rg[x_axis].astype('category')\n        rg[x_axis] = rg[x_axis].cat.reorder_categories(order_xaxis)\n        rg = rg.sort_values(x_axis)\n    if order_yaxis is not None:\n        rg[y_axis] = rg[y_axis].astype('category')\n        rg[y_axis] = rg[y_axis].cat.reorder_categories(order_yaxis)\n        rg = rg.sort_values(y_axis)\n    if order_xaxis and order_yaxis is not None:\n        rg = rg.sort_values([x_axis, y_axis])\n\n    pivot_df = rg.pivot(index=x_axis, columns=y_axis, values='count')\n\n    # Plotting tool\n    if plot_tool == 'matplotlib':\n\n        if matplotlib_cmap is None:\n            if len(rg[y_axis].unique()) &lt;= 9:\n                matplotlib_cmap = \"Set1\"        \n            elif len(rg[y_axis].unique()) &gt; 9 and len(rg[y_axis].unique()) &lt;=20:\n                matplotlib_cmap = plt.cm.tab20      #tab20  \n            else:\n                matplotlib_cmap = plt.cm.gist_ncar\n\n        # Plotting\n        # add width if not passed via parameters\n        try:\n            width\n        except NameError:\n            width=0.9\n        # actual plotting   \n        p = pivot_df.plot.bar(stacked=True, cmap=matplotlib_cmap, width=width,  **kwargs)\n        handles, labels = p.get_legend_handles_labels() # for reversing the order of the legend\n        p.legend(reversed(handles), reversed(labels), bbox_to_anchor=matplotlib_bbox_to_anchor, loc=matplotlib_legend_loc)\n\n    elif plot_tool == 'plotly':\n\n        fig = px.bar(rg, x=x_axis, y=\"count\", color=y_axis, **kwargs)\n        fig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)',\n                           'paper_bgcolor': 'rgba(0, 0, 0, 0)'},\n                          xaxis = dict(tickmode='linear') #type = 'category'\n                          )\n        fig.show()\n\n\n    else:\n\n        raise ValueError('plot_tool should be either matplotlib or plotly')\n\n    # Return data\n    if return_data is True:\n        return pivot_df\n</code></pre>"},{"location":"Functions/pl/umap/","title":"umap","text":"<p>Short Description</p> <p><code>sm.pl.umap</code>: The function allows users to generate a scatter plot of the UMAP. </p>"},{"location":"Functions/pl/umap/#scimap.plotting._umap--function","title":"Function","text":""},{"location":"Functions/pl/umap/#scimap.plotting._umap.umap","title":"<code>umap(adata, color=None, use_layer=None, use_raw=False, log=False, label='umap', cmap='vlag', palette=None, alpha=0.8, figsize=(5, 5), s=None, ncols=None, tight_layout=False, return_data=False, save_figure=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData Object  </p> required <code>color</code> <p>list, optional Keys for annotations of observations in <code>adata.obs.columns</code> or genes in <code>adata.var.index</code>. e.g. ['CD3D', 'SOX10'] The default is None.</p> <code>None</code> <code>use_layer</code> <p>string, optional Pass name of any <code>Layer</code> in AnnData. The default is <code>None</code> and <code>adata.X</code> is used.</p> <code>None</code> <code>use_raw</code> <p>bool, optional If set to <code>True</code>, values in <code>adata.raw.X</code> will be used to color the plot. The default is False.</p> <code>False</code> <code>log</code> <p>bool, optional If set to <code>True</code>, the data will natural log transformed using <code>np.log1p()</code> for coloring. The default is False.</p> <code>False</code> <code>label</code> <p>string, optional The <code>label key</code> used when running <code>sm.tl.umap()</code>. The default is 'umap'.</p> <code>'umap'</code> <code>cmap</code> <p>string, optional Color map to use for continous variables. Can be a name or a Colormap  instance (e.g. \"magma\u201d, \"viridis\"). The default is 'vlag'.</p> <code>'vlag'</code> <code>palette</code> <p>dict, optional Colors to use for plotting categorical annotation groups.  It accepts a <code>dict</code> mapping categories to colors.  e.g. <code>palette = {'T cells': '#000000', 'B cells': '#FFF675'}</code>. Auto color will be generated for other categories that are not specified. The default is None.</p> <code>None</code> <code>alpha</code> <p>float, optional blending value, between 0 (transparent) and 1 (opaque). The default is 0.8.</p> <code>0.8</code> <code>figsize</code> <p>tuple, optional Width, height in inches. The default is (10, 10).</p> <code>(5, 5)</code> <code>s</code> <p>int, optional The marker size in points. The default is None.</p> <code>None</code> <code>ncols</code> <p>int, optional Number of panels per row. The default is None.</p> <code>None</code> <code>tight_layout</code> <p>bool, optional Adjust the padding between and around subplots. If True it will ensure that the legends are visible. The default is False.</p> <code>False</code> <code>return_data</code> <p>bool, optional Returns the data used for plotting. The default is False.</p> <code>False</code> <code>save_figure</code> <p>string, optional Pass path to saving figure with file extension. e.g <code>\\path      o\\directory\figure.pdf</code> The default is None.</p> <code>None</code> <code>**kwargs</code> <p>Other <code>matplotlib</code> parameters. </p> <code>{}</code> <p>Returns:</p> Name Type Description <code>final_data</code> <p>Dataframe If return_data is set to <code>True</code>.</p> <pre><code># Run UMAP\nadata = sm.tl.umap(adata)\n\n# plot results\nsm.pl.umap(adata, color=['CD3D', 'SOX10'])\n</code></pre> Source code in <code>scimap/plotting/_umap.py</code> <pre><code>def umap (adata, color=None, use_layer=None, use_raw=False, log=False, label='umap',\n          cmap='vlag', palette=None, alpha=0.8, figsize=(5, 5), s=None, ncols=None, \n          tight_layout=False, return_data=False, save_figure=None, **kwargs):\n\"\"\"\nParameters:\n\n    adata : AnnData Object  \n\n    color : list, optional\n        Keys for annotations of observations in `adata.obs.columns` or genes in `adata.var.index`. e.g. ['CD3D', 'SOX10']\n        The default is None.\n\n    use_layer : string, optional  \n        Pass name of any `Layer` in AnnData. The default is `None` and `adata.X` is used.\n\n    use_raw : bool, optional  \n        If set to `True`, values in `adata.raw.X` will be used to color the plot. The default is False.\n\n    log : bool, optional  \n        If set to `True`, the data will natural log transformed using `np.log1p()` for coloring. The default is False.\n\n    label : string, optional  \n        The `label key` used when running `sm.tl.umap()`. The default is 'umap'.\n\n    cmap : string, optional  \n        Color map to use for continous variables. Can be a name or a Colormap \n        instance (e.g. \"magma\u201d, \"viridis\"). The default is 'vlag'.\n\n    palette : dict, optional  \n        Colors to use for plotting categorical annotation groups. \n        It accepts a `dict` mapping categories to colors. \n        e.g. `palette = {'T cells': '#000000', 'B cells': '#FFF675'}`.\n        Auto color will be generated for other categories that are not specified. The default is None.\n\n    alpha : float, optional  \n        blending value, between 0 (transparent) and 1 (opaque). The default is 0.8.\n\n    figsize : tuple, optional  \n        Width, height in inches. The default is (10, 10).\n\n    s : int, optional  \n        The marker size in points. The default is None.\n\n    ncols : int, optional  \n        Number of panels per row. The default is None.\n\n    tight_layout : bool, optional  \n        Adjust the padding between and around subplots. If True it will ensure that\n        the legends are visible. The default is False.\n\n    return_data : bool, optional  \n        Returns the data used for plotting. The default is False.\n\n    save_figure : string, optional  \n        Pass path to saving figure with file extension.\n        e.g `\\path\\to\\directory\\figure.pdf` The default is None.\n\n    **kwargs : Other `matplotlib` parameters. \n\nReturns:\n\n    final_data : Dataframe\n        If return_data is set to `True`.\n\nExample:\n```python\n\n# Run UMAP\nadata = sm.tl.umap(adata)\n\n# plot results\nsm.pl.umap(adata, color=['CD3D', 'SOX10'])\n\n\n```\n\n    \"\"\"\n\n    # check if umap tool has been run\n    try:\n        adata.obsm[label]\n    except KeyError:\n        raise KeyError(\"Please run `sm.tl.umap(adata)` first\")\n\n    # identify the coordinates\n    umap_coordinates = pd.DataFrame(adata.obsm[label],index=adata.obs.index, columns=['umap-1','umap-2'])\n\n    # other data that the user requests\n    if color is not None:\n        if isinstance(color, str):\n            color = [color]\n        # identify if all elemets of color are available        \n        if set(color).issubset(list(adata.var.index) + list(adata.obs.columns)) is False:\n            raise ValueError(\"Element passed to `color` is not found in adata, please check!\")\n\n        # organise the data\n        if any(item in color for item in list(adata.obs.columns)):\n            adataobs = adata.obs.loc[:, adata.obs.columns.isin(color)]\n        else:\n            adataobs = None\n\n        if any(item in color for item in list(adata.var.index)):\n            # find the index of the marker\n            marker_index = np.where(np.isin(list(adata.var.index), color))[0]\n            if use_layer is not None:\n                adatavar = adata.layers[use_layer][:, np.r_[marker_index]]\n            elif use_raw is True:\n                adatavar = adata.raw.X[:, np.r_[marker_index]]\n            else:\n                adatavar = adata.X[:, np.r_[marker_index]]\n            adatavar = pd.DataFrame(adatavar, index=adata.obs.index, columns = list(adata.var.index[marker_index]))\n        else:\n            adatavar = None\n\n        # combine all color data\n        if adataobs is not None and adatavar is not None:\n            color_data = pd.concat ([adataobs, adatavar], axis=1)\n        elif adataobs is not None and adatavar is None:\n            color_data = adataobs\n        elif adataobs is None and adatavar is not None:\n            color_data = adatavar\n    else:\n        color_data = None\n\n    # combine color data with umap coordinates\n    if color_data is not None:\n        final_data = pd.concat([umap_coordinates, color_data], axis=1)\n    else:\n        final_data = umap_coordinates\n\n    # create some reasonable defaults\n    # estimate number of columns in subpolt\n    nplots = len(final_data.columns) - 2 # total number of plots\n    if ncols is None:\n        if nplots &gt;= 4:\n            subplot = [math.ceil(nplots / 4), 4]\n        elif nplots == 0:\n            subplot = [1, 1]\n        else:\n            subplot = [math.ceil(nplots / nplots), nplots]\n    else:\n        subplot = [math.ceil(nplots /ncols), ncols]\n\n    if nplots == 0:\n        n_plots_to_remove = 0\n    else:\n        n_plots_to_remove = np.prod(subplot) - nplots # figure if we have to remove any subplots\n\n    # size of points\n    if s is None:\n        if nplots == 0:\n            s = (100000 / adata.shape[0])\n        else:\n            s = (100000 / adata.shape[0]) / nplots\n\n\n    # if there are categorical data then assign colors to them\n    if final_data.select_dtypes(exclude=[\"number\",\"bool_\",\"object_\"]).shape[1] &gt; 0:\n        # find all categories in the dataframe\n        cat_data = final_data.select_dtypes(exclude=[\"number\",\"bool_\",\"object_\"])\n        # find all categories\n        all_cat = []\n        for i in cat_data.columns:\n            all_cat.append(list(cat_data[i].cat.categories))\n\n        # generate colormapping for all categories\n        less_9 = [colors.rgb2hex(x) for x in sns.color_palette('Set1')]\n        nineto20 = [colors.rgb2hex(x) for x in sns.color_palette('tab20')]\n        greater20 = [colors.rgb2hex(x) for x in sns.color_palette('gist_ncar', max([len(i) for i in all_cat]))]\n\n        all_cat_colormap = dict()\n        for i in range(len(all_cat)):\n            if len(all_cat[i]) &lt;= 9:\n                dict1 = dict(zip(all_cat[i] , less_9[ : len(all_cat[i]) ]   ))\n            elif len(all_cat[i]) &gt; 9 and len(all_cat[i]) &lt;= 20:\n                dict1 = dict(zip(all_cat[i] , nineto20[ : len(all_cat[i]) ]   ))\n            else:\n                dict1 = dict(zip(all_cat[i] , greater20[ : len(all_cat[i]) ]   ))\n            all_cat_colormap.update(dict1)\n\n        # if user has passed in custom colours update the colors\n        if palette is not None:\n            all_cat_colormap.update(palette)\n    else:\n        all_cat_colormap = None\n\n\n    # plot\n    fig, ax = plt.subplots(subplot[0],subplot[1], figsize=figsize)\n    plt.rcdefaults()\n    #plt.rcParams['axes.facecolor'] = 'white'\n\n    # remove unwanted axes\n    #fig.delaxes(ax[-1])\n    if n_plots_to_remove &gt; 0:\n        for i in range(n_plots_to_remove):\n            fig.delaxes(ax[-1][  (len(ax[-1])-1)-i :   (len(ax[-1]))-i   ][0])\n\n    # to make sure the ax is always 2x2\n    if any(i &gt; 1 for i in subplot):\n        if any(i == 1 for i in subplot):\n            ax = ax.reshape(subplot[0],subplot[1])\n\n    if nplots == 0:\n        ax.scatter(x = final_data['umap-1'], y = final_data['umap-2'], s=s, cmap=cmap, alpha=alpha, **kwargs)\n        plt.xlabel(\"UMAP-1\"); plt.ylabel(\"UMAP-2\") \n        plt.tick_params(right= False,top= False,left= False, bottom= False)\n        ax.get_xaxis().set_ticks([]); ax.get_yaxis().set_ticks([])\n        if tight_layout is True:\n            plt.tight_layout()\n\n    elif all(i == 1 for i in subplot):\n        column_to_plot = [e for e in list(final_data.columns) if e not in ('umap-1', 'umap-2')][0]\n        if all_cat_colormap is None:\n            im = ax.scatter(x = final_data['umap-1'], y = final_data['umap-2'], s=s, \n                       c=final_data[column_to_plot],\n                       cmap=cmap, alpha=alpha, **kwargs)\n            plt.colorbar(im, ax=ax)\n        else:\n            ax.scatter(x = final_data['umap-1'], y = final_data['umap-2'], s=s, \n                       c=final_data[column_to_plot].map(all_cat_colormap),\n                       cmap=cmap, alpha=alpha, **kwargs)\n            # create legend\n            patchList = []\n            for key in list(final_data[column_to_plot].unique()):\n                data_key = mpatches.Patch(color=all_cat_colormap[key], label=key)\n                patchList.append(data_key)    \n                ax.legend(handles=patchList,bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n\n        plt.xlabel(\"UMAP-1\"); plt.ylabel(\"UMAP-2\") \n        plt.title(column_to_plot)\n        plt.tick_params(right= False,top= False,left= False, bottom= False)\n        ax.set(xticklabels = ([])); ax.set(yticklabels = ([]))\n        if tight_layout is True:\n            plt.tight_layout()\n\n    else: \n        column_to_plot = [e for e in list(final_data.columns) if e not in ('umap-1', 'umap-2')]\n        k=0\n        for i,j in itertools.product(range(subplot[0]), range(subplot[1])):\n\n            if final_data[column_to_plot[k]].dtype == 'category':\n                ax[i,j].scatter(x = final_data['umap-1'], y = final_data['umap-2'], s=s,\n                                c=final_data[column_to_plot[k]].map(all_cat_colormap),\n                                cmap=cmap, alpha=alpha, **kwargs)\n                # create legend\n                patchList = []\n                for key in list(final_data[column_to_plot[k]].unique()):\n                    data_key = mpatches.Patch(color=all_cat_colormap[key], label=key)\n                    patchList.append(data_key)    \n                    ax[i,j].legend(handles=patchList,bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n            else:               \n                im = ax[i,j].scatter(x = final_data['umap-1'], y = final_data['umap-2'], s=s,\n                                c=final_data[column_to_plot[k]],\n                                cmap=cmap, alpha=alpha, **kwargs)\n                plt.colorbar(im, ax=ax[i, j])\n\n            ax[i,j].tick_params(right= False,top= False,left= False, bottom= False)\n            ax[i,j].set_xticklabels([]); ax[i,j].set_yticklabels([])\n            ax[i,j].set_xlabel(\"UMAP-1\"); ax[i,j].set_ylabel(\"UMAP-2\")\n            ax[i,j].set_title(column_to_plot[k])\n            if tight_layout is True:\n                plt.tight_layout()\n            k = k+1 # iterator\n\n    # if save figure is requested\n    if save_figure is not None:\n        plt.savefig(save_figure)  \n\n    # return data if needed\n    if return_data is True:\n        return final_data\n</code></pre>"},{"location":"Functions/pl/voronoi/","title":"voronoi","text":"<p>!!!</p> <p>Short Description</p> <p><code>sm.pl.voronoi</code>: The function allows users to generate a voronoi diagram and color it based on  any categorical column. Please note, voronoi diagrams are best fitted for small regions with  upto 5000 cells. Any larger, the voronoi plots are uninterpretable and takes a long time to generate.</p>"},{"location":"Functions/pl/voronoi/#scimap.plotting._voronoi--function","title":"Function","text":""},{"location":"Functions/pl/voronoi/#scimap.plotting._voronoi.voronoi","title":"<code>voronoi(adata, color_by=None, colors=None, x_coordinate='X_centroid', y_coordinate='Y_centroid', imageid='imageid', subset=None, x_lim=None, y_lim=None, flip_y=True, voronoi_edge_color='black', voronoi_line_width=0.1, voronoi_alpha=0.5, size_max=np.inf, overlay_points=None, overlay_points_categories=None, overlay_drop_categories=None, overlay_points_colors=None, overlay_point_size=5, overlay_point_alpha=1, overlay_point_shape='.', plot_legend=True, legend_size=6, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>Anndata object</p> required <code>color_by</code> <p>string, optional Color the voronoi diagram based on categorical variable (e.g. cell types or neighbourhoods). Pass the name of the column which contains the categorical variable.</p> <code>None</code> <code>colors</code> <p>string or Dict, optional Custom coloring the voronoi diagram. The parameter accepts <code>sns color palettes</code> or a python dictionary mapping the categorical variable with the required color.</p> <code>None</code> <code>x_coordinate</code> <p>float, required Column name containing the x-coordinates values.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <p>float, required Column name containing the y-coordinates values.</p> <code>'Y_centroid'</code> <code>flip_y</code> <p>bool, optional Flip the Y-axis if needed. Some algorithms output the XY with the Y-coordinates flipped. If the image overlays do not align to the cells, try again by setting this to <code>False</code>.</p> <code>True</code> <code>imageid</code> <p>string, optional Column name of the column containing the image id.</p> <code>'imageid'</code> <code>subset</code> <p>string, optional imageid of a single image to be subsetted for plotting.</p> <code>None</code> <code>voronoi_edge_color</code> <p>string, optional A Matplotlib color for marking the edges of the voronoi.  If <code>facecolor</code> is passed, the edge color will always be the same as the face color.</p> <code>'black'</code> <code>voronoi_line_width</code> <p>float, optional The linewidth of the marker edges. Note: The default edgecolors is 'face'. You may want to change this as well. </p> <code>0.1</code> <code>voronoi_alpha</code> <p>float, optional The alpha blending value, between 0 (transparent) and 1 (opaque).</p> <code>0.5</code> <code>x_lim</code> <p>list, optional Pass the x-coordinates range [x1,x2].</p> <code>None</code> <code>y_lim</code> <p>list, optional Pass the y-coordinates range [y1,y2].</p> <code>None</code> <code>overlay_points</code> <p>string, optional It is possible to overlay a scatter plot on top of the voronoi diagram. Pass the name of the column which contains categorical variable to be overlayed.</p> <code>None</code> <code>overlay_points_categories</code> <p>list, optional If the passed column in <code>overlay_points</code> contains multiple categories, however the user is only interested in a subset of categories, those specific names can be passed as a list. By default all  categories will be overlayed on the voronoi diagram.</p> <code>None</code> <code>overlay_drop_categories</code> <p>list, optional Similar to <code>overlay_points_categories</code>. Here for ease of use, especially if large number of categories are present. The user can drop a set of categories.</p> <code>None</code> <code>overlay_points_colors</code> <p>string or dict, optional Similar to <code>colors</code>. User can pass in a a) solid color (like <code>black</code>) b) sns palettes name (like <code>Set1</code>) c) python dictionary mapping the categories with custom colors</p> <code>None</code> <code>overlay_point_size</code> <p>float, optional Overlay scatter plot point size.</p> <code>5</code> <code>overlay_point_alpha</code> <p>float, optional The alpha blending value for the overlay, between 0 (transparent) and 1 (opaque).</p> <code>1</code> <code>overlay_point_shape</code> <p>string, optional The marker style. marker can be either an instance of the class or the text shorthand for a particular marker.</p> <code>'.'</code> <code>plot_legend</code> <p>bool, optional Define if the figure legend should be plotted. Please note the figure legend may be out of view and you may need to resize the image to see it, especially  the legend for the scatter plot which will be on the left side of the plot.</p> <code>True</code> <code>legend_size</code> <p>float, optional Resize the legend if needed.</p> <code>6</code> Example <pre><code>sm.pl.voronoi(adata, color_by='phenotype', colors=None, \n         x_coordinate='X_position', y_coordinate='Y_position',\n         imageid='ImageId',subset=None,\n         voronoi_edge_color = 'black',voronoi_line_width = 0.2, \n         voronoi_alpha = 0.5, size_max=np.inf,\n         overlay_points='phenotype', overlay_points_categories=None, \n         overlay_drop_categories=None,\n         overlay_point_size = 5, overlay_point_alpha= 1, \n         overlay_point_shape=\".\", plot_legend=False, legend_size=6)\n</code></pre> Source code in <code>scimap/plotting/_voronoi.py</code> <pre><code>def voronoi (adata, color_by=None, colors=None, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n             imageid='imageid',subset=None, x_lim=None, y_lim=None, flip_y=True,\n             voronoi_edge_color='black', voronoi_line_width=0.1, voronoi_alpha=0.5, size_max=np.inf,\n             overlay_points=None, overlay_points_categories=None, overlay_drop_categories=None, overlay_points_colors=None,\n             overlay_point_size = 5, overlay_point_alpha= 1, overlay_point_shape=\".\", plot_legend=True, legend_size = 6, **kwargs):\n\"\"\"\nParameters:\n    adata : Anndata object\n\n    color_by : string, optional  \n        Color the voronoi diagram based on categorical variable (e.g. cell types or neighbourhoods).\n        Pass the name of the column which contains the categorical variable.\n\n    colors : string or Dict, optional  \n        Custom coloring the voronoi diagram. The parameter accepts `sns color palettes` or a python dictionary\n        mapping the categorical variable with the required color.\n\n    x_coordinate : float, required  \n        Column name containing the x-coordinates values.\n\n    y_coordinate : float, required  \n        Column name containing the y-coordinates values.\n\n    flip_y : bool, optional  \n        Flip the Y-axis if needed. Some algorithms output the XY with the Y-coordinates flipped.\n        If the image overlays do not align to the cells, try again by setting this to `False`.\n\n    imageid : string, optional  \n        Column name of the column containing the image id.\n\n    subset : string, optional  \n        imageid of a single image to be subsetted for plotting.\n\n    voronoi_edge_color : string, optional  \n        A Matplotlib color for marking the edges of the voronoi. \n        If `facecolor` is passed, the edge color will always be the same as the face color.\n\n    voronoi_line_width : float, optional  \n        The linewidth of the marker edges. Note: The default edgecolors is 'face'. You may want to change this as well. \n\n    voronoi_alpha : float, optional  \n        The alpha blending value, between 0 (transparent) and 1 (opaque).\n\n    x_lim : list, optional  \n        Pass the x-coordinates range [x1,x2].\n\n    y_lim : list, optional  \n        Pass the y-coordinates range [y1,y2].\n\n    overlay_points : string, optional  \n        It is possible to overlay a scatter plot on top of the voronoi diagram.\n        Pass the name of the column which contains categorical variable to be overlayed.\n\n    overlay_points_categories : list, optional  \n        If the passed column in `overlay_points` contains multiple categories, however the user is only\n        interested in a subset of categories, those specific names can be passed as a list. By default all \n        categories will be overlayed on the voronoi diagram.\n\n    overlay_drop_categories : list, optional  \n        Similar to `overlay_points_categories`. Here for ease of use, especially if large number of categories are present.\n        The user can drop a set of categories.\n\n    overlay_points_colors : string or dict, optional  \n        Similar to `colors`.  \n        User can pass in a  \n        a) solid color (like `black`)  \n        b) sns palettes name (like `Set1`)  \n        c) python dictionary mapping the categories with custom colors\n\n    overlay_point_size : float, optional  \n        Overlay scatter plot point size.\n\n    overlay_point_alpha : float, optional  \n        The alpha blending value for the overlay, between 0 (transparent) and 1 (opaque).\n\n    overlay_point_shape : string, optional  \n        The marker style. marker can be either an instance of the class or the text shorthand for a particular marker.\n\n    plot_legend : bool, optional  \n        Define if the figure legend should be plotted.  \n        Please note the figure legend may be out of view and you may need to resize the image to see it, especially \n        the legend for the scatter plot which will be on the left side of the plot.\n\n    legend_size : float, optional  \n        Resize the legend if needed.\n\nExample:\n\n    ```python\n    sm.pl.voronoi(adata, color_by='phenotype', colors=None, \n             x_coordinate='X_position', y_coordinate='Y_position',\n             imageid='ImageId',subset=None,\n             voronoi_edge_color = 'black',voronoi_line_width = 0.2, \n             voronoi_alpha = 0.5, size_max=np.inf,\n             overlay_points='phenotype', overlay_points_categories=None, \n             overlay_drop_categories=None,\n             overlay_point_size = 5, overlay_point_alpha= 1, \n             overlay_point_shape=\".\", plot_legend=False, legend_size=6)\n\n    ```\n\n    \"\"\"\n\n\n    # create the data frame needed\n    data = adata.obs\n\n    # Subset the image of interest\n    if subset is not None:\n        data = data[data[imageid] == subset]\n\n\n    # subset coordinates if needed\n    if x_lim is not None:\n        x1 = x_lim [0]\n        if len(x_lim) &lt; 2:\n            x2 = max(data[x_coordinate])\n        else:\n            x2 = x_lim [1]\n    if y_lim is not None:\n        y1 = y_lim [0]\n        if len(y_lim) &lt; 2:\n            y2 = min(data[y_coordinate])\n        else:\n            y2 = y_lim [1]\n    # do the actuall subsetting\n    if x_lim is not None:\n        data = data[data[x_coordinate] &gt;= x1]\n        data = data[data[x_coordinate] &lt;= x2]\n    if y_lim is not None:\n        data = data[data[y_coordinate] &lt;= y1]\n        data = data[data[y_coordinate] &gt;= y2]\n\n\n    # create an extra column with index information\n    data['index_info'] = np.arange(data.shape[0])\n\n    # generate the x and y coordinates\n    points = data[[x_coordinate,y_coordinate]].values\n\n    # invert the Y-axis\n    if flip_y is True:\n        points[:,1] = max(points[:,1])-points[:,1]\n\n    # Generate colors\n    if color_by is None:\n        colors = np.repeat('#e5e5e5', len(data))\n#    elif color_by is None and colors is not None:\n#        if isinstance(colors,str):\n#            colors = np.repeat(colors, len(data))\n    elif color_by is not None and colors is None:\n        # auto color the samples\n        if len(np.unique(data[color_by])) &lt;= 9:\n            c = sns.color_palette('Set1')[0:len(np.unique(data[color_by]))]\n        if len(np.unique(data[color_by])) &gt; 9 and len(np.unique(data[color_by])) &lt;= 20:\n            c = sns.color_palette('tab20')[0:len(np.unique(data[color_by]))]\n        if len(np.unique(data[color_by])) &gt; 20:\n            # For large categories generate random colors \n            np.random.seed(0) ; c = np.random.rand(len(np.unique(data[color_by])),3).tolist()\n        # merge colors with phenotypes/ categories of interest\n        p = np.unique(data[color_by])\n        c_p = dict(zip(p, c))\n        # map to colors\n        colors = list(map(c_p.get, list(data[color_by].values)))\n    elif color_by is not None and colors is not None:\n        # check if colors is a dictionary or a sns color scale\n        if isinstance(colors,str): \n            if len(sns.color_palette(colors)) &lt; len(np.unique(data[color_by])):\n                raise ValueError(str(colors) + ' includes a maximun of ' + str(len(sns.color_palette(colors))) + ' colors, while your data need '  + str(len(np.unique(data[color_by]))) + ' colors')\n            else:\n                c = sns.color_palette(colors)[0:len(np.unique(data[color_by]))]    \n                # merge colors with phenotypes/ categories of interest\n                p = np.unique(data[color_by])\n                c_p = dict(zip(p, c))\n        if isinstance(colors,dict):\n            if len(colors) &lt; len(np.unique(data[color_by])):\n                raise ValueError('Color mapping is not provided for all categories. Please check')\n            else:\n                c_p = colors\n        # map to colors\n        colors = list(map(c_p.get, list(data[color_by].values)))\n\n\n\n    # create the voronoi object\n    vor = Voronoi(points)\n\n    # trim the object\n    regions, vertices = voronoi_finite_polygons_2d(vor)\n\n    # plotting\n    pts = MultiPoint([Point(i) for i in points])\n    mask = pts.convex_hull\n    new_vertices = []\n    if type(voronoi_alpha)!=list:\n        voronoi_alpha = [voronoi_alpha]*len(points)\n    areas = []\n    for i,(region,alph) in enumerate(zip(regions,voronoi_alpha)):\n        polygon = vertices[region]\n        shape = list(polygon.shape)\n        shape[0] += 1\n        p = Polygon(np.append(polygon, polygon[0]).reshape(*shape)).intersection(mask)\n        areas+=[p.area]\n        if p.area &lt;size_max:\n            poly = np.array(list(zip(p.boundary.coords.xy[0][:-1], p.boundary.coords.xy[1][:-1])))\n            new_vertices.append(poly)\n            if voronoi_edge_color == 'facecolor':\n                plt.fill(*zip(*poly), alpha=alph, edgecolor=colors[i], linewidth = voronoi_line_width , facecolor = colors[i])\n                plt.xticks([]) ; plt.yticks([]);\n            else:\n                plt.fill(*zip(*poly), alpha=alph, edgecolor=voronoi_edge_color, linewidth = voronoi_line_width, facecolor = colors[i])\n                plt.xticks([]) ; plt.yticks([]);\n                #plt.xlim([1097.5,1414.5])\n                #plt.ylim([167.3,464.1])\n\n\n    # Add scatter on top of the voronoi if user requests\n    if overlay_points is not None:\n        if overlay_points_categories is None:\n            d = data\n        if overlay_points_categories is not None:\n            # convert to list if needed (cells to keep)\n            if isinstance(overlay_points_categories,str): \n                overlay_points_categories = [overlay_points_categories]\n            # subset cells needed\n            d = data[data[overlay_points].isin(overlay_points_categories)]    \n        if overlay_drop_categories is not None:\n            # conver to list if needed (cells to drop)\n            if isinstance(overlay_drop_categories,str): \n                overlay_drop_categories = [overlay_drop_categories]\n            # subset cells needed\n            d = d[-d[overlay_points].isin(overlay_drop_categories)]\n\n        # Find the x and y coordinates for the overlay category\n        #points_scatter = d[[x_coordinate,y_coordinate]].values\n        points_scatter = points[d.index_info.values]\n\n        # invert the Y-axis\n        #points_scatter[:,1] = max(points_scatter[:,1])-points_scatter[:,1]\n\n        # Generate colors for the scatter plot\n        if overlay_points_colors is None and color_by == overlay_points:\n            # Borrow color from vornoi\n            wanted_keys = np.unique(d[overlay_points]) # The keys to extract\n            c_p_scatter = dict((k, c_p[k]) for k in wanted_keys if k in c_p)\n        elif overlay_points_colors is None and color_by != overlay_points:\n            # Randomly generate colors for all the categories in scatter plot\n            # auto color the samples\n            if len(np.unique(d[overlay_points])) &lt;= 9:\n                c_scatter = sns.color_palette('Set1')[0:len(np.unique(d[overlay_points]))]\n            if len(np.unique(d[overlay_points])) &gt; 9 and len(np.unique(d[overlay_points])) &lt;= 20:\n                c_scatter = sns.color_palette('tab20')[0:len(np.unique(d[overlay_points]))]\n            if len(np.unique(d[overlay_points])) &gt; 20:\n                # For large categories generate random colors \n                np.random.seed(1) ; c_scatter = np.random.rand(len(np.unique(d[overlay_points])),3).tolist()\n            # merge colors with phenotypes/ categories of interest\n            p_scatter = np.unique(d[overlay_points])\n            c_p_scatter = dict(zip(p_scatter, c_scatter))\n        elif  overlay_points_colors is not None:\n            # check if the overlay_points_colors is a pallete\n            if isinstance(overlay_points_colors,str):\n                try:\n                    c_scatter = sns.color_palette(overlay_points_colors)[0:len(np.unique(d[overlay_points]))]\n                    if len(sns.color_palette(overlay_points_colors)) &lt; len(np.unique(d[overlay_points])):\n                        raise ValueError(str(overlay_points_colors) + ' pallete includes a maximun of ' + str(len(sns.color_palette(overlay_points_colors))) + ' colors, while your data (overlay_points_colors) need '  + str(len(np.unique(d[overlay_points]))) + ' colors') \n                except:\n                    c_scatter = np.repeat(overlay_points_colors,len(np.unique(d[overlay_points])))   #[overlay_points_colors]\n                # create a dict\n                p_scatter = np.unique(d[overlay_points])\n                c_p_scatter = dict(zip(p_scatter, c_scatter))\n            if isinstance(overlay_points_colors,dict):\n                if len(overlay_points_colors) &lt; len(np.unique(d[overlay_points])):\n                    raise ValueError('Color mapping is not provided for all categories. Please check overlay_points_colors')\n                else:\n                    c_p_scatter = overlay_points_colors\n        # map to colors\n        colors_scatter = list(map(c_p_scatter.get, list(d[overlay_points].values)))\n\n        #plt.scatter(x = points_scatter[:,0], y = points_scatter[:,1], s= overlay_point_size, alpha= overlay_point_alpha, c= colors_scatter, marker=overlay_point_shape)\n        plt.scatter(x = points_scatter[:,0], y = points_scatter[:,1], s= overlay_point_size, alpha= overlay_point_alpha, c= colors_scatter, marker=overlay_point_shape,**kwargs)\n        plt.xticks([]) ; plt.yticks([]);\n\n\n    if plot_legend is True:\n        # Add legend to voronoi\n        patchList = []\n        for key in c_p:\n                data_key = mpatches.Patch(color=c_p[key], label=key)\n                patchList.append(data_key)\n\n        first_legend = plt.legend(handles=patchList, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., prop={'size': legend_size})\n        plt.tight_layout()\n        # Add the legend manually to the current Axes.\n        ax = plt.gca().add_artist(first_legend)\n\n        if overlay_points is not None:\n            # Add legend to scatter\n            patchList_scatter = []\n            for key in c_p_scatter:\n                    data_key_scatter = mpatches.Patch(color=c_p_scatter[key], label=key)\n                    patchList_scatter.append(data_key_scatter)\n\n            plt.legend(handles=patchList_scatter, bbox_to_anchor=(-0.05, 1), loc=1, borderaxespad=0., prop={'size': legend_size})\n</code></pre>"},{"location":"Functions/pp/combat/","title":"combat","text":"<p>Short Description</p> <p>ComBat is a well-established method for correcting batch effects in high-dimensional data, such as single-cell RNA-seq. This implementation uses the <code>combat</code> function to correct batch effects across multiple slides.  </p>"},{"location":"Functions/pp/combat/#scimap.preprocessing._combat--function","title":"Function","text":""},{"location":"Functions/pp/combat/#scimap.preprocessing._combat.combat","title":"<code>combat(adata, batch='imageid', layer=None, log=False, replaceOriginal=False, label='combat')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData object</code> <p>Annotated data matrix.</p> required <code>batch</code> <code>str</code> <p>The batch key or column in <code>adata.obs</code> that indicates the batches for each cell.</p> <code>'imageid'</code> <code>layer</code> <code>str or None</code> <p>The layer in <code>adata.layers</code> that contains the expression data to correct. If None,  <code>adata.X</code> is used. use <code>raw</code> to use the data stored in <code>adata.raw.X</code></p> <code>None</code> <code>log</code> <code>bool</code> <p>Whether to log transform the data before applying ComBat. Generally use it with <code>raw</code>.</p> <code>False</code> <code>replaceOriginal</code> <code>bool</code> <p>Whether to replace the original expression data in <code>adata</code> with the corrected data.</p> <code>False</code> <code>label</code> <code>str</code> <p>The prefix for the key in <code>adata</code> that will contain the corrected data. If <code>replaceOriginal</code> is <code>True</code>, this parameter has no effect.  </p> <code>'combat'</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>anndata</code> <p>The corrected expression data is stored in a new layer <code>adata.layers['combat']</code>.</p> <p>Examples:</p> <pre><code># applying batch correction using raw data\nadata = sm.pp.combat (adata,\n                batch='imageid',\n                layer='raw',\n                log=True,\n                replaceOriginal=False,\n                label='combat')\n\n# results will be available in adata.layers['combat']\n</code></pre> Source code in <code>scimap/preprocessing/_combat.py</code> <pre><code>def combat(\n    adata,\n    batch='imageid',\n    layer=None,\n    log=False,\n    replaceOriginal=False,\n    label='combat'):\n\n\"\"\"\nParameters:\n    adata (AnnData object):  \n        Annotated data matrix.\n\n    batch (str, optional):  \n        The batch key or column in `adata.obs` that indicates the batches for each cell.\n\n    layer (str or None, optional):\n        The layer in `adata.layers` that contains the expression data to correct. If None, \n        `adata.X` is used. use `raw` to use the data stored in `adata.raw.X`\n\n    log (bool, optional):  \n        Whether to log transform the data before applying ComBat. Generally use it with `raw`.\n\n    replaceOriginal (bool, optional):\n        Whether to replace the original expression data in `adata` with the corrected data.\n\n    label (str, optional):  \n        The prefix for the key in `adata` that will contain the corrected data. If `replaceOriginal` is `True`, this parameter has no effect.  \n\nReturns:\n    adata (anndata):  \n        The corrected expression data is stored in a new layer `adata.layers['combat']`.\n\nExamples:\n\n    ```python\n\n    # applying batch correction using raw data\n    adata = sm.pp.combat (adata,\n                    batch='imageid',\n                    layer='raw',\n                    log=True,\n                    replaceOriginal=False,\n                    label='combat')\n\n    # results will be available in adata.layers['combat']\n\n    ```\n    \"\"\"\n\n    # isolate the data\n    if layer is None:\n        data = pd.DataFrame(adata.X, index=adata.obs.index, columns=adata.var.index)\n    elif layer == 'raw':\n        data = pd.DataFrame(adata.raw.X, index=adata.obs.index, columns=adata.var.index)\n    else:\n        data = pd.DataFrame(adata.layers[layer], index=adata.obs.index, columns=adata.var.index)\n\n    # log the data if requested\n    if log is True:\n        data = np.log1p(data)\n\n    # isolate batch\n    batchData = adata.obs[batch]\n\n    # convert to category\n    batchData = batchData.astype('category')\n\n    # make sure there are atleast two batches\n    if len(batchData.unique()) &lt; 2:\n        raise Exception(\n            \"Sorry a minimum of 2 batches is required. Please check the '\"\n            + str(batch)\n            + \"' column\"\n        )\n\n    # perform batch correction\n    batchCorrected = pycombat(data.T, batchData).T\n\n    # add as a specific layer\n    adata.layers[label] = batchCorrected\n\n    # replace original\n    if replaceOriginal is True:\n        if layer is None:\n            adata.X = batchCorrected\n        elif layer == 'raw':\n            del adata.raw\n            adata.raw = ad.AnnData(batchCorrected, obs=adata.obs)\n        else:\n            adata.layers[layer] = batchCorrected\n\n    # return adata\n    return adata\n</code></pre>"},{"location":"Functions/pp/mcmicro_to_scimap/","title":"mcmicro_to_scimap","text":"<p>Short Description</p> <p><code>sm.pp.mcmicro_to_scimap</code>: The function allows users to directly import the output from mcmicro  into <code>scimap</code>.</p>"},{"location":"Functions/pp/mcmicro_to_scimap/#scimap.preprocessing._mcmicro_to_scimap--function","title":"Function","text":""},{"location":"Functions/pp/mcmicro_to_scimap/#scimap.preprocessing._mcmicro_to_scimap.mcmicro_to_scimap","title":"<code>mcmicro_to_scimap(feature_table_path, remove_dna=True, remove_string_from_name=None, log=True, drop_markers=None, random_sample=None, unique_CellId=True, CellId='CellID', split='X_centroid', custom_imageid=None, min_cells=None, output_dir=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>feature_table_path</code> <code>list</code> <p>This is a list of paths that lead to the single-cell spatial feature tables. Each image should have a unique path assigned to it.</p> required <code>remove_dna</code> <code>bool</code> <p>Remove the DNA channels from the final output. Looks for channels with the string 'dna' in it.</p> <code>True</code> <code>remove_string_from_name</code> <p>string, optional Used to celan up channel names. If a string is given, that particular string will be removed from all marker names. If multiple images are passed, just use the string that appears in the first image.</p> <code>None</code> <code>log</code> <p>bool, optional Log the data (log1p transformation will be applied).</p> <code>True</code> <code>drop_markers</code> <p>list, optional List of markers to drop from the analysis. e.g. [\"CD3D\", \"CD20\"].</p> <code>None</code> <code>random_sample</code> <p>int, optional Randomly sub-sample the data with the desired number of cells.</p> <code>None</code> <code>CellId</code> <p>string, optional Name of the column that contains the cell ID.</p> <code>'CellID'</code> <code>unique_CellId</code> <p>bool, optional By default, the function creates a unique name for each cell/row by combining the  <code>CellId</code> and <code>imageid</code>. If you wish not to perform this operation please pass <code>False</code>. The function will use whatever is under <code>CellId</code>. In which case, please be careful to pass unique <code>CellId</code> especially when loading multiple datasets togeather.  </p> <code>True</code> <code>split</code> <p>string, optional To split the CSV into counts table and meta data, pass in the name of the column that immediately follows the marker quantification.</p> <code>'X_centroid'</code> <code>custom_imageid</code> <p>string, optional Pass a user defined Image ID. By default the name of the CSV file is used.</p> <code>None</code> <code>min_cells</code> <p>int, optional If these many cells are not in the image, the image will be dropped. Particulary useful when importing multiple images.</p> <code>None</code> <code>output_dir</code> <p>string, optional Path to output directory. </p> <code>None</code> <p>Returns:</p> Type Description <p>AnnData Object</p> <pre><code>feature_table_path = ['/Users/aj/whole_sections/PTCL1_450.csv',\n                  '/Users/aj/whole_sections/PTCL2_552.csv']\nadata = sm.pp.mcmicro_to_scimap (feature_table_path, drop_markers= ['CD21', 'ACTIN'], random_sample=5000)\n</code></pre> Source code in <code>scimap/preprocessing/_mcmicro_to_scimap.py</code> <pre><code>def mcmicro_to_scimap (feature_table_path,\n                       remove_dna=True,\n                       remove_string_from_name=None,\n                       log=True,\n                       drop_markers=None,\n                       random_sample=None, \n                       unique_CellId=True,\n                       CellId='CellID',\n                       split='X_centroid',\n                       custom_imageid=None,\n                       min_cells=None, \n                       output_dir=None):\n\"\"\"\nParameters:\n\n    feature_table_path (list):    \n        This is a list of paths that lead to the single-cell spatial feature tables. Each image should have a unique path assigned to it.\n\n    remove_dna (bool):    \n        Remove the DNA channels from the final output. Looks for channels with the string 'dna' in it.\n\n    remove_string_from_name : string, optional  \n        Used to celan up channel names. If a string is given, that particular string will be removed from all marker names.\n        If multiple images are passed, just use the string that appears in the first image.\n\n    log : bool, optional  \n        Log the data (log1p transformation will be applied).\n\n    drop_markers : list, optional  \n        List of markers to drop from the analysis. e.g. [\"CD3D\", \"CD20\"].\n\n    random_sample : int, optional  \n        Randomly sub-sample the data with the desired number of cells.\n\n    CellId : string, optional  \n        Name of the column that contains the cell ID.\n\n    unique_CellId: bool, optional  \n        By default, the function creates a unique name for each cell/row by combining the \n        `CellId` and `imageid`. If you wish not to perform this operation please pass `False`.\n        The function will use whatever is under `CellId`. In which case, please be careful to pass unique `CellId`\n        especially when loading multiple datasets togeather.  \n\n    split : string, optional  \n        To split the CSV into counts table and meta data, pass in the name of the column\n        that immediately follows the marker quantification.\n\n    custom_imageid: string, optional  \n        Pass a user defined Image ID. By default the name of the CSV file is used.\n\n    min_cells: int, optional  \n        If these many cells are not in the image, the image will be dropped.\n        Particulary useful when importing multiple images.\n\n    output_dir: string, optional  \n        Path to output directory. \n\nReturns:\n\n    AnnData Object\n\n\nExample:\n```python\nfeature_table_path = ['/Users/aj/whole_sections/PTCL1_450.csv',\n                  '/Users/aj/whole_sections/PTCL2_552.csv']\nadata = sm.pp.mcmicro_to_scimap (feature_table_path, drop_markers= ['CD21', 'ACTIN'], random_sample=5000)\n```\n    \"\"\"\n\n    # feature_table_path list or string\n    if isinstance(feature_table_path, str):\n        feature_table_path = [feature_table_path]\n    feature_table_path = [pathlib.Path(p) for p in feature_table_path]\n\n    # Import data based on the location provided\n    def load_process_data (image):\n        # Print the data that is being processed\n        print(f\"Loading {image.name}\")\n        d = pd.read_csv(image)\n        # If the data does not have a unique image ID column, add one.\n        if 'imageid' not in d.columns:\n            if custom_imageid is not None:\n                imid = custom_imageid\n            else:\n                #imid = random.randint(1000000,9999999)\n                imid = image.stem\n            d['imageid'] = imid\n        # Unique name for the data\n        if unique_CellId is True:\n            d.index = d['imageid'].astype(str)+'_'+d[CellId].astype(str)\n        else:\n            d.index = d[CellId]\n\n        # move image id and cellID column to end\n        cellid_col = [col for col in d.columns if col != CellId] + [CellId]; d = d[cellid_col]\n        imageid_col = [col for col in d.columns if col != 'imageid'] + ['imageid']; d = d[imageid_col]\n        # If there is INF replace with zero\n        d = d.replace([np.inf, -np.inf], 0)\n        # Return data\n        return d\n    # Apply function to all images and create a master dataframe\n    r_load_process_data = lambda x: load_process_data(image=x) # Create lamda function\n    all_data = list(map(r_load_process_data, list(feature_table_path))) # Apply function\n\n    # Merge all the data into a single large dataframe\n    for i in range(len(all_data)):\n        all_data[i].columns = all_data[0].columns\n    entire_data = pd.concat(all_data, axis=0, sort=False)\n\n    # Randomly sample the data\n    if random_sample is not None:\n        entire_data = entire_data.sample(n=random_sample,replace=False)\n\n    #Remove the images that contain less than a defined threshold of cells (min_cells)\n    if min_cells is not None:\n        to_drop = entire_data['imageid'].value_counts()[entire_data['imageid'].value_counts() &lt; min_cells].index\n        entire_data = entire_data[~entire_data['imageid'].isin(to_drop)]\n        print('Removed Images that contained less than '+str(min_cells)+' cells: '+ str(to_drop.values))\n\n    # Split the data into expression data and meta data\n    # Step-1 (Find the index of the column with name Area)\n    split_idx = entire_data.columns.get_loc(split)\n    meta = entire_data.iloc [:,split_idx:]\n    # Step-2 (select only the expression values)\n    entire_data = entire_data.iloc [:,:split_idx]\n\n    # Rename the columns of the data\n    if remove_string_from_name is not None:\n        entire_data.columns = entire_data.columns.str.replace(remove_string_from_name, '')\n\n    # Save a copy of the column names in the uns space of ANNDATA\n    markers = list(entire_data.columns)\n\n    # Remove DNA channels\n    if remove_dna is True:\n        entire_data = entire_data.loc[:,~entire_data.columns.str.contains('dna', case=False)]\n\n    # Drop unnecessary markers\n    if drop_markers is not None:\n        if isinstance(drop_markers, str):\n            drop_markers = [drop_markers]\n        entire_data = entire_data.drop(columns=drop_markers)\n\n    # Create an anndata object\n    adata = ad.AnnData(entire_data)\n    adata.obs = meta\n    adata.uns['all_markers'] = markers\n\n    # Add log data\n    if log is True:\n        adata.raw = adata\n        adata.X = np.log1p(adata.X)\n\n    # Save data if requested\n    if output_dir is not None:\n        output_dir = pathlib.Path(output_dir)\n        output_dir.mkdir(exist_ok=True, parents=True)\n        imid = feature_table_path[0].stem\n        adata.write(output_dir / f'{imid}.h5ad')\n        #adata.write(str(output_dir) + '/' + imid + '.h5ad')\n    else:    \n        # Return data\n        return adata\n</code></pre>"},{"location":"Functions/pp/rescale/","title":"rescale","text":"<p>Short Description</p> <p><code>sm.pp.rescale</code>: The function allows users to rescale the data. This step is often performed to standardize the  the expression of all markers to a common scale. The rescaling can be either performed automatically or manually.  User defined gates can be passed to rescale the data manually, else the algorithm fits a GMM (gaussian mixed model) to  identify the cutoff point. The resultant data is between 0-1 where values below 0.5 are considered non-expressing while  above 0.5 is considered positive. </p>"},{"location":"Functions/pp/rescale/#scimap.preprocessing._rescale--function","title":"Function","text":""},{"location":"Functions/pp/rescale/#scimap.preprocessing._rescale.rescale","title":"<code>rescale(adata, gate=None, log=True, imageid='imageid', failed_markers=None, method='all', random_state=0)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData Object  </p> required <code>gate</code> <p>dataframe, optional DataFrame with first column as markers and subsequent column with gate values for each image in the dataset. The column names should correspond to the unique <code>imageid</code>. If only one column of gate is provied  to a dataset with multiple images, the same gate will be applied to all images. Note: If gates are not provided or left out for a particular marker, the function will try to  automatically identify a gate based on applying gaussian mixture modeling algorithm (GMM). The default is None.</p> <code>None</code> <code>log</code> <p>bool, optional By default the data stored in <code>adata.raw.X</code> is extracted for scaling. If the user wishes to log transform (log1p) it before applying the gates, this parameter can be set to True. Please note if the function is used to  identify gates based on GMM, it is recommended for the data to be log transformed. The default is True.</p> <code>True</code> <code>imageid</code> <p>string, optional The column containing the Image IDs. When passing manual gates the columns of the dataframe need to match  to the elements within the passed <code>imageid</code> column. The default is 'imageid'.</p> <code>'imageid'</code> <code>failed_markers</code> <p>dict, optional Markers that were deemed to have failed based on prior visual inspection. This parameter accepts a python  dictionary with <code>key</code> as <code>imageid</code> and <code>value</code> as markers that failed in that particular <code>imageid</code>.  Example: <code>failed_markers = {'image_1': ['failed_marker_1'], 'image_2' : ['failed_marker_1', 'failed_marker_2']}</code>.  To make it easier to allow specifying markers that failed in <code>all</code> images within the dataset, the parameter also  recognizes the special keyword <code>all</code>. For example, <code>failed_markers = {'all': ['failed_marker_X'], 'image_2' : ['failed_marker_1', 'failed_marker_2']}</code>.  The default is None.</p> <code>None</code> <code>method</code> <p>string, optional Two avialble option are- 'all' or 'by_image'. In the event that multiple images were loaded in with distinct 'imageid', users have the option to apply GMM by pooling all data togeather or to apply it to each image independently.  Please be aware of batch effects when passing 'all' to multiple images. In contrast, if there are not enough variation  within individual images, the GMM cannot reliably distinguish between the negative and positive populations as well.  </p> <code>'all'</code> <code>random_state</code> <p>int, optional Seed for GMM. The default is 0.</p> <code>0</code> <p>Returns:</p> Type Description <p>Modified AnnData Object The values in <code>adata.X</code> are replaced with the scaled data. The final gates used for saving the data is also stored in <code>adata.uns['gates']</code></p> <pre><code># create a df with manual gates\nmanual_gate = pd.DataFrame({'marker': ['CD3D', 'KI67'], 'gate': [7, 8]}) \nadata = sm.pp.rescale (adata, gate=manual_gate, failed_markers={'all':['CD20', 'CD21']})\n\n# you could also import the gates as a pandas dataframe without index\nmanual_gate = pd.read_csv('manual_gates.csv')\nadata = sm.pp.rescale (adata, gate=manual_gate, failed_markers={'all':['CD20', 'CD21']})\n\n# The function can also be run without providing manual gates. This will trigger the GMM mode\nadata = sm.pp.rescale (adata, gate=None, failed_markers={'all':['CD20', 'CD21']})\n</code></pre> Source code in <code>scimap/preprocessing/_rescale.py</code> <pre><code>def rescale (adata, gate=None, log=True,\n             imageid='imageid', failed_markers=None,\n              method='all',random_state=0):\n\"\"\"\nParameters:\n\n    adata : AnnData Object  \n\n    gate : dataframe, optional  \n        DataFrame with first column as markers and subsequent column with gate values for each image in the dataset.\n        The column names should correspond to the unique `imageid`. If only one column of gate is provied \n        to a dataset with multiple images, the same gate will be applied to all images.\n        Note: If gates are not provided or left out for a particular marker, the function will try to \n        automatically identify a gate based on applying gaussian mixture modeling algorithm (GMM). The default is None.\n\n    log : bool, optional  \n        By default the data stored in `adata.raw.X` is extracted for scaling. If the user wishes to log transform (log1p)\n        it before applying the gates, this parameter can be set to True. Please note if the function is used to \n        identify gates based on GMM, it is recommended for the data to be log transformed. The default is True.\n\n    imageid : string, optional  \n        The column containing the Image IDs. When passing manual gates the columns of the dataframe need to match \n        to the elements within the passed `imageid` column. The default is 'imageid'.\n\n    failed_markers : dict, optional  \n        Markers that were deemed to have failed based on prior visual inspection. This parameter accepts a python \n        dictionary with `key` as `imageid` and `value` as markers that failed in that particular `imageid`. \n        Example: `failed_markers = {'image_1': ['failed_marker_1'], 'image_2' : ['failed_marker_1', 'failed_marker_2']}`. \n        To make it easier to allow specifying markers that failed in `all` images within the dataset, the parameter also \n        recognizes the special keyword `all`. For example, `failed_markers = {'all': ['failed_marker_X'], 'image_2' : ['failed_marker_1', 'failed_marker_2']}`. \n        The default is None.\n\n    method : string, optional  \n        Two avialble option are- 'all' or 'by_image'. In the event that multiple images were loaded in with distinct 'imageid',\n        users have the option to apply GMM by pooling all data togeather or to apply it to each image independently. \n        Please be aware of batch effects when passing 'all' to multiple images. In contrast, if there are not enough variation \n        within individual images, the GMM cannot reliably distinguish between the negative and positive populations as well.  \n\n    random_state : int, optional  \n        Seed for GMM. The default is 0.\n\nReturns:\n\n    Modified AnnData Object\n        The values in `adata.X` are replaced with the scaled data.\n        The final gates used for saving the data is also stored in `adata.uns['gates']`\n\nExample:\n```python\n# create a df with manual gates\nmanual_gate = pd.DataFrame({'marker': ['CD3D', 'KI67'], 'gate': [7, 8]}) \nadata = sm.pp.rescale (adata, gate=manual_gate, failed_markers={'all':['CD20', 'CD21']})\n\n# you could also import the gates as a pandas dataframe without index\nmanual_gate = pd.read_csv('manual_gates.csv')\nadata = sm.pp.rescale (adata, gate=manual_gate, failed_markers={'all':['CD20', 'CD21']})\n\n# The function can also be run without providing manual gates. This will trigger the GMM mode\nadata = sm.pp.rescale (adata, gate=None, failed_markers={'all':['CD20', 'CD21']})\n\n```\n\n    \"\"\"\n\n    #log=True; imageid='imageid'; failed_markers=None; method='all'; random_state=0\n\n    # make a copy to raw data if raw is none\n    if adata.raw is None:\n        adata.raw = adata\n\n    # Mapping between markers and gates in the given dataset\n    dataset_markers = list(adata.var.index)\n    dataset_images = list(adata.obs[imageid].unique())\n    m= pd.DataFrame(index=dataset_markers, columns=dataset_images).reset_index()\n    m= pd.melt(m, id_vars=[m.columns[0]])\n    m.columns = ['markers', 'imageid', 'gate']\n    # Manipulate m with and without provided manual fates\n    if gate is None:\n        gate_mapping = m.copy()\n    elif bool(set(list(gate.columns)) &amp; set(dataset_images)) is False:\n        global_manual_m = pd.melt(gate, id_vars=[gate.columns[0]])\n        global_manual_m.columns = ['markers', 'imageid', 'm_gate']\n        gate_mapping = m.copy()\n        gate_mapping.gate = gate_mapping.gate.fillna(gate_mapping.markers.map(dict(zip(global_manual_m.markers, global_manual_m.m_gate))))\n    else:\n        manual_m = pd.melt(gate, id_vars=[gate.columns[0]])\n        manual_m.columns = ['markers', 'imageid', 'm_gate']\n        gate_mapping = pd.merge(m, manual_m,  how='left', left_on=['markers','imageid'], right_on = ['markers','imageid'])\n        gate_mapping['gate'] = gate_mapping['gate'].fillna(gate_mapping['m_gate'])\n        gate_mapping = gate_mapping.drop(columns='m_gate')\n\n    # Addressing failed markers\n    def process_failed (adata_subset, foramted_failed_markers):\n        print('Processing Failed Marker in ' + str(adata_subset.obs[imageid].unique()[0]))\n        # prepare data\n        data_subset = pd.DataFrame(adata_subset.raw.X, columns=adata_subset.var.index, index=adata_subset.obs.index)\n        if log is True:\n            data_subset = np.log1p(data_subset)\n\n        # subset markers in the subset\n        fm_sub = foramted_failed_markers[adata_subset.obs[imageid].unique()].dropna()\n\n\n        def process_failed_internal (fail_mark, data_subset):\n            return data_subset[fail_mark].max()\n        r_process_failed_internal = lambda x: process_failed_internal (fail_mark=x,data_subset=data_subset)\n        f_g = list(map(r_process_failed_internal, [ x[0] for x in fm_sub.values]))\n        subset_gate = pd.DataFrame( {'markers': [ x[0] for x in fm_sub.values],  \n                       'imageid': adata_subset.obs[imageid].unique()[0],\n                       'gate': f_g,})     \n        # return\n        return subset_gate\n\n    # Identify the failed markers\n    if failed_markers is not None:\n        # check if failed marker is a dict\n        if isinstance(failed_markers, dict) is False:\n            raise ValueError ('`failed_markers` should be a python dictionary, please refer documentation')\n        # create a copy \n        fm = failed_markers.copy()\n        # seperate all from the rest\n        if 'all' in failed_markers:\n            all_failed = failed_markers['all']\n            if isinstance(all_failed, str):\n                all_failed = [all_failed]\n            failed_markers.pop('all', None)\n\n            df = pd.DataFrame(columns = adata.obs[imageid].unique())\n            for i in range(len(all_failed)):\n                df.loc[i] = np.repeat(all_failed[i], len(df.columns))\n            #for i in  range(len(df.columns)):\n            #    df.loc[i] = all_failed[i]\n        # rest of the failed markers\n        #fail = pd.DataFrame.from_dict(failed_markers)        \n        fail = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in failed_markers.items() ]))\n        # merge\n        if 'all' in fm:\n            foramted_failed_markers = pd.concat([fail, df], axis=0)\n        else: \n            foramted_failed_markers = fail\n\n        # send the adata objects that need to be processed\n        # Check if any image needs to pass through the GMM protocol\n        adata_list = [adata[adata.obs[imageid] == i] for i in foramted_failed_markers.columns]\n        # apply the process_failed function\n        r_process_failed = lambda x: process_failed (adata_subset=x,foramted_failed_markers=foramted_failed_markers)\n        failed_gates = list(map(r_process_failed, adata_list))    \n        # combine the results and merge with gate_mapping\n        result = []\n        for i in range(len(failed_gates)):\n            result.append(failed_gates[i])\n        result = pd.concat(result, join='outer')\n        # use this to merge with gate_mapping\n        x1 = gate_mapping.set_index(['markers', 'imageid'])['gate']\n        x2 = result.set_index(['markers', 'imageid'])['gate']\n        x1.update(x2)\n        gate_mapping = x1.reset_index()\n\n    # trim the data before applying GMM\n    def clipping (x):\n        clip = x.clip(lower =np.percentile(x,0.01), upper=np.percentile(x,99.99)).tolist()\n        return clip\n\n    # Find GMM based gates\n    def gmm_gating (marker, data):\n        print('Finding the optimal gate by GMM for ' + str(marker))\n        data_gm = data[marker].values.reshape(-1, 1)\n        gmm = GaussianMixture(n_components=2, random_state=random_state).fit(data_gm)\n        gate = np.mean(gmm.means_)\n        return gate\n\n    # Running gmm_gating on the dataset\n    def gmm_gating_internal (adata_subset, gate_mapping, method):\n        print('GMM for ' + str(adata_subset.obs[imageid].unique()))\n        data_subset = pd.DataFrame(adata_subset.raw.X, columns=adata_subset.var.index, index=adata_subset.obs.index)      \n        # find markers\n        if method == 'all':\n            image_specific = gate_mapping.copy()\n            marker_to_gate = list(gate_mapping[gate_mapping.gate.isnull()].markers.unique())\n        else:        \n            image_specific = gate_mapping[gate_mapping['imageid'].isin(adata_subset.obs[imageid].unique())]\n            marker_to_gate = image_specific[image_specific.gate.isnull()].markers.values   \n        # Apply clipping\n        data_subset_clipped = data_subset.apply(clipping)\n        # log transform data\n        if log is True:\n            data_subset_clipped = np.log1p(data_subset_clipped)\n        # identify the gates for the markers\n        r_gmm_gating = lambda x: gmm_gating(marker=x, data=data_subset_clipped) \n        gates = list(map(r_gmm_gating, marker_to_gate))     \n        # create a df with results\n        result = image_specific[image_specific.gate.isnull()]\n        mapping = dict(zip(marker_to_gate, gates))\n        for i in result.index:\n            result.loc[i, 'gate'] = mapping[result.loc[i, 'markers']]\n        #result['gate'] = result['gate'].fillna(result['markers'].map(dict(zip(marker_to_gate, gates))))        \n        # return\n        return result\n\n\n    # Create a list of image IDs that need to go through the GMM\n    gmm_images = gate_mapping[gate_mapping.gate.isnull()].imageid.unique()  \n\n    # Check if any image needs to pass through the GMM protocol\n    if len(gmm_images) &gt; 0 :\n        # Create a list of adata that need to go through the GMM\n        if method == 'all':\n            adata_list = [adata]\n        else:\n            adata_list = [adata[adata.obs[imageid] == i] for i in gmm_images]\n        # run function\n        r_gmm_gating_internal = lambda x: gmm_gating_internal (adata_subset=x, \n                                                               gate_mapping=gate_mapping,\n                                                               method=method) \n        all_gates = list(map(r_gmm_gating_internal, adata_list))\n\n        # combine the results and merge with gate_mapping\n        result = []\n        for i in range(len(all_gates)):\n            result.append(all_gates[i])\n        result = pd.concat(result, join='outer')\n        # use this to merge with gate_mapping\n        gate_mapping.gate = gate_mapping.gate.fillna(gate_mapping.markers.map(dict(zip(result.markers, result.gate))))\n\n\n    # Rescaling function\n    def data_scaler (adata_subset, gate_mapping):\n        print('Scaling Image ' + str(adata_subset.obs[imageid].unique()[0]))\n        # Organise data\n        data_subset = pd.DataFrame(adata_subset.raw.X, columns=adata_subset.var.index, index=adata_subset.obs.index)\n        if log is True:\n            data_subset = np.log1p(data_subset)\n        # subset markers in the subset\n        gate_mapping_sub = gate_mapping[gate_mapping['imageid'] == adata_subset.obs[imageid].unique()[0]]\n\n        # organise gates\n        def data_scaler_internal (marker, gate_mapping_sub):\n            print('Scaling ' + str(marker))\n            # find the gate\n            moi = gate_mapping_sub[gate_mapping_sub.markers == marker]['gate'].values[0]\n\n            # Find the closest value to the gate\n            absolute_val_array = np.abs(data_subset[marker].values - float(moi))\n            # throw error if the array has nan values\n            if np.isnan(absolute_val_array).any():\n                raise ValueError (\"An exception occurred: \" + str(marker) + ' has nan values')\n            # smallest diff\n            smallest_difference_index = absolute_val_array.argmin()\n            closest_element = data_subset[marker].values[smallest_difference_index]\n\n            # rescale the data based on the identified gate\n            marker_study = data_subset[marker]\n            marker_study = marker_study.sort_values(axis=0)\n            # Find the index of the gate\n            # account for 0\n            if all(marker_study == 0):\n                gate_index = pd.DataFrame(marker_study).tail(2).index[0]\n            else:\n                gate_index = marker_study.index[marker_study == closest_element][0]\n            # Split into high and low groups\n            high = marker_study[gate_index:]\n            low = marker_study[:gate_index]\n            # Prepare for scaling the high and low dataframes\n            scaler_high = MinMaxScaler(feature_range=(0.5, 1))\n            scaler_low = MinMaxScaler(feature_range=(0, 0.5))\n            # Scale it\n            h = pd.DataFrame(scaler_high.fit_transform(high.values.reshape(-1, 1)), index = high.index)\n            l = pd.DataFrame(scaler_low.fit_transform(low.values.reshape(-1, 1)), index = low.index)\n            # Merge the high and low and resort it\n            scaled_data = pd.concat([l,h])\n            scaled_data = scaled_data.loc[~scaled_data.index.duplicated(keep='first')]\n            scaled_data = scaled_data.reindex(data_subset.index)\n            #scaled_data[scaled_data &gt; 0.5].count(axis=1).sum()\n            # return\n            return scaled_data\n\n        # run internal function\n        r_data_scaler_internal = lambda x: data_scaler_internal (marker=x, gate_mapping_sub=gate_mapping_sub) \n        scaled_subset = list(map(r_data_scaler_internal, gate_mapping_sub.markers.values))\n\n        # combine the results and merge with gate_mapping\n        scaled_subset_result = []\n        for i in range(len(scaled_subset)):\n            scaled_subset_result.append(scaled_subset[i])\n        scaled_subset_result = pd.concat(scaled_subset_result, join='outer', axis=1)\n        scaled_subset_result.columns = gate_mapping_sub.markers.values\n        #scaled_subset_result[scaled_subset_result['CD3E'] &gt; 0.5]['CD3E'].count(axis=1).sum()\n\n        # return\n        return scaled_subset_result\n\n    # pass each dataset seperately\n    adata_list = [adata[adata.obs[imageid] == i] for i in adata.obs[imageid].unique()]\n\n    # Run the scaler function\n    r_data_scaler = lambda x: data_scaler (adata_subset=x, gate_mapping=gate_mapping) \n    scaled_subset = list(map(r_data_scaler, adata_list))  \n\n    # combine the results and merge with gate_mapping\n    final_result = []\n    for i in range(len(scaled_subset)):\n        final_result.append(scaled_subset[i])\n    final_result = pd.concat(final_result, join='outer')\n\n    # reindex the final_results\n    final_result = final_result.reindex(adata.obs.index)\n\n    # save final gates\n    adata.uns['gates'] = gate_mapping.pivot_table(index=['markers'], columns=['imageid']).droplevel(0, axis=1)#.reset_index()\n\n    # add to the anndata\n    adata.X = final_result\n\n    # return adata\n    return adata\n</code></pre>"},{"location":"Functions/tl/cluster/","title":"cluster","text":"<p>Short Description</p> <p><code>sm.tl.cluster</code>: This function allows users to cluster the dataset.  The function supports four clustering algorithm (kmeans, phenograph, leiden and parc).</p>"},{"location":"Functions/tl/cluster/#scimap.tools._cluster--function","title":"Function","text":""},{"location":"Functions/tl/cluster/#scimap.tools._cluster.cluster","title":"<code>cluster(adata, method='kmeans', subset_genes=None, sub_cluster=False, sub_cluster_column='phenotype', sub_cluster_group=None, parc_small_pop=50, parc_too_big_factor=0.4, k=10, n_pcs=None, resolution=1, phenograph_clustering_metric='euclidean', nearest_neighbors=30, use_raw=True, log=True, random_state=0, collapse_labels=False, label=None, output_dir=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData Object</p> required <code>method</code> <p>string, optional Clustering method to be used- Implemented methods- kmeans, phenograph, leiden and parc.</p> <code>'kmeans'</code> <code>subset_genes</code> <p>list, optional Pass a list of genes ['CD3D', 'CD20', 'KI67'] that should be included for the purpose of clustering.  By default the algorithm uses all genes in the dataset.</p> <code>None</code> <code>sub_cluster</code> <p>Boolian, optional If the user has already performed clustering or phenotyping previously and would like to sub-cluster within a particular cluster/phenotype, this option can be used.</p> <code>False</code> <code>sub_cluster_column</code> <p>string, optional The column name that contains the cluster/phenotype information to be sub-clustered.  This is only required when sub_cluster is set to True.</p> <code>'phenotype'</code> <code>sub_cluster_group</code> <p>list, optional By default the program will sub-cluster all groups within column passed through the argument sub_cluster_column. If user wants to sub cluster only a subset of phenotypes/clusters this option can be used. Pass them as list e.g. [\"tumor\", \"b cells\"].     </p> <code>None</code> <code>parc_small_pop</code> <p>int, optional Smallest cluster population to be considered a community in PARC clustering.</p> <code>50</code> <code>parc_too_big_factor</code> <p>float, optional If a cluster exceeds this share of the entire cell population, then the PARC will be run on  the large cluster. at 0.4 it does not come into play.</p> <code>0.4</code> <code>k</code> <p>int, optional Number of clusters to return when using K-Means clustering.</p> <code>10</code> <code>n_pcs</code> <p>int, optional Number of PC's to be used in leiden clustering. By default it uses all PC's.</p> <code>None</code> <code>resolution</code> <p>float, optional A parameter value controlling the coarseness of the clustering.  Higher values lead to more clusters.</p> <code>1</code> <code>phenograph_clustering_metric</code> <p>string, optional Distance metric to define nearest neighbors. Note that performance will be slower for correlation and cosine.  Available methods- cityblock\u2019, \u2018cosine\u2019, \u2018euclidean\u2019, \u2018manhattan\u2019, braycurtis\u2019, \u2018canberra\u2019, \u2018chebyshev\u2019,  \u2018correlation\u2019, \u2018dice\u2019, \u2018hamming\u2019, \u2018jaccard\u2019, \u2018kulsinski\u2019, \u2018mahalanobis\u2019, \u2018minkowski\u2019, \u2018rogerstanimoto\u2019,  \u2018russellrao\u2019, \u2018seuclidean\u2019, \u2018sokalmichener\u2019, \u2018sokalsneath\u2019, \u2018sqeuclidean\u2019, \u2018yule\u2019</p> <code>'euclidean'</code> <code>nearest_neighbors</code> <p>int, optional Number of nearest neighbors to use in first step of graph construction.  This parameter is used both in leiden and phenograph clustering.</p> <code>30</code> <code>use_raw</code> <p>bool, optional If True, raw data will be used for clustering.  If False, normalized/scaled data within <code>adata.X</code> will be used.</p> <code>True</code> <code>log</code> <p>boolian, optional If <code>True</code>, the log of raw data is used. Set use_raw = <code>True</code> for this to take effect. </p> <code>True</code> <code>random_state</code> <p>int, optional Change the initialization of the optimization.</p> <code>0</code> <code>collapse_labels</code> <p>bool, optional While sub clustering only a few phenotypes/clusters, this argument helps to  group all the other phenotypes/clusters into a single category-  Helps in visualisation.</p> <code>False</code> <code>label</code> <p>string, optional Key or optional column name for the returned data, stored in <code>adata.obs</code>. The default is adata.obs [method used].</p> <code>None</code> <code>output_dir</code> <p>string, optional Path to output directory.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>adata</code> <p>AnnData Object Returns an updated <code>anndata</code> object with a new column. check- adata.obs [method used]</p> <pre><code>    adata = sm.tl.cluster (adata, k= 10, method = 'kmeans', \n    sub_cluster_column='phenotype', use_raw = True)\n</code></pre> Source code in <code>scimap/tools/_cluster.py</code> <pre><code>def cluster (adata, method='kmeans', subset_genes=None,\n             sub_cluster=False, sub_cluster_column='phenotype', sub_cluster_group = None,\n             parc_small_pop= 50, parc_too_big_factor=0.4, \n             k= 10, n_pcs=None, resolution=1, \n             phenograph_clustering_metric='euclidean', nearest_neighbors= 30, \n             use_raw=True, log=True, random_state=0, collapse_labels= False,\n             label=None, output_dir=None):\n\"\"\"\n\nParameters:\n\n    adata : AnnData Object\n\n    method : string, optional  \n        Clustering method to be used- Implemented methods- kmeans, phenograph, leiden and parc.\n\n    subset_genes : list, optional  \n        Pass a list of genes ['CD3D', 'CD20', 'KI67'] that should be included for the purpose of clustering. \n        By default the algorithm uses all genes in the dataset.\n\n    sub_cluster : Boolian, optional  \n        If the user has already performed clustering or phenotyping previously and would like to\n        sub-cluster within a particular cluster/phenotype, this option can be used.\n\n    sub_cluster_column : string, optional  \n        The column name that contains the cluster/phenotype information to be sub-clustered. \n        This is only required when sub_cluster is set to True.\n\n    sub_cluster_group : list, optional  \n        By default the program will sub-cluster all groups within column passed through the argument sub_cluster_column.\n        If user wants to sub cluster only a subset of phenotypes/clusters this option can be used.\n        Pass them as list e.g. [\"tumor\", \"b cells\"].     \n\n    parc_small_pop : int, optional  \n        Smallest cluster population to be considered a community in PARC clustering.\n\n    parc_too_big_factor : float, optional  \n        If a cluster exceeds this share of the entire cell population, then the PARC will be run on \n        the large cluster. at 0.4 it does not come into play.\n\n    k : int, optional  \n        Number of clusters to return when using K-Means clustering.\n\n    n_pcs : int, optional  \n        Number of PC's to be used in leiden clustering. By default it uses all PC's.\n\n    resolution : float, optional  \n        A parameter value controlling the coarseness of the clustering. \n        Higher values lead to more clusters.\n\n    phenograph_clustering_metric : string, optional  \n        Distance metric to define nearest neighbors. Note that performance will be slower for correlation and cosine. \n        Available methods- cityblock\u2019, \u2018cosine\u2019, \u2018euclidean\u2019, \u2018manhattan\u2019, braycurtis\u2019, \u2018canberra\u2019, \u2018chebyshev\u2019, \n        \u2018correlation\u2019, \u2018dice\u2019, \u2018hamming\u2019, \u2018jaccard\u2019, \u2018kulsinski\u2019, \u2018mahalanobis\u2019, \u2018minkowski\u2019, \u2018rogerstanimoto\u2019, \n        \u2018russellrao\u2019, \u2018seuclidean\u2019, \u2018sokalmichener\u2019, \u2018sokalsneath\u2019, \u2018sqeuclidean\u2019, \u2018yule\u2019\n\n    nearest_neighbors : int, optional  \n        Number of nearest neighbors to use in first step of graph construction. \n        This parameter is used both in leiden and phenograph clustering.\n\n    use_raw : bool, optional  \n        If True, raw data will be used for clustering. \n        If False, normalized/scaled data within `adata.X` will be used.\n\n    log : boolian, optional  \n        If `True`, the log of raw data is used. Set use_raw = `True` for this to take effect. \n\n    random_state : int, optional  \n        Change the initialization of the optimization.\n\n    collapse_labels : bool, optional  \n        While sub clustering only a few phenotypes/clusters, this argument helps to \n        group all the other phenotypes/clusters into a single category- \n        Helps in visualisation.\n\n    label : string, optional  \n        Key or optional column name for the returned data, stored in `adata.obs`. The default is adata.obs [method used].\n\n    output_dir : string, optional  \n        Path to output directory.\n\n\nReturns:\n\n    adata : AnnData Object\n        Returns an updated `anndata` object with a new column. check- adata.obs [method used]\n\nExample:\n\n```python\n    adata = sm.tl.cluster (adata, k= 10, method = 'kmeans', \n    sub_cluster_column='phenotype', use_raw = True)\n```\n\n    \"\"\"\n\n    # Load the andata object    \n    if isinstance(adata, str):\n        imid = str(adata.rsplit('/', 1)[-1])\n        adata = anndata.read(adata)\n    else:\n        adata = adata\n\n    # dynamically adapt the number of neighbours\n    if nearest_neighbors &gt; adata.shape[0]:\n        nearest_neighbors = adata.shape[0] - 3\n\n\n    # Leiden clustering\n    def leiden_clustering (pheno, adata, nearest_neighbors, n_pcs, resolution):\n\n        # subset the data to be clustered\n        if pheno is not None:\n            cell_subset =  adata.obs[adata.obs[sub_cluster_column] == pheno].index\n        else:\n            cell_subset = adata.obs.index\n\n        if use_raw == True:\n            data_subset = adata[cell_subset]\n            if log is True:\n                data_subset.X = np.log1p(data_subset.raw.X)          \n            else:\n                data_subset.X = data_subset.raw.X\n        else:\n            data_subset = adata[cell_subset]\n\n        # clustering\n        if pheno is not None:\n            print('Leiden clustering ' + str(pheno))\n        else:\n            print('Leiden clustering')\n\n        sc.tl.pca(data_subset)\n        if n_pcs is None:\n            n_pcs = len(adata.var)\n        sc.pp.neighbors(data_subset, n_neighbors=nearest_neighbors, n_pcs=n_pcs)\n        sc.tl.leiden(data_subset,resolution=resolution, random_state=random_state)\n\n        # Rename the labels\n        cluster_labels = list(map(str,list(data_subset.obs['leiden'])))\n        if pheno is not None:\n            cluster_labels = list(map(lambda orig_string: pheno + '-' + orig_string, cluster_labels))\n\n        # Make it into a dataframe\n        cluster_labels = pd.DataFrame(cluster_labels, index = data_subset.obs.index)\n\n        # return labels\n        return cluster_labels\n\n    # Kmeans clustering\n    def k_clustering (pheno, adata, k, sub_cluster_column, use_raw, random_state):\n\n        # subset the data to be clustered\n        if pheno is not None:\n            cell_subset =  adata.obs[adata.obs[sub_cluster_column] == pheno].index\n        else:\n            cell_subset = adata.obs.index\n\n        # Usage of scaled or raw data\n        if use_raw == True:\n            if log is True:\n                data_subset = pd.DataFrame(np.log1p(adata.raw[cell_subset].X), columns =adata[cell_subset].var.index, index = adata[cell_subset].obs.index)\n            else:\n                data_subset = pd.DataFrame(adata.raw[cell_subset].X, columns =adata[cell_subset].var.index, index = adata[cell_subset].obs.index)\n        else:\n            data_subset = pd.DataFrame(adata[cell_subset].X, columns =adata[cell_subset].var.index, index = adata[cell_subset].obs.index)\n\n        # K-means clustering\n        if pheno is not None:\n            print('Kmeans clustering ' + str(pheno))\n        else:\n            print('Kmeans clustering')\n\n        kmeans = KMeans(n_clusters=k, random_state=random_state).fit(data_subset)\n\n        # Rename the labels\n        cluster_labels = list(map(str,kmeans.labels_))\n        if pheno is not None:\n            cluster_labels = list(map(lambda orig_string: pheno + '-' + orig_string, cluster_labels))\n\n        # Make it into a \n        cluster_labels = pd.DataFrame(cluster_labels, index = data_subset.index)\n\n        # return labels\n        return cluster_labels\n\n    # Phenograph clustering\n    def phenograph_clustering (pheno, adata, primary_metric, nearest_neighbors):\n\n        # subset the data to be clustered\n        if pheno is not None:\n            cell_subset =  adata.obs[adata.obs[sub_cluster_column] == pheno].index\n        else:\n            cell_subset = adata.obs.index\n\n        # Usage of scaled or raw data\n        if use_raw == True:\n            data_subset = adata[cell_subset]\n            if log is True:\n                data_subset.X = np.log1p(data_subset.raw.X)          \n            else:\n                data_subset.X = data_subset.raw.X\n        else:\n            data_subset = adata[cell_subset]\n\n        # Phenograph clustering\n        if pheno is not None:\n            print('Phenograph clustering ' + str(pheno))\n        else:\n            print('Phenograph clustering')\n\n        sc.tl.pca(data_subset)\n        result = sce.tl.phenograph(data_subset.obsm['X_pca'], k = nearest_neighbors, primary_metric=phenograph_clustering_metric)\n\n        # Rename the labels\n        cluster_labels = list(map(str,result[0]))\n        if pheno is not None:\n            cluster_labels = list(map(lambda orig_string: pheno + '-' + orig_string, cluster_labels))\n\n        # Make it into a dataframe\n        cluster_labels = pd.DataFrame(cluster_labels, index = data_subset.obs.index)\n\n        # return labels\n        return cluster_labels\n\n\n    # PARC clustering\n    # https://github.com/ShobiStassen/PARC\n    def parc_clustering (pheno, adata, random_state,resolution,parc_too_big_factor,parc_small_pop):\n\n        # subset the data to be clustered\n        if pheno is not None:\n            cell_subset =  adata.obs[adata.obs[sub_cluster_column] == pheno].index\n        else:\n            cell_subset = adata.obs.index\n\n        # Usage of scaled or raw data\n        if use_raw == True:\n            data_subset = adata[cell_subset]\n            if log is True:\n                data_subset.X = np.log1p(data_subset.raw.X)\n            else:\n                data_subset.X = data_subset.raw.X      \n        else:\n            data_subset = adata[cell_subset]\n\n        # Phenograph clustering\n        if pheno is not None:\n            print('Parc clustering ' + str(pheno))\n        else:\n            print('Parc clustering')\n\n        sc.tl.pca(data_subset)\n        parc1 = parc.PARC(data_subset.obsm['X_pca'], random_seed=random_state, parc_small_pop = parc_small_pop, resolution_parameter=resolution,parc_too_big_factor=parc_too_big_factor)  \n        parc1.run_PARC() # Run Parc\n\n\n        # Rename the labels\n        cluster_labels = list(map(str,parc1.labels))\n        if pheno is not None:\n            cluster_labels = list(map(lambda orig_string: pheno + '-' + orig_string, cluster_labels))\n\n        # Make it into a dataframe\n        cluster_labels = pd.DataFrame(cluster_labels, index = data_subset.obs.index)\n\n        # return labels\n        return cluster_labels\n\n    # Use user defined genes for clustering\n    if subset_genes is not None:\n        bdata = adata[:,subset_genes]\n        bdata.raw = bdata[:,subset_genes]\n    else:\n        bdata = adata.copy()\n\n    # IF sub-cluster is True\n    # What cells to run the clustering on?\n    if sub_cluster is True:\n        if sub_cluster_group is not None:\n            if isinstance(sub_cluster_group, list):\n                pheno = sub_cluster_group\n            else:\n                pheno = [sub_cluster_group]         \n        else:\n            # Make sure number of clusters is not greater than number of cells available\n            if method == 'kmeans':\n                pheno = (bdata.obs[sub_cluster_column].value_counts() &gt; k+1).index[bdata.obs[sub_cluster_column].value_counts() &gt; k+1]\n            if method == 'phenograph':\n                pheno = (bdata.obs[sub_cluster_column].value_counts() &gt; nearest_neighbors+1).index[bdata.obs[sub_cluster_column].value_counts() &gt; nearest_neighbors+1]\n            if method == 'leiden':\n                pheno = (bdata.obs[sub_cluster_column].value_counts() &gt; 1).index[bdata.obs[sub_cluster_column].value_counts() &gt; 1]\n            if method == 'parc':\n                pheno = (bdata.obs[sub_cluster_column].value_counts() &gt; 1).index[bdata.obs[sub_cluster_column].value_counts() &gt; 1]\n\n\n    # Run the specified method\n    if method == 'kmeans':\n        if sub_cluster == True:  \n            # Apply the Kmeans function\n            r_k_clustering = lambda x: k_clustering(pheno=x, adata=bdata, k=k, sub_cluster_column=sub_cluster_column, use_raw=use_raw, random_state=random_state) # Create lamda function \n            all_cluster_labels = list(map(r_k_clustering, pheno)) # Apply function \n        else:\n            all_cluster_labels = k_clustering(pheno=None, adata=bdata, k=k, sub_cluster_column=sub_cluster_column, use_raw=use_raw, random_state=random_state)\n\n    if method == 'phenograph':\n        if sub_cluster == True:\n            r_phenograph_clustering = lambda x: phenograph_clustering(pheno=x, adata=bdata, primary_metric=phenograph_clustering_metric, nearest_neighbors=nearest_neighbors) # Create lamda function \n            all_cluster_labels = list(map(r_phenograph_clustering, pheno)) # Apply function      \n        else:\n            all_cluster_labels = phenograph_clustering(pheno=None, adata=bdata, primary_metric=phenograph_clustering_metric, nearest_neighbors=nearest_neighbors)\n\n\n    if method == 'leiden':\n        if sub_cluster == True:\n            r_leiden_clustering = lambda x: leiden_clustering(pheno=x, adata=bdata, nearest_neighbors=nearest_neighbors, n_pcs=n_pcs, resolution=resolution) # Create lamda function \n            all_cluster_labels = list(map(r_leiden_clustering, pheno)) # Apply function \n        else:\n            all_cluster_labels = leiden_clustering(pheno=None, adata=bdata, nearest_neighbors=nearest_neighbors, n_pcs=n_pcs, resolution=resolution)\n\n\n    if method == 'parc':\n        if sub_cluster == True:\n            r_parc_clustering = lambda x: parc_clustering(pheno=x, adata=bdata, random_state=random_state,resolution=resolution,parc_too_big_factor=parc_too_big_factor,parc_small_pop=parc_small_pop) # Create lamda function \n            all_cluster_labels = list(map(r_parc_clustering, pheno)) # Apply function \n        else:\n            all_cluster_labels = parc_clustering(pheno=None, adata=bdata, random_state=random_state,resolution=resolution,parc_too_big_factor=parc_too_big_factor,parc_small_pop=parc_small_pop)\n\n\n    # Merge all the labels into one and add to adata\n    if sub_cluster == True:\n        sub_clusters = pd.concat(all_cluster_labels, axis=0, sort=False)\n    else:\n        sub_clusters = all_cluster_labels\n\n    # Merge with all cells\n    #sub_clusters = pd.DataFrame(bdata.obs[sub_cluster_column]).merge(sub_clusters, how='outer', left_index=True, right_index=True)\n    sub_clusters = pd.DataFrame(bdata.obs).merge(sub_clusters, how='outer', left_index=True, right_index=True)\n\n\n    # Transfer labels\n    if collapse_labels is False and sub_cluster is True:\n        sub_clusters = pd.DataFrame(sub_clusters[0].fillna(sub_clusters[sub_cluster_column]))\n\n\n    # Get only the required column\n    sub_clusters = sub_clusters[0]\n\n    # re index the rows\n    sub_clusters = sub_clusters.reindex(adata.obs.index)\n\n    # Append to adata\n    if label is None:\n        adata.obs[method] = sub_clusters\n    else:\n        adata.obs[label] = sub_clusters\n\n    # Save data if requested\n    if output_dir is not None:\n        output_dir = pathlib.Path(output_dir)\n        output_dir.mkdir(exist_ok=True, parents=True)\n        adata.write(output_dir / imid)\n    else:    \n        # Return data\n        return adata\n</code></pre>"},{"location":"Functions/tl/foldchange/","title":"foldchange","text":"<p>Short Description</p> <p><code>sm.tl.foldchange</code>: The function allows users to compute the foldchange (fc) in cell-type (phenotype) abundance  between samples or ROI's. </p> <p>The reference sample or ROI needs to be passed via the <code>from_group</code> parameter.  The column name of <code>from_group</code> should be passed via <code>imageid</code>. The function computes the fc  to all other categories within the same <code>imageid</code> column. By default (can be turned off), the cell-abundance will be normalized for the total number of cells within the sample/ROI to account for difference in area. A <code>fisher-exact-test</code> is performed to compute the p-values.</p> <p>The results are stored in <code>.uns</code> section of the anndata object. </p>"},{"location":"Functions/tl/foldchange/#scimap.tools._foldchange--function","title":"Function","text":""},{"location":"Functions/tl/foldchange/#scimap.tools._foldchange.foldchange","title":"<code>foldchange(adata, from_group, to_group=None, imageid='imageid', phenotype='phenotype', normalize=True, subset_phenotype=None, label='foldchange')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData object</p> required <code>from_group</code> <p>list, required Pass in the name of the sample or ROI that will serve as a reference for calculating fold change. If multiple sample names or ROI's are passed in as a list e.g. ['ROI1', 'ROI2''], please note that they will be combined for calculating the fold change. </p> required <code>to_group</code> <p>list, optional By default the reference sample/ROI passed via <code>from_group</code> will be compared to all other groups within the same column. However if users wish to restrict the comparision to a subset of samples/ROI's they can be passed though this paramenter as a list. e.g. ['ROI3', 'ROI4']. </p> <code>None</code> <code>imageid</code> <p>string, optional The column that contains the samples/ROI information.</p> <code>'imageid'</code> <code>phenotype</code> <p>string, optional The column that contains the cell-type/phenotype information.</p> <code>'phenotype'</code> <code>normalize</code> <p>bool, optional Inorder to account for the sample/ROI area, the cellular abundance is first normalized to the total number of cells within the respective sample/ROI. Please note if you pass values in <code>subset_phenotype</code>, the abundance normalization is restricted to the total cells of the  cell types passed in via <code>subset_phenotype</code>.</p> <code>True</code> <code>subset_phenotype</code> <p>list, optional If users are interested in only a subset of cell-types, the names of those can be passed in through this parameter. The data is subsetted to include only these cell types before computing foldchange.</p> <code>None</code> <code>label</code> <p>string, optional Key for the returned data, stored in <code>adata.uns</code>. The foldchange and p-values  are returned seperately with the postfix <code>_fc</code> and <code>_pval</code>. </p> <code>'foldchange'</code> <p>Returns:</p> Name Type Description <code>adata</code> <p>Updated anndata object Check <code>adata.uns['foldchange_fc']</code> and <code>adata.uns['foldchange_pval']</code> for results.</p> Example <pre><code>adata = sm.tl.foldchange (adata, from_group='image_1', to_group=None, \n                          imageid='imageid', phenotype='phenotype',\n                          normalize=True, \n                          subset_phenotype=['Tcells','Bcells','Macs'], \n                          label='foldchange')\n</code></pre> Source code in <code>scimap/tools/_foldchange.py</code> <pre><code>def foldchange (adata, from_group, to_group=None, imageid='imageid', phenotype='phenotype',\n                normalize=True, subset_phenotype=None, label='foldchange'):\n\"\"\"\n\n\nParameters:\n    adata : AnnData object\n\n    from_group : list, required  \n        Pass in the name of the sample or ROI that will serve as a reference for calculating fold change.\n        If multiple sample names or ROI's are passed in as a list e.g. ['ROI1', 'ROI2''], please note that\n        they will be combined for calculating the fold change. \n\n    to_group : list, optional  \n        By default the reference sample/ROI passed via `from_group` will be compared to all other groups\n        within the same column. However if users wish to restrict the comparision to a subset of\n        samples/ROI's they can be passed though this paramenter as a list. e.g. ['ROI3', 'ROI4']. \n\n    imageid : string, optional  \n        The column that contains the samples/ROI information.\n\n    phenotype : string, optional  \n        The column that contains the cell-type/phenotype information.\n\n    normalize : bool, optional  \n        Inorder to account for the sample/ROI area, the cellular abundance is first normalized\n        to the total number of cells within the respective sample/ROI. Please note if you pass values in\n        `subset_phenotype`, the abundance normalization is restricted to the total cells of the \n        cell types passed in via `subset_phenotype`.\n\n    subset_phenotype : list, optional  \n        If users are interested in only a subset of cell-types, the names of those can be passed in through\n        this parameter. The data is subsetted to include only these cell types before computing foldchange.\n\n    label : string, optional  \n        Key for the returned data, stored in `adata.uns`. The foldchange and p-values \n        are returned seperately with the postfix `_fc` and `_pval`. \n\nReturns:\n    adata : Updated anndata object\n        Check `adata.uns['foldchange_fc']` and `adata.uns['foldchange_pval']` for results.\n\n\nExample:\n    ```python\n    adata = sm.tl.foldchange (adata, from_group='image_1', to_group=None, \n                              imageid='imageid', phenotype='phenotype',\n                              normalize=True, \n                              subset_phenotype=['Tcells','Bcells','Macs'], \n                              label='foldchange')\n\n    ```\n\n\n    \"\"\"\n\n    # prepare data\n    data = adata.obs[[imageid,phenotype]]\n\n    # convert from and to groups to list\n    if isinstance(from_group, str):\n        from_group = [from_group]\n    if isinstance(to_group, str):\n        to_group = [to_group]\n\n    # subset phenotype of interest\n    if subset_phenotype is not None:\n        if isinstance (subset_phenotype, str):\n            subset_phenotype = [subset_phenotype]\n        data = data[data[phenotype].isin(subset_phenotype)]\n\n    # subset data    \n    from_data = data[data[imageid].isin(from_group)]\n    if len(from_group) &gt; 1:\n        combined_name = '_'.join(from_group)\n        from_data[imageid] = combined_name\n    from_data[imageid] = from_data[imageid].astype('str').astype('category')\n    from_data[phenotype] = from_data[phenotype].astype('str').astype('category')\n    if to_group is None:\n        to_data = data[~data[imageid].isin(from_group)]\n    else:\n        to_data = data[data[imageid].isin(to_group)]\n    to_data[imageid] = to_data[imageid].astype('str').astype('category')\n    to_data[phenotype] = to_data[phenotype].astype('str').astype('category')\n\n    # consolidated counts dataframe\n    from_data_consolidated = pd.DataFrame(from_data.groupby([imageid,phenotype]).size()).unstack().fillna(0)\n    from_data_consolidated.columns = np.unique(from_data_consolidated.columns.get_level_values(1))\n\n    to_data_consolidated = pd.DataFrame(to_data.groupby([imageid,phenotype]).size()).unstack().fillna(0)\n    to_data_consolidated.columns = np.unique(to_data_consolidated.columns.get_level_values(1))\n\n    # make backup of the sample names\n    from_b = list(from_data_consolidated.index)\n    to_b = list(to_data_consolidated.index)\n\n    # make sure from_data_consolidated and to_data_consolidated has the same columns\n    x = from_data_consolidated.T\n    x.columns = x.columns.astype(str)\n    y = to_data_consolidated.T\n    y.columns = y.columns.astype(str)\n    consolidated = x.merge(y, how='outer', left_index=True, right_index=True).fillna(0)\n\n    # split it back into from and to\n    from_data_consolidated = consolidated[from_b].T\n    to_data_consolidated = consolidated[to_b].T\n\n    # create the total minus to and from tables\n    from_data_total = abs(from_data_consolidated.sub( from_data_consolidated.sum(axis=1), axis=0))\n    to_data_total = abs(to_data_consolidated.sub( to_data_consolidated.sum(axis=1), axis=0))\n\n    # \n    print('calculating P values')\n    p_vals = []\n    for i in from_data_consolidated.columns:\n        a = from_data_consolidated[i][0]\n        c = from_data_total[i][0]\n        for j in to_data_consolidated.index:\n            b = to_data_consolidated[i][j]\n            d = to_data_total[i][j]\n            oddsratio, pvalue = stats.fisher_exact([[a, b], [c, d]])\n            p_vals.append(pvalue)\n\n    # replace 0 with a small number (1 cell) to avoind inf\n    from_data_consolidated_zero = from_data_consolidated.replace(0, 1, inplace=False)\n    to_data_consolidated_zero = to_data_consolidated.replace(0, 1, inplace=False)\n\n    # normalize based on area i.e total cells if user requests\n    if normalize is True:\n        # Normalize for total cells\n        from_data_ratio = from_data_consolidated_zero.div(from_data_consolidated_zero.sum(axis=1), axis=0)\n        to_data_ratio = to_data_consolidated_zero.div(to_data_consolidated_zero.sum(axis=1), axis=0)   \n    else:\n        from_data_ratio = from_data_consolidated_zero\n        to_data_ratio = to_data_consolidated_zero\n\n    # foldchange\n    fold_change = to_data_ratio.div(from_data_ratio.values,  axis=1)\n    fold_change.index.name = '-'.join(from_group)\n\n    # reshape the pvalues to the todata df\n    p_values = np.reshape(p_vals, to_data_consolidated.shape)\n    p_values = pd.DataFrame(p_values, columns = to_data_consolidated.columns, index= to_data_consolidated.index)\n\n    # return data\n    adata.uns[str(label)+'_pval'] = p_values\n    adata.uns[str(label)+'_fc'] = fold_change\n\n    return adata\n</code></pre>"},{"location":"Functions/tl/phenotype_cells/","title":"phenotype_cells","text":"<p>Short Description</p> <p><code>sm.tl.phenotype_cells</code>: The phenotyping function takes in the <code>scaled data</code> and a prior knowledge based <code>phenotype workflow</code>  file to assign phenotype annotation to each cell in the dataset. Use the <code>sm.tl.rescale</code> function to scale the data first. </p> <p>Phenotype workflow file description: An example of the <code>phenotype_workflow.csv</code> can be found here.  </p> <p>The <code>phenotype_workflow</code> accepts six categories of gating strategy for performing phenotyping.</p> <ul> <li>allpos</li> <li>allneg</li> <li>anypos</li> <li>anyneg</li> <li>pos</li> <li>neg</li> </ul> <p><code>allpos</code>- All of the defined markers should be positive. <code>allneg</code>- All of the defined markers should be negative. <code>anypos</code>- Any one of the defined marker is sufficient to be positive. (e.g) For defining macrophages, one could use a strategy in which a cell is defined as a macrophage if any of <code>CD68, CD163 or CD206</code> is positive. <code>anyneg</code>- Any of the defined marker is negative. <code>pos</code>- A given marker is positive. If this argument is passed to multiple markers. (e.g) If regulatory T cell is defined as <code>CD4+</code>, <code>FOXP3+</code> by passing <code>pos</code> to each the markers and the algorithm finds that for a few cells one of the two is not, the algorithm will assign the cell as likely-regulatory T cell and will allow the user to make the decision later. <code>neg</code>- A given marker is negative.  </p> <p>It is always advised to use positive markers over negative markers </p>"},{"location":"Functions/tl/phenotype_cells/#scimap.tools._phenotype_cells--function","title":"Function","text":""},{"location":"Functions/tl/phenotype_cells/#scimap.tools._phenotype_cells.phenotype_cells","title":"<code>phenotype_cells(adata, phenotype, gate=0.5, label='phenotype', imageid='imageid', pheno_threshold_percent=None, pheno_threshold_abs=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>anndata object</p> required <code>phenotype</code> <p>dataframe, required A gating strategy for phenotyping the cells. An example <code>workflow</code> provided here.</p> required <code>gate</code> <p>int, optional By default rescale function, scales the data such that values above 0.5 are considered positive cells.</p> <code>0.5</code> <code>label</code> <p>string, optional Name the column underwhich the final phenotype calling will be saved.</p> <code>'phenotype'</code> <code>imageid</code> <p>string, optional Name of the column that contains the unique imageid. This is only utilized when the user uses <code>pheno_threshold_percent</code> or <code>pheno_threshold_abs</code> parameters.</p> <code>'imageid'</code> <code>pheno_threshold_percent</code> <p>float, optional Accepts values between (0-100). If any particular phenotype is below the user defined threshold, it is recategorised as 'unknown. Generally used to deal with low background false positives.</p> <code>None</code> <code>pheno_threshold_abs</code> <p>int, optional Serves the same purpose as that of pheno_threshold_percent. However, an absolute number can be passed. For example, if user passes in 10- any phenotype that contains less than 10 cells will be recategorized as unknown.</p> <code>None</code> <p>Returns:</p> Type Description <p>adata Updated AnnData object with the phenotype calls for each cell. Check <code>adata.obs['phenotype']</code> for results.</p> Example <pre><code># load the workflow csv file\nphenotype = pd.read_csv('path/to/csv/file/')  \n# phenotype the cells based on the workflow provided\nadata = sm.tl.phenotype_cells (adata, phenotype=phenotype, \ngate = 0.5, label=\"phenotype\")\n</code></pre> Source code in <code>scimap/tools/_phenotype_cells.py</code> <pre><code>def phenotype_cells (adata, \n                     phenotype, \n                     gate = 0.5, \n                     label=\"phenotype\", \n                     imageid='imageid',\n                     pheno_threshold_percent=None, \n                     pheno_threshold_abs=None):\n\"\"\"\n\nParameters:\n\n    adata : anndata object\n\n    phenotype : dataframe, required  \n        A gating strategy for phenotyping the cells. An example `workflow` provided [here](https://github.com/ajitjohnson/scimap/blob/master/scimap/tests/_data/phenotype_workflow.csv).\n\n    gate : int, optional  \n        By default rescale function, scales the data such that values above 0.5 are considered positive cells.\n\n    label : string, optional  \n        Name the column underwhich the final phenotype calling will be saved.\n\n    imageid : string, optional  \n        Name of the column that contains the unique imageid. This is only utilized\n        when the user uses `pheno_threshold_percent` or `pheno_threshold_abs` parameters.\n\n    pheno_threshold_percent : float, optional  \n        Accepts values between (0-100). If any particular phenotype is below the user defined threshold,\n        it is recategorised as 'unknown. Generally used to deal with low background false positives.\n\n    pheno_threshold_abs : int, optional  \n        Serves the same purpose as that of pheno_threshold_percent. However, an absolute\n        number can be passed. For example, if user passes in 10- any phenotype that contains\n        less than 10 cells will be recategorized as unknown.\n\nReturns:\n    adata\n        Updated AnnData object with the phenotype calls for each cell. Check `adata.obs['phenotype']` for results.\n\nExample:    \n    ```python\n    # load the workflow csv file\n    phenotype = pd.read_csv('path/to/csv/file/')  \n    # phenotype the cells based on the workflow provided\n    adata = sm.tl.phenotype_cells (adata, phenotype=phenotype, \n    gate = 0.5, label=\"phenotype\")\n    ```\n\n    \"\"\"\n\n    # Create a dataframe from the adata object\n    data = pd.DataFrame(adata.X, columns = adata.var.index, index= adata.obs.index)\n\n    # Function to calculate the phenotype scores\n    def phenotype_cells (data,phenotype,gate,group):\n\n        # Subset the phenotype based on the group\n        phenotype = phenotype[phenotype.iloc[:,0] == group]\n\n        # Parser to parse the CSV file into four categories\n        def phenotype_parser (p, cell):\n            # Get the index and subset the phenotype row being passed in\n            location = p.iloc[:,1] == cell\n            idx = [i for i, x in enumerate(location) if x][0]\n            phenotype = p.iloc[idx,:]\n            # Calculate\n            pos = phenotype[phenotype == 'pos'].index.tolist()\n            neg = phenotype[phenotype == 'neg'].index.tolist()\n            anypos = phenotype[phenotype == 'anypos'].index.tolist()\n            anyneg = phenotype[phenotype == 'anyneg'].index.tolist()\n            allpos = phenotype[phenotype == 'allpos'].index.tolist()\n            allneg = phenotype[phenotype == 'allneg'].index.tolist()\n            return {'pos': pos, 'neg': neg ,'anypos': anypos, 'anyneg': anyneg, 'allpos': allpos, 'allneg': allneg}\n            #return pos, neg, anypos, anyneg\n\n        # Run the phenotype_parser function on all rows\n        p_list = phenotype.iloc[:,1].tolist()\n        r_phenotype = lambda x: phenotype_parser(cell=x, p=phenotype) # Create lamda function\n        all_phenotype = list(map(r_phenotype, p_list)) # Apply function\n        all_phenotype = dict(zip(p_list, all_phenotype)) # Name the lists\n\n        # Define function to check if there is any marker that does not satisfy the gate\n        def gate_satisfation_lessthan (marker, data, gate):\n            fail = np.where(data[marker] &lt; gate, 1, 0) # 1 is fail\n            return fail\n        # Corresponding lamda function\n        r_gate_satisfation_lessthan = lambda x: gate_satisfation_lessthan(marker=x, data=data, gate=gate)\n\n        # Define function to check if there is any marker that does not satisfy the gate\n        def gate_satisfation_morethan (marker, data, gate):\n            fail = np.where(data[marker] &gt; gate, 1, 0)\n            return fail\n        # Corresponding lamda function\n        r_gate_satisfation_morethan = lambda x: gate_satisfation_morethan(marker=x, data=data, gate=gate)\n\n        def prob_mapper (data, all_phenotype, cell, gate):\n\n            print(\"Phenotyping \" + str(cell))\n\n            # Get the appropriate dict from all_phenotype\n            p = all_phenotype[cell]\n\n            # Identiy the marker used in each category\n            pos = p.get('pos')\n            neg = p.get('neg')\n            anypos = p.get('anypos')\n            anyneg = p.get('anyneg')\n            allpos = p.get('allpos')\n            allneg = p.get('allneg')\n\n            # Perform computation for each group independently\n            # Positive marker score\n            if len(pos) != 0:\n                pos_score = data[pos].mean(axis=1).values\n                pos_fail = list(map(r_gate_satisfation_lessthan, pos)) if len(pos) &gt; 1 else []\n                pos_fail = np.amax(pos_fail, axis=0) if len(pos) &gt; 1 else []\n            else:\n                pos_score = np.repeat(0, len(data))\n                pos_fail = []\n\n            # Negative marker score\n            if len(neg) != 0:\n                neg_score = (1-data[neg]).mean(axis=1).values\n                neg_fail = list(map(r_gate_satisfation_morethan, neg)) if len(neg) &gt; 1 else []\n                neg_fail = np.amax(neg_fail, axis=0) if len(neg) &gt; 1 else []\n            else:\n                neg_score = np.repeat(0, len(data))\n                neg_fail = []\n\n            # Any positive score\n            anypos_score = np.repeat(0, len(data)) if len(anypos) == 0 else data[anypos].max(axis=1).values\n\n            # Any negative score\n            anyneg_score = np.repeat(0, len(data)) if len(anyneg) == 0 else (1-data[anyneg]).max(axis=1).values\n\n            # All positive score\n            if len(allpos) != 0:\n                allpos_score = data[allpos]\n                allpos_score['score'] = allpos_score.max(axis=1)\n                allpos_score.loc[(allpos_score &lt; gate).any(axis = 1), 'score'] = 0\n                allpos_score = allpos_score['score'].values + 0.01 # A small value is added to give an edge over the matching positive cell\n            else:\n                allpos_score = np.repeat(0, len(data))\n\n\n            # All negative score\n            if len(allneg) != 0:\n                allneg_score = 1- data[allneg]\n                allneg_score['score'] = allneg_score.max(axis=1)\n                allneg_score.loc[(allneg_score &lt; gate).any(axis = 1), 'score'] = 0\n                allneg_score = allneg_score['score'].values + 0.01\n            else:\n                allneg_score = np.repeat(0, len(data))\n\n\n            # Total score calculation\n            # Account for differences in the number of categories used for calculation of the final score\n            number_of_non_empty_features = np.sum([len(pos) != 0,\n                                                len(neg) != 0,\n                                                len(anypos) != 0,\n                                                len(anyneg) != 0,\n                                                len(allpos) != 0,\n                                                len(allneg) != 0])\n\n            total_score = (pos_score + neg_score + anypos_score + anyneg_score + allpos_score + allneg_score) / number_of_non_empty_features\n\n            return {cell: total_score, 'pos_fail': pos_fail ,'neg_fail': neg_fail}\n            #return total_score, pos_fail, neg_fail\n\n\n        # Apply the fuction to get the total score for all cell types\n        r_prob_mapper = lambda x: prob_mapper (data=data, all_phenotype=all_phenotype, cell=x, gate=gate) # Create lamda function\n        final_scores = list(map(r_prob_mapper, [*all_phenotype])) # Apply function\n        final_scores = dict(zip([*all_phenotype], final_scores)) # Name the lists\n\n        # Combine the final score to annotate the cells with a label\n        final_score_df = pd.DataFrame()\n        for i in [*final_scores]:\n            df = pd.DataFrame(final_scores[i][i])\n            final_score_df= pd.concat([final_score_df, df], axis=1)\n        # Name the columns\n        final_score_df.columns = [*final_scores]\n        final_score_df.index = data.index\n        # Add a column called unknown if all markers have a value less than the gate (0.5)\n        unknown = group + str('-rest')\n        final_score_df[unknown] = (final_score_df &lt; gate).all(axis=1).astype(int)\n\n        # Name each cell\n        labels = final_score_df.idxmax(axis=1)\n\n        # Group all failed instances (i.e. when multiple markers were given\n        # any one of the marker fell into neg or pos zones of the gate)\n        pos_fail_all = pd.DataFrame()\n        for i in [*final_scores]:\n            df = pd.DataFrame(final_scores[i]['pos_fail'])\n            df.columns = [i] if len(df) != 0 else []\n            pos_fail_all= pd.concat([pos_fail_all, df], axis=1)\n        pos_fail_all.index = data.index if len(pos_fail_all) != 0 else []\n        # Same for Neg\n        neg_fail_all = pd.DataFrame()\n        for i in [*final_scores]:\n            df = pd.DataFrame(final_scores[i]['neg_fail'])\n            df.columns = [i] if len(df) != 0 else []\n            neg_fail_all= pd.concat([neg_fail_all, df], axis=1)\n        neg_fail_all.index = data.index if len(neg_fail_all) != 0 else []\n\n\n        # Modify the labels with the failed annotations\n        if len(pos_fail_all) != 0:\n            for i in pos_fail_all.columns:\n                labels[(labels == i) &amp; (pos_fail_all[i] == 1)] = 'likely-' + i\n        # Do the same for negative\n        if len(neg_fail_all) != 0:\n            for i in neg_fail_all.columns:\n                labels[(labels == i) &amp; (neg_fail_all[i] == 1)] = 'likely-' + i\n\n        # Retun the labels\n        return labels\n\n    # Create an empty dataframe to hold the labeles from each group\n    phenotype_labels = pd.DataFrame()\n\n    # Loop through the groups to apply the phenotype_cells function\n    for i in phenotype.iloc[:,0].unique():\n\n        if phenotype_labels.empty:\n            phenotype_labels = pd.DataFrame(phenotype_cells(data = data, group = i, phenotype=phenotype, gate=gate))\n            phenotype_labels.columns = [i]\n\n        else:\n            # Find the column with the cell-type of interest\n            column_of_interest = [] # Empty list to hold the column name\n            try:\n                column_of_interest = phenotype_labels.columns[phenotype_labels.eq(i).any()]\n            except:\n                pass\n            # If the cell-type of interest was not found just add NA\n            if len(column_of_interest) == 0:\n                phenotype_labels[i] = np.nan\n            else:\n                #cells_of_interest = phenotype_labels[phenotype_labels[column_of_interest] == i].index\n                cells_of_interest = phenotype_labels[phenotype_labels[column_of_interest].eq(i).any(axis=1)].index\n                d = data.loc[cells_of_interest]\n                print(\"-- Subsetting \" + str(i))\n                phenotype_l = pd.DataFrame(phenotype_cells(data = d, group = i, phenotype=phenotype, gate=gate), columns = [i])\n                phenotype_labels = phenotype_labels.merge(phenotype_l, how='outer', left_index=True, right_index=True)\n\n    # Rearrange the rows back to original\n    phenotype_labels = phenotype_labels.reindex(data.index)\n    phenotype_labels = phenotype_labels.replace('-rest', np.nan, regex=True)\n\n    print(\"Consolidating the phenotypes across all groups\")\n    phenotype_labels_Consolidated = phenotype_labels.fillna(method='ffill', axis = 1)\n    phenotype_labels[label] = phenotype_labels_Consolidated.iloc[:,-1].values\n\n    # replace nan to 'other cells'\n    phenotype_labels[label] = phenotype_labels[label].fillna('Unknown')\n\n    # Apply the phenotype threshold if given\n    if pheno_threshold_percent or pheno_threshold_abs is not None:\n        p = pd.DataFrame(phenotype_labels[label])\n        q = pd.DataFrame(adata.obs[imageid])\n        p = q.merge(p, how='outer', left_index=True, right_index=True)\n\n        # Function to remove phenotypes that are less than the given threshold\n        def remove_phenotype(p, ID, pheno_threshold_percent, pheno_threshold_abs):\n            d = p[p[imageid] == ID]\n            x = pd.DataFrame(d.groupby([label]).size())\n            x.columns = ['val']\n            # FInd the phenotypes that are less than the given threshold\n            if pheno_threshold_percent is not None:\n                fail = list(x.loc[x['val'] &lt; x['val'].sum() * pheno_threshold_percent/100].index)\n            if pheno_threshold_abs is not None:\n                fail = list(x.loc[x['val'] &lt; pheno_threshold_abs].index)\n            d[label] = d[label].replace(dict(zip(fail, np.repeat('Unknown',len(fail)))))\n            # Return\n            return d\n\n        # Apply function to all images\n        r_remove_phenotype = lambda x: remove_phenotype (p=p, ID=x,\n                                                         pheno_threshold_percent=pheno_threshold_percent,\n                                                         pheno_threshold_abs=pheno_threshold_abs) # Create lamda function\n        final_phrnotypes= list(map(r_remove_phenotype, list(p[imageid].unique()))) # Apply function\n\n        final_phrnotypes = pd.concat(final_phrnotypes, join='outer')\n        phenotype_labels = final_phrnotypes.reindex(adata.obs.index)\n\n\n    # Return to adata\n    adata.obs[label] = phenotype_labels[label]\n\n    #for i in phenotype_labels.columns:\n    #    adata.obs[i] = phenotype_labels[i]\n\n    return adata\n</code></pre>"},{"location":"Functions/tl/spatial_aggregate/","title":"spatial_aggregate","text":"<p>Short Description</p> <p><code>sm.tl.spatial_aggregate</code>: The function allows users to find regions of aggregration of similar cells. Use the <code>purity</code> parameter to fine-tune percent of similar cells within a given <code>radius</code>. </p>"},{"location":"Functions/tl/spatial_aggregate/#scimap.tools._spatial_aggregate--function","title":"Function","text":""},{"location":"Functions/tl/spatial_aggregate/#scimap.tools._spatial_aggregate.spatial_aggregate","title":"<code>spatial_aggregate(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid', purity=60, phenotype='phenotype', method='radius', radius=30, knn=10, imageid='imageid', subset=None, label='spatial_aggregate')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData object</p> required <code>x_coordinate</code> <p>float, required Column name containing the x-coordinates values.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <p>float, required Column name containing the y-coordinates values.</p> <code>'Y_centroid'</code> <code>purity</code> <p>int, optional Supply a value between 1 to 100. It is the percent purity of neighbouring cells. For e.g. if 60 is chosen, every neighbourhood is tested such that if a  particular phenotype makes up greater than 60% of the total  population it is annotated to be an aggregate of that particular phenotype.</p> <code>60</code> <code>phenotype</code> <p>string, required Column name of the column containing the phenotype information.  It could also be any categorical assignment given to single cells.</p> <code>'phenotype'</code> <code>method</code> <p>string, optional Two options are available: a) 'radius', b) 'knn'. a) radius - Identifies the neighbours within a given radius for every cell. b) knn - Identifies the K nearest neigbours for every cell.</p> <code>'radius'</code> <code>radius</code> <p>int, optional The radius used to define a local neighbhourhood.</p> <code>30</code> <code>knn</code> <p>int, optional Number of cells considered for defining the local neighbhourhood.</p> <code>10</code> <code>imageid</code> <p>string, optional Column name of the column containing the image id.</p> <code>'imageid'</code> <code>subset</code> <p>string, optional imageid of a single image to be subsetted for analyis.</p> <code>None</code> <code>label</code> <p>string, optional Key for the returned data, stored in <code>adata.obs</code>.</p> <code>'spatial_aggregate'</code> <p>Returns:</p> Name Type Description <code>adata</code> <p>AnnData object Updated AnnData object with the results stored in <code>adata.obs['spatial_aggregate']</code>.</p> <pre><code>    # Running the radius method\n    adata = sm.tl.spatial_aggregate (adata, x_coordinate='X_centroid',y_coordinate='Y_centroid',\n                        phenotype='phenotype', method='radius', radius=30, purity = 60,\n                        imageid='imageid',subset=None,label='spatial_aggregate_radius')\n\n    # Running the knn method\n    adata =  sm.tl.spatial_aggregate (adata, x_coordinate='X_centroid',y_coordinate='Y_centroid',\n                        phenotype='phenotype', method='knn', knn=10, purity = 60,\n                        imageid='imageid',subset=None,label='spatial_aggregate_knn')\n</code></pre> Source code in <code>scimap/tools/_spatial_aggregate.py</code> <pre><code>def spatial_aggregate (adata, x_coordinate='X_centroid',y_coordinate='Y_centroid',\n                       purity = 60, phenotype='phenotype', method='radius', radius=30, knn=10, \n                       imageid='imageid',subset=None,label='spatial_aggregate'):\n\"\"\"\n\nParameters:\n    adata : AnnData object\n\n    x_coordinate : float, required  \n        Column name containing the x-coordinates values.\n\n    y_coordinate : float, required  \n        Column name containing the y-coordinates values.\n\n    purity : int, optional  \n        Supply a value between 1 to 100. It is the percent purity of neighbouring cells.\n        For e.g. if 60 is chosen, every neighbourhood is tested such that if a \n        particular phenotype makes up greater than 60% of the total \n        population it is annotated to be an aggregate of that particular phenotype.\n\n    phenotype : string, required  \n        Column name of the column containing the phenotype information. \n        It could also be any categorical assignment given to single cells.\n\n    method : string, optional  \n        Two options are available: a) 'radius', b) 'knn'.\n        a) radius - Identifies the neighbours within a given radius for every cell.\n        b) knn - Identifies the K nearest neigbours for every cell.\n\n    radius : int, optional  \n        The radius used to define a local neighbhourhood.\n\n    knn : int, optional  \n        Number of cells considered for defining the local neighbhourhood.\n\n    imageid : string, optional  \n        Column name of the column containing the image id.\n\n    subset : string, optional  \n        imageid of a single image to be subsetted for analyis.\n\n    label : string, optional  \n        Key for the returned data, stored in `adata.obs`.\n\nReturns:\n    adata : AnnData object\n        Updated AnnData object with the results stored in `adata.obs['spatial_aggregate']`.\n\n\nExample:\n```python\n    # Running the radius method\n    adata = sm.tl.spatial_aggregate (adata, x_coordinate='X_centroid',y_coordinate='Y_centroid',\n                        phenotype='phenotype', method='radius', radius=30, purity = 60,\n                        imageid='imageid',subset=None,label='spatial_aggregate_radius')\n\n    # Running the knn method\n    adata =  sm.tl.spatial_aggregate (adata, x_coordinate='X_centroid',y_coordinate='Y_centroid',\n                        phenotype='phenotype', method='knn', knn=10, purity = 60,\n                        imageid='imageid',subset=None,label='spatial_aggregate_knn')\n```\n    \"\"\"\n\n    # Error statements\n    #if purity &lt; 51:\n    #    raise ValueError('purity should be set to a value greater than 50')\n\n    def spatial_aggregate_internal (adata_subset, x_coordinate,y_coordinate,phenotype,purity,\n                                    method,radius,knn,imageid,subset,label):\n\n\n        # Create a DataFrame with the necessary inforamtion\n        data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n\n        # Identify neighbourhoods based on the method used\n        # a) KNN method\n        if method == 'knn':\n            print(\"Identifying the \" + str(knn) + \" nearest neighbours for every cell\")\n            tree = BallTree(data[['x','y']], leaf_size= 2)\n            ind = tree.query(data[['x','y']], k=knn, return_distance= False)\n            neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n            neighbours.drop(0, axis=1, inplace=True) # Remove self neighbour\n\n        # b) Local radius method\n        if method == 'radius':\n            print(\"Identifying neighbours within \" + str(radius) + \" pixels of every cell\")\n            kdt = BallTree(data[['x','y']], leaf_size= 2) \n            ind = kdt.query_radius(data[['x','y']], r=radius, return_distance=False)\n            for i in range(0, len(ind)): ind[i] = np.delete(ind[i], np.argwhere(ind[i] == i))#remove self\n            neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n\n        # Map phenotype\n        phenomap = dict(zip(list(range(len(ind))), data['phenotype'])) # Used for mapping\n\n        # Loop through (all functionized methods were very slow)\n        for i in neighbours.columns:\n            neighbours[i] = neighbours[i].dropna().map(phenomap, na_action='ignore')\n\n        # Drop NA\n        #n_dropped = neighbours.dropna(how='all')\n\n\n        # Collapse all the neighbours into a single column\n        n = pd.DataFrame(neighbours.stack(), columns = [\"neighbour_phenotype\"])\n        n.index = n.index.get_level_values(0) # Drop the multi index\n        n = pd.DataFrame(n)\n        n['order'] = list(range(len(n)))\n\n        # Merge with real phenotype\n        n_m = n.merge(data['phenotype'], how='inner', left_index=True, right_index=True)\n        n_m['neighbourhood'] = n_m.index\n        n = n_m.sort_values(by=['order'])\n\n        # Count the neighbours\n        k = n.groupby(['neighbourhood','neighbour_phenotype']).size().unstack().fillna(0)\n        k = k.div(k.sum(axis=1), axis=0)\n\n        # Iteratte over all rows and find the column which passes the purity test\n        #def col_name_mapper (row_data, purity):\n        #    p = row_data[row_data &gt;= purity/100]\n        #    #phenotype_name = 'non-significant' if len(p.index) == 0 else p.index[0]\n        #    phenotype_name = 'non-significant' if len(p.index) == 0 else p.idxmax()\n        #    return phenotype_name\n        # Apply the iteration function\n        #aggregate_pheno = pd.DataFrame(k.apply(lambda x: col_name_mapper(row_data=x,purity=purity), axis=1))\n        aggregate_pheno = pd.DataFrame(k[k&gt;=purity/100].idxmax(axis=1).fillna('non-significant'))\n        aggregate_pheno.columns = ['spatial_aggregate']\n\n        # Return \n        return aggregate_pheno\n\n\n    # Subset a particular image if needed\n    if subset is not None:\n        adata_list = [adata[adata.obs[imageid] == subset]]\n    else:\n        adata_list = [adata[adata.obs[imageid] == i] for i in adata.obs[imageid].unique()]\n\n    # Apply function to all images and create a master dataframe\n    # Create lamda function \n    r_spatial_aggregate_internal = lambda x: spatial_aggregate_internal(adata_subset=x,\n                                                                          x_coordinate=x_coordinate,\n                                                                          y_coordinate=y_coordinate,\n                                                                          phenotype=phenotype,\n                                                                          method=method,\n                                                                          radius=radius,knn=knn,\n                                                                          imageid=imageid,subset=subset,\n                                                                          purity=purity,\n                                                                          label=label) \n    all_data = list(map(r_spatial_aggregate_internal, adata_list)) # Apply function \n\n    # Merge all the results into a single dataframe    \n    result = []\n    for i in range(len(all_data)):\n        result.append(all_data[i])\n    result = pd.concat(result, join='outer')  \n\n    # Reindex the cells\n    result = result.fillna(0)\n    result = result.reindex(adata.obs.index)\n\n    # Add to adata\n    adata.obs[label] = result\n\n    # Return        \n    return adata\n</code></pre>"},{"location":"Functions/tl/spatial_cluster/","title":"spatial_cluster","text":"<p>Short Description</p> <p><code>sm.tl.spatial_cluster</code>: This function allows users to cluster the spatial neighbourhood matrix  genereated by either <code>sm.tl.spatial_expression</code>, <code>sm.tl.spatial_count</code>, <code>sm.tl.spatial_lda</code> etc.</p>"},{"location":"Functions/tl/spatial_cluster/#scimap.tools._spatial_cluster--function","title":"Function","text":""},{"location":"Functions/tl/spatial_cluster/#scimap.tools._spatial_cluster.spatial_cluster","title":"<code>spatial_cluster(adata, df_name='spatial_count', method='kmeans', k=10, n_pcs=None, resolution=1, phenograph_clustering_metric='euclidean', nearest_neighbors=30, random_state=0, label=None, output_dir=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData object loaded into memory or path to AnnData object.</p> required <code>df_name</code> <p>string, required Label of the spatial analysis performed. By default if <code>sm.tl.spatial_count</code> was run the results will be saved under <code>spatial_count</code> and if <code>sm.tl.spatial_expression</code> was run, the results will be saved under <code>spatial_expression</code>.</p> <code>'spatial_count'</code> <code>method</code> <p>string, optional Clustering method to be used- Implemented methods- kmeans, phenograph and leiden.</p> <code>'kmeans'</code> <code>k</code> <p>int, optional Number of clusters to return when using K-Means clustering.</p> <code>10</code> <code>phenotype</code> <p>string, optional The column name that contains the cluster/phenotype information.</p> required <code>n_pcs</code> <p>int, optional Number of PC's to be used in leiden clustering. By default it uses all PC's.</p> <code>None</code> <code>resolution</code> <p>float, optional A parameter value controlling the coarseness of the clustering.  Higher values lead to more clusters.</p> <code>1</code> <code>phenograph_clustering_metric</code> <p>string, optional Distance metric to define nearest neighbors. Note that performance will be slower for correlation and cosine.  Available methods- cityblock\u2019, \u2018cosine\u2019, \u2018euclidean\u2019, \u2018manhattan\u2019, braycurtis\u2019, \u2018canberra\u2019, \u2018chebyshev\u2019,  \u2018correlation\u2019, \u2018dice\u2019, \u2018hamming\u2019, \u2018jaccard\u2019, \u2018kulsinski\u2019, \u2018mahalanobis\u2019, \u2018minkowski\u2019, \u2018rogerstanimoto\u2019,  \u2018russellrao\u2019, \u2018seuclidean\u2019, \u2018sokalmichener\u2019, \u2018sokalsneath\u2019, \u2018sqeuclidean\u2019, \u2018yule\u2019</p> <code>'euclidean'</code> <code>nearest_neighbors</code> <p>int, optional Number of nearest neighbors to use in first step of graph construction.  This parameter is used both in leiden and phenograph clustering.</p> <code>30</code> <code>random_state</code> <p>int, optional Change the initialization of the optimization.</p> <code>0</code> <code>label</code> <p>string, optional Key or optional column name for the returned data, stored in <code>adata.obs</code>. The default is adata.obs [spatial_method used].</p> <code>None</code> <code>output_dir</code> <p>string, optional Path to output directory.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>adata</code> <p>AnnData Object Returns an updated anndata object with a new column. check- adata.obs [spatial_method used]</p> <pre><code>    adata = sm.tl.spatial_cluster (adata, k= 10, method = 'kmeans') # results will be saved under adata.obs['spatial_kmeans']\n</code></pre> Source code in <code>scimap/tools/_spatial_cluster.py</code> <pre><code>def spatial_cluster (adata, df_name='spatial_count', method = 'kmeans',k=10,\n                     n_pcs=None, resolution=1, phenograph_clustering_metric='euclidean', \n                     nearest_neighbors=30, random_state=0,label=None, output_dir=None):\n\"\"\"\n\n\nParameters:\n    adata : AnnData object loaded into memory or path to AnnData object.\n\n    df_name : string, required  \n        Label of the spatial analysis performed.\n        By default if `sm.tl.spatial_count` was run the results will be saved under `spatial_count` and\n        if `sm.tl.spatial_expression` was run, the results will be saved under `spatial_expression`.\n\n    method : string, optional  \n        Clustering method to be used- Implemented methods- kmeans, phenograph and leiden.\n\n    k : int, optional  \n        Number of clusters to return when using K-Means clustering.\n\n    phenotype : string, optional  \n        The column name that contains the cluster/phenotype information.\n\n    n_pcs : int, optional  \n        Number of PC's to be used in leiden clustering. By default it uses all PC's.\n\n    resolution : float, optional  \n        A parameter value controlling the coarseness of the clustering. \n        Higher values lead to more clusters.\n\n    phenograph_clustering_metric : string, optional  \n        Distance metric to define nearest neighbors. Note that performance will be slower for correlation and cosine. \n        Available methods- cityblock\u2019, \u2018cosine\u2019, \u2018euclidean\u2019, \u2018manhattan\u2019, braycurtis\u2019, \u2018canberra\u2019, \u2018chebyshev\u2019, \n        \u2018correlation\u2019, \u2018dice\u2019, \u2018hamming\u2019, \u2018jaccard\u2019, \u2018kulsinski\u2019, \u2018mahalanobis\u2019, \u2018minkowski\u2019, \u2018rogerstanimoto\u2019, \n        \u2018russellrao\u2019, \u2018seuclidean\u2019, \u2018sokalmichener\u2019, \u2018sokalsneath\u2019, \u2018sqeuclidean\u2019, \u2018yule\u2019\n\n    nearest_neighbors : int, optional  \n        Number of nearest neighbors to use in first step of graph construction. \n        This parameter is used both in leiden and phenograph clustering.\n\n    random_state : int, optional  \n        Change the initialization of the optimization.\n\n    label : string, optional  \n        Key or optional column name for the returned data, stored in `adata.obs`. The default is adata.obs [spatial_method used].\n\n    output_dir : string, optional  \n        Path to output directory.\n\nReturns:\n    adata : AnnData Object  \n        Returns an updated anndata object with a new column. check- adata.obs [spatial_method used]\n\nExample:\n```python\n    adata = sm.tl.spatial_cluster (adata, k= 10, method = 'kmeans') # results will be saved under adata.obs['spatial_kmeans']\n```\n    \"\"\"\n\n    # Load the andata object    \n    if isinstance(adata, str):\n        imid = str(adata.rsplit('/', 1)[-1])\n        adata = ad.read(adata)\n    else:\n        adata = adata\n\n    # Make a copy of adata to modify\n    adata_copy = adata.copy()\n\n    # Error check\n    try:\n        adata_copy.uns[df_name]\n    except KeyError:\n        print (str('Supplied df_name not found, please run `sm.tl.spatial_expression` or LDA, counts or other similar methods'))\n\n    # Crete a new anndata object with the user defined spatial information\n    adata_new = ad.AnnData(adata_copy.uns[df_name].fillna(0))\n    adata_new.obs = adata_copy.obs\n\n    # Create a meaningful label name\n    if label is None:\n        label = 'spatial_' + str(method)\n\n    # Run the clustering algorithm\n    adata_new = cluster (adata = adata_new,\n                         method = method,\n                         k=k, \n                         n_pcs=n_pcs, \n                         resolution=resolution,\n                         phenograph_clustering_metric=phenograph_clustering_metric,\n                         nearest_neighbors=nearest_neighbors, \n                         use_raw=False, \n                         random_state=random_state,\n                         label=label)\n\n    # Get the clusters and append that to original adata object\n    result = adata_new.obs[label]\n    result = result.reindex(adata.obs.index)\n    adata.obs[label] = result\n\n\n    # Save data if requested\n    if output_dir is not None:\n        output_dir = pathlib.Path(output_dir)\n        output_dir.mkdir(exist_ok=True, parents=True)\n        adata.write(output_dir / imid)\n    else:    \n        # Return data\n        return adata\n</code></pre>"},{"location":"Functions/tl/spatial_count/","title":"spatial_count","text":"<p>Short Description</p> <p>The <code>sm.tl.spatial_count</code> function allows users to compute a neighbourhood matrix  using any categorical variable (e.g. cell-types) as input.</p> <p>The function supports two methods to define a local neighbourhood  Radius method: Can be used to identifies the neighbours within a user defined radius for every cell. KNN method: Can be used to identifies the neighbours based on K nearest neigbours for every cell</p> <p>The resultant neighbourhood matrix is saved with <code>adata.uns</code>. </p> <p>This can be further clustered to identify similar neighbourhoods.  Use the [spatial_cluster] function to further group the neighbourhoods into  Reccurent Cellular Neighbourhoods (RCNs)</p>"},{"location":"Functions/tl/spatial_count/#scimap.tools._spatial_count--function","title":"Function","text":""},{"location":"Functions/tl/spatial_count/#scimap.tools._spatial_count.spatial_count","title":"<code>spatial_count(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid', phenotype='phenotype', method='radius', radius=30, knn=10, imageid='imageid', subset=None, label='spatial_count')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>anndata object</p> required <code>x_coordinate</code> <p>float, required Column name containing the x-coordinates values.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <p>float, required Column name containing the y-coordinates values.</p> <code>'Y_centroid'</code> <code>phenotype</code> <p>string, required Column name of the column containing the phenotype information.  It could also be any categorical assignment given to single cells.</p> <code>'phenotype'</code> <code>method</code> <p>string, optional Two options are available: a) <code>radius</code>, b) <code>knn</code>. a) radius - Identifies the neighbours within a given radius for every cell. b) knn - Identifies the K nearest neigbours for every cell.  </p> <code>'radius'</code> <code>radius</code> <p>int, optional The radius used to define a local neighbhourhood.</p> <code>30</code> <code>knn</code> <p>int, optional Number of cells considered for defining the local neighbhourhood.</p> <code>10</code> <code>imageid</code> <p>string, optional Column name of the column containing the image id.</p> <code>'imageid'</code> <code>subset</code> <p>string, optional imageid of a single image to be subsetted for analyis.</p> <code>None</code> <code>label</code> <p>string, optional Key for the returned data, stored in <code>adata.uns</code>.</p> <code>'spatial_count'</code> <p>Returns:</p> Name Type Description <code>adata</code> <p>anndata object Updated AnnData object with the results stored in <code>adata.uns ['spatial_count']</code>.</p> Example <pre><code># Running the radius method\nadata = sm.tl.spatial_count (adata,x_coordinate='X_centroid',\n                             y_coordinate='Y_centroid',\n                             phenotype='phenotype',\n                             method='radius',radius=30,\n                             imageid='imageid',subset=None,\n                             label='spatial_count_radius')\n\n# Running the knn method\nadata = sm.tl.spatial_count (adata,x_coordinate='X_centroid',\n                             y_coordinate='Y_centroid',\n                             phenotype='phenotype',method='knn',\n                             knn=10, imageid='imageid',\n                             subset=None,label='spatial_count_knn')\n</code></pre> Source code in <code>scimap/tools/_spatial_count.py</code> <pre><code>def spatial_count (adata,\n                   x_coordinate='X_centroid',\n                   y_coordinate='Y_centroid',\n                   phenotype='phenotype',\n                   method='radius',\n                   radius=30,knn=10,\n                   imageid='imageid',\n                   subset=None,\n                   label='spatial_count'):\n\"\"\"\nParameters:\n    adata : anndata object\n\n    x_coordinate : float, required  \n        Column name containing the x-coordinates values.\n\n    y_coordinate : float, required  \n        Column name containing the y-coordinates values.\n\n    phenotype : string, required  \n        Column name of the column containing the phenotype information. \n        It could also be any categorical assignment given to single cells.\n\n    method : string, optional  \n        Two options are available: a) `radius`, b) `knn`.  \n        a) radius - Identifies the neighbours within a given radius for every cell.  \n        b) knn - Identifies the K nearest neigbours for every cell.  \n\n    radius : int, optional  \n        The radius used to define a local neighbhourhood.\n\n    knn : int, optional  \n        Number of cells considered for defining the local neighbhourhood.\n\n    imageid : string, optional  \n        Column name of the column containing the image id.\n\n    subset : string, optional  \n        imageid of a single image to be subsetted for analyis.\n\n    label : string, optional  \n        Key for the returned data, stored in `adata.uns`.\n\nReturns:\n    adata : anndata object  \n        Updated AnnData object with the results stored in `adata.uns ['spatial_count']`.\n\nExample:\n    ```python\n    # Running the radius method\n    adata = sm.tl.spatial_count (adata,x_coordinate='X_centroid',\n                                 y_coordinate='Y_centroid',\n                                 phenotype='phenotype',\n                                 method='radius',radius=30,\n                                 imageid='imageid',subset=None,\n                                 label='spatial_count_radius')\n\n    # Running the knn method\n    adata = sm.tl.spatial_count (adata,x_coordinate='X_centroid',\n                                 y_coordinate='Y_centroid',\n                                 phenotype='phenotype',method='knn',\n                                 knn=10, imageid='imageid',\n                                 subset=None,label='spatial_count_knn')\n    ```\n    \"\"\"\n\n    def spatial_count_internal (adata_subset,x_coordinate,y_coordinate,phenotype,method,radius,knn,\n                                imageid,subset,label):\n\n        # Create a DataFrame with the necessary inforamtion\n        data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n\n        # Identify neighbourhoods based on the method used\n        # a) KNN method\n        if method == 'knn':\n            print(\"Identifying the \" + str(knn) + \" nearest neighbours for every cell\")\n            tree = BallTree(data[['x','y']], leaf_size= 2)\n            ind = tree.query(data[['x','y']], k=knn, return_distance= False)\n            neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n            neighbours.drop(0, axis=1, inplace=True) # Remove self neighbour\n\n        # b) Local radius method\n        if method == 'radius':\n            print(\"Identifying neighbours within \" + str(radius) + \" pixels of every cell\")\n            kdt = BallTree(data[['x','y']], metric='euclidean') \n            ind = kdt.query_radius(data[['x','y']], r=radius, return_distance=False)\n            for i in range(0, len(ind)): ind[i] = np.delete(ind[i], np.argwhere(ind[i] == i))#remove self\n            neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n\n        # Map phenotype\n        phenomap = dict(zip(list(range(len(ind))), data['phenotype'])) # Used for mapping\n\n        # Loop through (all functionized methods were very slow)\n        for i in neighbours.columns:\n            neighbours[i] = neighbours[i].dropna().map(phenomap, na_action='ignore')\n\n        # Drop NA\n        #n_dropped = neighbours.dropna(how='all')\n\n        # Collapse all the neighbours into a single column\n        n = pd.DataFrame(neighbours.stack(), columns = [\"neighbour_phenotype\"])\n        n.index = n.index.get_level_values(0) # Drop the multi index\n        n = pd.DataFrame(n)\n        n['order'] = list(range(len(n)))\n\n        # Merge with real phenotype\n        n_m = n.merge(data['phenotype'], how='inner', left_index=True, right_index=True)\n        n_m['neighbourhood'] = n_m.index\n        n = n_m.sort_values(by=['order'])\n\n        # Normalize based on total cell count\n        k = n.groupby(['neighbourhood','neighbour_phenotype']).size().unstack().fillna(0)\n        k = k.div(k.sum(axis=1), axis=0)\n\n        # return the normalized neighbour occurance count\n        return k\n\n    # Subset a particular image if needed\n    if subset is not None:\n        adata_list = [adata[adata.obs[imageid] == subset]]\n    else:\n        adata_list = [adata[adata.obs[imageid] == i] for i in adata.obs[imageid].unique()]\n\n    # Apply function to all images and create a master dataframe\n    # Create lamda function \n    r_spatial_count_internal = lambda x: spatial_count_internal(adata_subset=x,x_coordinate=x_coordinate,\n                                                   y_coordinate=y_coordinate,phenotype=phenotype,\n                                                   method=method,radius=radius,knn=knn,\n                                                   imageid=imageid,subset=subset,label=label) \n    all_data = list(map(r_spatial_count_internal, adata_list)) # Apply function \n\n\n    # Merge all the results into a single dataframe    \n    result = []\n    for i in range(len(all_data)):\n        result.append(all_data[i])\n    result = pd.concat(result, join='outer')  \n\n    # Reindex the cells\n    result = result.fillna(0)\n    result = result.reindex(adata.obs.index)\n\n    # Add to adata\n    adata.uns[label] = result\n\n    # Return        \n    return adata\n</code></pre>"},{"location":"Functions/tl/spatial_distance/","title":"spatial_distance","text":"<p>Short Description</p> <p><code>sm.tl.spatial_distance</code>: The function allows users to calculate  the average shortest between phenotypes or clusters of interest (3D data supported).</p>"},{"location":"Functions/tl/spatial_distance/#scimap.tools._spatial_distance--function","title":"Function","text":""},{"location":"Functions/tl/spatial_distance/#scimap.tools._spatial_distance.spatial_distance","title":"<code>spatial_distance(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid', z_coordinate=None, phenotype='phenotype', subset=None, imageid='imageid', label='spatial_distance')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData object</p> required <code>x_coordinate</code> <p>float, required Column name containing the x-coordinates values.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <p>float, required Column name containing the y-coordinates values.</p> <code>'Y_centroid'</code> <code>z_coordinate</code> <p>float, optional Column name containing the z-coordinates values.</p> <code>None</code> <code>phenotype</code> <p>string, required Column name of the column containing the phenotype information.  It could also be any categorical assignment given to single cells.</p> <code>'phenotype'</code> <code>subset</code> <p>string, optional imageid of a single image to be subsetted for analyis.</p> <code>None</code> <code>imageid</code> <p>string, optional Column name of the column containing the image id.</p> <code>'imageid'</code> <code>label</code> <p>string, optional Key for the returned data, stored in <code>adata.obs</code>.</p> <code>'spatial_distance'</code> <p>Returns:</p> Name Type Description <code>adata</code> <p>AnnData object Updated AnnData object with the results stored in <code>adata.uns ['spatial_distance']</code>.</p> <pre><code>    adata = sm.tl.spatial_distance (adata,x_coordinate='X_position',\n    y_coordinate='Y_position',imageid='ImageId')\n</code></pre> Source code in <code>scimap/tools/_spatial_distance.py</code> <pre><code>def spatial_distance (adata,x_coordinate='X_centroid',y_coordinate='Y_centroid',\n                      z_coordinate=None,\n                      phenotype='phenotype',subset=None,imageid='imageid',\n                      label='spatial_distance'):\n\"\"\"\n\nParameters:\n\n    adata : AnnData object\n\n    x_coordinate : float, required  \n        Column name containing the x-coordinates values.\n\n    y_coordinate : float, required  \n        Column name containing the y-coordinates values.\n\n    z_coordinate : float, optional  \n        Column name containing the z-coordinates values.\n\n    phenotype : string, required  \n        Column name of the column containing the phenotype information. \n        It could also be any categorical assignment given to single cells.\n\n    subset : string, optional  \n        imageid of a single image to be subsetted for analyis.\n\n    imageid : string, optional  \n        Column name of the column containing the image id.\n\n    label : string, optional  \n        Key for the returned data, stored in `adata.obs`.\n\nReturns:\n    adata : AnnData object  \n        Updated AnnData object with the results stored in `adata.uns ['spatial_distance']`.\n\nExample:\n```python\n    adata = sm.tl.spatial_distance (adata,x_coordinate='X_position',\n    y_coordinate='Y_position',imageid='ImageId')\n```     \n\n    \"\"\"\n\n\n    def spatial_distance_internal (adata_subset,x_coordinate,y_coordinate,z_coordinate,\n                                   phenotype,subset,imageid,label):\n\n        print(\"Processing Image: \" + str(adata_subset.obs[imageid].unique()[0]))\n        # Create a dataFrame with the necessary inforamtion\n        if z_coordinate is not None:\n            print(\"Including Z -axis\")\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'z': adata_subset.obs[z_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n        else:\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n\n        # Function to identify shortest distance for each phenotype of interest\n        def distance (pheno):\n            pheno_interest = data[data['phenotype'] == pheno]\n            # Build the ball-tree for search space\n            tree = BallTree(pheno_interest[['x','y']], metric='euclidean') \n            # Calculate shortest distance (if statement to account for K)\n            if len(pheno_interest) &gt; 1:\n                dist, ind = tree.query(data[['x','y']], k=2, return_distance= True)\n                dist = pd.DataFrame(dist)\n                dist.loc[dist[0] == 0, 0]  = dist[1]\n                dist = dist[0].values\n            else:\n                dist, ind = tree.query(data[['x','y']], k=1, return_distance= True)\n                dist = list(itertools.chain.from_iterable(dist))\n            return dist\n\n        # Run in parallel for all phenotypes\n        phenotype_list = list(data['phenotype'].unique())\n        # Apply function\n        final_dist = Parallel(n_jobs=-1)(delayed(distance)(pheno=i) for i in phenotype_list)     \n        final_dist = pd.DataFrame(final_dist, index = phenotype_list, columns = data.index).T\n\n        return final_dist\n\n    # subset a particular subset of cells if the user wants else break the adata into list of anndata objects\n    if subset is not None:\n        adata_list = [adata[adata.obs[imageid].isin(subset)]]\n    else:\n        adata_list = [adata[adata.obs[imageid] == i] for i in adata.obs[imageid].unique()]\n\n    # Apply function to all images and create a master dataframe\n    # Create lamda function \n    r_spatial_distance_internal = lambda x: spatial_distance_internal (adata_subset=x,\n                                                                       x_coordinate=x_coordinate,y_coordinate=y_coordinate, z_coordinate=z_coordinate,\n                                                                       phenotype=phenotype,subset=subset,imageid=imageid,label=label) \n    all_data = list(map(r_spatial_distance_internal, adata_list)) # Apply function \n\n    # Merge all the results into a single dataframe    \n    result = []\n    for i in range(len(all_data)):\n        result.append(all_data[i])\n    result = pd.concat(result, join='outer')  \n\n\n    # Add to anndata\n    adata.uns[label] = result\n\n    # return\n    return adata\n</code></pre>"},{"location":"Functions/tl/spatial_expression/","title":"spatial_expression","text":"<p>Short Description</p> <p><code>sm.tl.spatial_expression</code>: The function allows users to compute a neighbourhood weighted matrix  based on the expression values.</p> <p>The function supports two methods to define a local neighbourhood Radius method: Can be used to identifies the neighbours within a user defined radius for every cell. KNN method: Can be used to identifies the neighbours based on K nearest neigbours for every cell  </p> <p>The resultant proportion matrix is saved with <code>adata.uns</code>. </p> <p>This can be further clustered to identify similar neighbourhoods.  Use the [spatial_cluster] function to further group the neighbourhoods into  Reccurent Cellular Neighbourhoods (RCNs)</p>"},{"location":"Functions/tl/spatial_expression/#scimap.tools._spatial_expression--function","title":"Function","text":""},{"location":"Functions/tl/spatial_expression/#scimap.tools._spatial_expression.spatial_expression","title":"<code>spatial_expression(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid', method='radius', radius=30, knn=10, imageid='imageid', use_raw=True, log=True, subset=None, label='spatial_expression', output_dir=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData object loaded into memory or path to AnnData object.</p> required <code>x_coordinate</code> <p>float, required Column name containing the x-coordinates values.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <p>float, required Column name containing the y-coordinates values.</p> <code>'Y_centroid'</code> <code>method</code> <p>string, optional Two options are available: a) <code>radius</code>, b) <code>knn</code>. a) <code>radius</code> - Identifies the neighbours within a given radius for every cell. b) <code>knn</code> - Identifies the K nearest neigbours for every cell.  </p> <code>'radius'</code> <code>radius</code> <p>int, optional The radius used to define a local neighbhourhood.</p> <code>30</code> <code>knn</code> <p>int, optional Number of cells considered for defining the local neighbhourhood.</p> <code>10</code> <code>imageid</code> <p>string, optional Column name of the column containing the image id.</p> <code>'imageid'</code> <code>subset</code> <p>string, optional imageid of a single image to be subsetted for analyis.</p> <code>None</code> <code>use_raw</code> <p>boolian, optional Argument to denote whether to use the raw data or scaled data after applying <code>sm.pp.rescale</code>.</p> <code>True</code> <code>log</code> <p>boolian, optional If <code>True</code>, the log of raw data is used. Set use_raw = <code>True</code> for this to take effect. </p> <code>True</code> <code>label</code> <p>string, optional Key for the returned data, stored in <code>adata.uns</code>.</p> <code>'spatial_expression'</code> <code>output_dir</code> <p>string, optional Path to output directory.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>adata</code> <p>AnnData object Updated AnnData object with the results stored in <code>adata.uns ['spatial_expression']</code>.</p> <pre><code># Running the knn method\nadata = sm.tl.spatial_expression (adata, x_coordinate='X_centroid',\n                                  y_coordinate='Y_centroid',\n                                  method='knn', knn=10, imageid='imageid', \n                                  use_raw=True,subset=None,\n                                  label='spatial_expression_knn')\n```\n</code></pre> Source code in <code>scimap/tools/_spatial_expression.py</code> <pre><code>def spatial_expression (adata, \n                        x_coordinate='X_centroid',\n                        y_coordinate='Y_centroid',\n                        method='radius', radius=30, \n                        knn=10, imageid='imageid', \n                        use_raw=True, log=True, subset=None,\n                        label='spatial_expression',\n                        output_dir=None):\n\"\"\"\nParameters:\n    adata : AnnData object loaded into memory or path to AnnData object.\n\n    x_coordinate : float, required  \n        Column name containing the x-coordinates values.\n\n    y_coordinate : float, required  \n        Column name containing the y-coordinates values.\n\n    method : string, optional  \n        Two options are available: a) `radius`, b) `knn`.  \n        a) `radius` - Identifies the neighbours within a given radius for every cell.  \n        b) `knn` - Identifies the K nearest neigbours for every cell.  \n\n    radius : int, optional  \n        The radius used to define a local neighbhourhood.\n\n    knn : int, optional  \n        Number of cells considered for defining the local neighbhourhood.\n\n    imageid : string, optional  \n        Column name of the column containing the image id.\n\n    subset : string, optional  \n        imageid of a single image to be subsetted for analyis.\n\n    use_raw : boolian, optional  \n        Argument to denote whether to use the raw data or scaled data after applying `sm.pp.rescale`.\n\n    log : boolian, optional  \n        If `True`, the log of raw data is used. Set use_raw = `True` for this to take effect. \n\n    label : string, optional  \n        Key for the returned data, stored in `adata.uns`.\n\n    output_dir : string, optional  \n        Path to output directory.\n\nReturns:\n    adata : AnnData object  \n        Updated AnnData object with the results stored in `adata.uns ['spatial_expression']`.\n\n\n Example:\n    ```python\n    # Running the radius method\n    adata = sm.tl.spatial_expression (adata, x_coordinate='X_centroid',\n                                      y_coordinate='Y_centroid',\n                                      method='radius', radius=30, \n                                      imageid='imageid', \n                                      use_raw=True,subset=None,\n                                      label='spatial_expression_radius')\n\n    # Running the knn method\n    adata = sm.tl.spatial_expression (adata, x_coordinate='X_centroid',\n                                      y_coordinate='Y_centroid',\n                                      method='knn', knn=10, imageid='imageid', \n                                      use_raw=True,subset=None,\n                                      label='spatial_expression_knn')\n    ```\n    \"\"\"\n\n    # Load the andata object    \n    if isinstance(adata, str):\n        imid = str(adata.rsplit('/', 1)[-1])\n        adata = anndata.read(adata)\n    else:\n        adata = adata\n\n\n    # Error statements\n    if use_raw is False:\n        if all(adata.X[0] &lt; 1) is False:\n            raise ValueError('Please run `sm.pp.rescale` first if you wish to use `use_raw = False`')\n\n\n    def spatial_expression_internal (adata_subset, x_coordinate, y_coordinate,log,\n                                     method, radius, knn, imageid, use_raw, subset,label):\n\n        # Create a DataFrame with the necessary inforamtion\n        data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate]})\n\n        # Identify neighbourhoods based on the method used\n        # a) KNN method\n        if method == 'knn':\n            print(\"Identifying the \" + str(knn) + \" nearest neighbours for every cell\")\n            tree = BallTree(data, leaf_size= 2)\n            dist, ind = tree.query(data, k=knn, return_distance= True)\n\n\n        # b) Local radius method\n        if method == 'radius':\n            print(\"Identifying neighbours within \" + str(radius) + \" pixels of every cell\")\n            kdt = BallTree(data, metric='euclidean')\n            ind, dist = kdt.query_radius(data, r=radius, return_distance= True)\n\n        # Normalize range (0-1) and account for total number of cells \n        d = scipy.sparse.lil_matrix((len(data), len(data)))\n        for row, (columns, values) in enumerate(zip(ind, dist)):\n            # Drop self-distance element.\n            idx = columns != row\n            columns = columns[idx]\n            values = values[idx]\n            if len(values) == 1:\n                values = [1.0]\n            elif len(values) &gt; 1:\n                # Normalize distances.\n                values = (values.max() - values) / (values.max() - values.min())\n                values /= values.sum()\n            # Assign row to matrix.\n            d[row, columns] = values\n\n        # convert to csr sparse matrix\n        wn_matrix_sparse = d.tocsr()\n\n\n        # Calculation of spatial lag\n        if use_raw==True:\n            if log is True:\n                spatial_lag = pd.DataFrame(wn_matrix_sparse * np.log1p(adata_subset.raw.X), columns = adata_subset.var.index, index=adata_subset.obs.index)\n            else:\n                spatial_lag = pd.DataFrame(wn_matrix_sparse * adata_subset.raw.X, columns = adata_subset.var.index, index=adata_subset.obs.index)\n        else:\n            spatial_lag = pd.DataFrame(wn_matrix_sparse * adata_subset.X, columns = adata_subset.var.index, index=adata_subset.obs.index)\n\n        # return value\n        return spatial_lag\n\n    # Subset a particular image if needed\n    if subset is not None:\n        adata_list = [adata[adata.obs[imageid] == subset]]\n    else:\n        adata_list = [adata[adata.obs[imageid] == i] for i in adata.obs[imageid].unique()]\n\n    # Apply function to all images and create a master dataframe\n    # Create lamda function \n    r_spatial_expression_internal = lambda x: spatial_expression_internal(adata_subset=x, \n                                                                x_coordinate=x_coordinate, \n                                                                y_coordinate=y_coordinate, \n                                                                method=method, radius=radius, \n                                                                knn=knn, imageid=imageid, \n                                                                use_raw=use_raw, subset=subset,\n                                                                log=log,\n                                                                label=label) \n    all_data = list(map(r_spatial_expression_internal, adata_list)) # Apply function \n\n    # Merge all the results into a single dataframe    \n    result = []\n    for i in range(len(all_data)):\n        result.append(all_data[i])\n    result = pd.concat(result, join='outer')  \n\n    # Reindex the cells\n    result = result.fillna(0)\n    result = result.reindex(adata.obs.index)\n\n    # Add to adata\n    adata.uns[label] = result\n\n    # Save data if requested\n    if output_dir is not None:\n        output_dir = pathlib.Path(output_dir)\n        output_dir.mkdir(exist_ok=True, parents=True)\n        adata.write(output_dir / imid)\n    else:    \n        # Return data\n        return adata\n</code></pre>"},{"location":"Functions/tl/spatial_interaction/","title":"spatial_interaction","text":"<p>Short Description</p> <p><code>sm.tl.spatial_interaction</code>: The function allows users to computes how likely celltypes are found next to each another compared to random background (3D data supported). </p>"},{"location":"Functions/tl/spatial_interaction/#scimap.tools._spatial_interaction--function","title":"Function","text":""},{"location":"Functions/tl/spatial_interaction/#scimap.tools._spatial_interaction.spatial_interaction","title":"<code>spatial_interaction(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid', z_coordinate=None, phenotype='phenotype', method='radius', radius=30, knn=10, permutation=1000, imageid='imageid', subset=None, pval_method='zscore', label='spatial_interaction')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData object</p> required <code>x_coordinate</code> <p>float, required Column name containing the x-coordinates values.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <p>float, required Column name containing the y-coordinates values.</p> <code>'Y_centroid'</code> <code>z_coordinate</code> <p>float, optional Column name containing the z-coordinates values.</p> <code>None</code> <code>phenotype</code> <p>string, required Column name of the column containing the phenotype information.  It could also be any categorical assignment given to single cells.</p> <code>'phenotype'</code> <code>method</code> <p>string, optional Two options are available: a) 'radius', b) 'knn'. a) radius - Identifies the neighbours within a given radius for every cell. b) knn - Identifies the K nearest neigbours for every cell.</p> <code>'radius'</code> <code>radius</code> <p>int, optional The radius used to define a local neighbhourhood.</p> <code>30</code> <code>knn</code> <p>int, optional Number of cells considered for defining the local neighbhourhood.</p> <code>10</code> <code>permutation</code> <p>int, optional The number of permutations to be performed for calculating the P-Value.</p> <code>1000</code> <code>imageid</code> <p>string, optional Column name of the column containing the image id.</p> <code>'imageid'</code> <code>subset</code> <p>string, optional imageid of a single image to be subsetted for analyis.</p> <code>None</code> <code>pval_method</code> <p>string, optional Two options are available: a) 'histocat', b) 'zscore'. a) P-values are calculated by subtracting the permuted mean from the observed mean divided by the number of permutations as described in the histoCAT manuscript (Denis et.al, Nature Methods 2017) b) zscores are calculated from the mean and standard deviation and further p-values are derived by fitting the observed values to a normal distribution. The default is 'histocat'.</p> <code>'zscore'</code> <code>label</code> <p>string, optional Key for the returned data, stored in <code>adata.obs</code>. The default is 'spatial_interaction'.</p> <code>'spatial_interaction'</code> <p>Returns:</p> Name Type Description <code>adata</code> <p>AnnData object Updated AnnData object with the results stored in <code>adata.obs['spatial_aggregate']</code>.</p> <pre><code>    # Using the radius method to identify local neighbours and histocat to compute P-values\n    adata = sm.tl.spatial_interaction(adata, method='radius', radius=30, pval_method='histocat',\n                                      imageid='imageid',x_coordinate='X',y_coordinate='Y')\n\n\n    # Using the KNN method to identify local neighbours and zscore to compute P-values\n    adata = sm.tl.spatial_interaction(adata, method='knn', radius=30,pval_method='zscore',\n                                      imageid='ImageId',x_coordinate='X_position',y_coordinate='Y_position')\n\n    # Interaction analysis on 3D data\n    adata = sm.tl.spatial_interaction(adata, method='radius', radius=60, pval_method='zscore',\n                                      imageid='ImageId',x_coordinate='X_position',\n                                      y_coordinate='Y_position', z_coordinate='Z_position')\n</code></pre> Source code in <code>scimap/tools/_spatial_interaction.py</code> <pre><code>def spatial_interaction (adata,x_coordinate='X_centroid',y_coordinate='Y_centroid',\n                         z_coordinate=None,\n                         phenotype='phenotype',\n                         method='radius', radius=30, knn=10,\n                         permutation=1000,\n                         imageid='imageid',subset=None,\n                         pval_method='zscore',\n                         label='spatial_interaction'):\n\"\"\"\nParameters:\n    adata : AnnData object\n    x_coordinate : float, required  \n        Column name containing the x-coordinates values.\n    y_coordinate : float, required  \n        Column name containing the y-coordinates values.\n    z_coordinate : float, optional  \n        Column name containing the z-coordinates values.\n    phenotype : string, required  \n        Column name of the column containing the phenotype information. \n        It could also be any categorical assignment given to single cells.\n    method : string, optional  \n        Two options are available: a) 'radius', b) 'knn'.\n        a) radius - Identifies the neighbours within a given radius for every cell.\n        b) knn - Identifies the K nearest neigbours for every cell.\n    radius : int, optional  \n        The radius used to define a local neighbhourhood.\n    knn : int, optional  \n        Number of cells considered for defining the local neighbhourhood.\n    permutation : int, optional  \n        The number of permutations to be performed for calculating the P-Value.\n    imageid : string, optional  \n        Column name of the column containing the image id.\n    subset : string, optional  \n        imageid of a single image to be subsetted for analyis.\n    pval_method : string, optional  \n        Two options are available: a) 'histocat', b) 'zscore'.  \n        a) P-values are calculated by subtracting the permuted mean from the observed mean\n        divided by the number of permutations as described in the histoCAT manuscript (Denis et.al, Nature Methods 2017)  \n        b) zscores are calculated from the mean and standard deviation and further p-values are\n        derived by fitting the observed values to a normal distribution. The default is 'histocat'.\n    label : string, optional  \n        Key for the returned data, stored in `adata.obs`. The default is 'spatial_interaction'.\nReturns:\n    adata : AnnData object  \n        Updated AnnData object with the results stored in `adata.obs['spatial_aggregate']`.\n\nExample:\n```python\n    # Using the radius method to identify local neighbours and histocat to compute P-values\n    adata = sm.tl.spatial_interaction(adata, method='radius', radius=30, pval_method='histocat',\n                                      imageid='imageid',x_coordinate='X',y_coordinate='Y')\n\n\n    # Using the KNN method to identify local neighbours and zscore to compute P-values\n    adata = sm.tl.spatial_interaction(adata, method='knn', radius=30,pval_method='zscore',\n                                      imageid='ImageId',x_coordinate='X_position',y_coordinate='Y_position')\n\n    # Interaction analysis on 3D data\n    adata = sm.tl.spatial_interaction(adata, method='radius', radius=60, pval_method='zscore',\n                                      imageid='ImageId',x_coordinate='X_position',\n                                      y_coordinate='Y_position', z_coordinate='Z_position')\n```\n    \"\"\"\n\n\n    def spatial_interaction_internal (adata_subset,x_coordinate,y_coordinate,\n                                      z_coordinate,\n                                      phenotype,\n                                      method, radius, knn,\n                                      permutation, \n                                      imageid,subset,\n                                      pval_method):\n\n        print(\"Processing Image: \" + str(adata_subset.obs[imageid].unique()))\n\n        # Create a dataFrame with the necessary inforamtion\n        if z_coordinate is not None:\n            print(\"Including Z -axis\")\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'z': adata_subset.obs[z_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n        else:\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n\n\n        # Identify neighbourhoods based on the method used\n        # a) KNN method\n        if method == 'knn':\n            print(\"Identifying the \" + str(knn) + \" nearest neighbours for every cell\")\n            if z_coordinate is not None:\n                tree = BallTree(data[['x','y','z']], leaf_size= 2)\n                ind = tree.query(data[['x','y','z']], k=knn, return_distance= False)\n            else:\n                tree = BallTree(data[['x','y']], leaf_size= 2)\n                ind = tree.query(data[['x','y']], k=knn, return_distance= False)\n            neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n            neighbours.drop(0, axis=1, inplace=True) # Remove self neighbour\n\n        # b) Local radius method\n        if method == 'radius':\n            print(\"Identifying neighbours within \" + str(radius) + \" pixels of every cell\")\n            if z_coordinate is not None:\n                kdt = BallTree(data[['x','y','z']], metric='euclidean') \n                ind = kdt.query_radius(data[['x','y','z']], r=radius, return_distance=False)\n            else:\n                kdt = BallTree(data[['x','y']], metric='euclidean') \n                ind = kdt.query_radius(data[['x','y']], r=radius, return_distance=False)\n\n            for i in range(0, len(ind)): ind[i] = np.delete(ind[i], np.argwhere(ind[i] == i))#remove self\n            neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n\n        # Map Phenotypes to Neighbours\n        # Loop through (all functionized methods were very slow)\n        phenomap = dict(zip(list(range(len(ind))), data['phenotype'])) # Used for mapping\n        print(\"Mapping phenotype to neighbors\")\n        for i in neighbours.columns:\n            neighbours[i] = neighbours[i].dropna().map(phenomap, na_action='ignore')\n\n        # Drop NA\n        neighbours = neighbours.dropna(how='all')\n\n        # Collapse all the neighbours into a single column\n        n = pd.DataFrame(neighbours.stack(), columns = [\"neighbour_phenotype\"])\n        n.index = n.index.get_level_values(0) # Drop the multi index\n\n        # Merge with real phenotype\n        n = n.merge(data['phenotype'], how='inner', left_index=True, right_index=True)\n\n        # Permutation\n        print('Performing '+ str(permutation) + ' permutations')\n\n        def permutation_pval (data):\n            data = data.assign(neighbour_phenotype=np.random.permutation(data['neighbour_phenotype']))\n            #data['neighbour_phenotype'] = np.random.permutation(data['neighbour_phenotype'])\n            data_freq = data.groupby(['phenotype','neighbour_phenotype']).size().unstack()\n            data_freq = data_freq.fillna(0).stack().values \n            return data_freq\n\n        # Apply function\n        final_scores = Parallel(n_jobs=-1)(delayed(permutation_pval)(data=n) for i in range(permutation)) \n        perm = pd.DataFrame(final_scores).T\n\n        # Consolidate the permutation results\n        print('Consolidating the permutation results')\n        # Calculate P value\n        # real\n        n_freq = n.groupby(['phenotype','neighbour_phenotype']).size().unstack().fillna(0).stack() \n        # permutation\n        mean = perm.mean(axis=1)\n        std = perm.std(axis=1)\n        # P-value calculation\n        if pval_method == 'histocat':\n            # real value - prem value / no of perm \n            p_values = abs(n_freq.values - mean) / (permutation+1)\n            p_values = p_values[~np.isnan(p_values)].values\n        if pval_method == 'zscore':\n            z_scores = (n_freq.values - mean) / std        \n            z_scores[np.isnan(z_scores)] = 0\n            p_values = scipy.stats.norm.sf(abs(z_scores))*2\n            p_values = p_values[~np.isnan(p_values)]\n\n        # Compute Direction of interaction (interaction or avoidance)\n        direction = ((n_freq.values - mean) / abs(n_freq.values - mean)).fillna(1)\n\n        # Normalize based on total cell count\n        k = n.groupby(['phenotype','neighbour_phenotype']).size().unstack().fillna(0)\n        # add neighbour phenotype that are not present to make k a square matrix\n        columns_to_add = dict.fromkeys(np.setdiff1d(k.index,k.columns), 0)\n        k = k.assign(**columns_to_add)\n\n        total_cell_count = data['phenotype'].value_counts()\n        total_cell_count = total_cell_count[k.columns].values # keep only cell types that are present in the column of k\n        # total_cell_count = total_cell_count.reindex(k.columns).values # replaced by above\n        k_max = k.div(total_cell_count, axis = 0)\n        k_max = k_max.div(k_max.max(axis=1), axis=0).stack()\n\n        # DataFrame with the neighbour frequency and P values\n        count = (k_max.values * direction).values # adding directionallity to interaction\n        neighbours = pd.DataFrame({'count': count,'p_val': p_values}, index = k_max.index)\n        #neighbours.loc[neighbours[neighbours['p_val'] &gt; p_val].index,'count'] = np.NaN\n        #del neighbours['p_val']\n        neighbours.columns = [adata_subset.obs[imageid].unique()[0], 'pvalue_' + str(adata_subset.obs[imageid].unique()[0])]\n        neighbours = neighbours.reset_index()\n        #neighbours = neighbours['count'].unstack()\n\n        # return\n        return neighbours\n\n\n    # subset a particular subset of cells if the user wants else break the adata into list of anndata objects\n    if subset is not None:\n        adata_list = [adata[adata.obs[imageid] == subset]]\n    else:\n        adata_list = [adata[adata.obs[imageid] == i] for i in adata.obs[imageid].unique()]\n\n\n    # Apply function to all images and create a master dataframe\n    # Create lamda function \n    r_spatial_interaction_internal = lambda x: spatial_interaction_internal (adata_subset=x, x_coordinate=x_coordinate, y_coordinate=y_coordinate, \n                                                                             z_coordinate=z_coordinate, phenotype=phenotype, method=method,  radius=radius, knn=knn, permutation=permutation, imageid=imageid,subset=subset,pval_method=pval_method) \n    all_data = list(map(r_spatial_interaction_internal, adata_list)) # Apply function \n\n\n    # Merge all the results into a single dataframe    \n    df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['phenotype', 'neighbour_phenotype'], how='outer'), all_data)\n\n\n    # Add to anndata\n    adata.uns[label] = df_merged\n\n    # return\n    return adata\n</code></pre>"},{"location":"Functions/tl/spatial_lda/","title":"spatial_lda","text":"<p>Short Description</p> <p><code>sm.tl.spatial_lda</code>: The function allows users to compute a neighbourhood matrix  using any categorical variable (e.g. cell-types) as input and then perform  Latent Dirichlet Allocation (LDA) modelling. The latent space weights are then then  returned which can be clustered to identify Reccurent Cellular Neighbourhoods (RCNs).</p> <p>Use the [spatial_cluster] function to further group the neighbourhoods into  Reccurent Cellular Neighbourhoods (RCNs)</p>"},{"location":"Functions/tl/spatial_lda/#scimap.tools._spatial_lda--function","title":"Function","text":""},{"location":"Functions/tl/spatial_lda/#scimap.tools._spatial_lda.spatial_lda","title":"<code>spatial_lda(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid', phenotype='phenotype', method='radius', radius=30, knn=10, imageid='imageid', num_motifs=10, random_state=0, subset=None, label='spatial_lda', **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData object</p> required <code>x_coordinate</code> <p>float, required Column name containing the x-coordinates values.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <p>float, required Column name containing the y-coordinates values.</p> <code>'Y_centroid'</code> <code>phenotype</code> <p>string, required Column name of the column containing the phenotype information.  It could also be any categorical assignment given to single cells.</p> <code>'phenotype'</code> <code>method</code> <p>string, optional Two options are available: a) 'radius', b) 'knn'. a) radius - Identifies the neighbours within a given radius for every cell. b) knn - Identifies the K nearest neigbours for every cell.  </p> <code>'radius'</code> <code>radius</code> <p>int, optional The radius used to define a local neighbhourhood.</p> <code>30</code> <code>knn</code> <p>int, optional Number of cells considered for defining the local neighbhourhood.</p> <code>10</code> <code>imageid</code> <p>string, optional Column name of the column containing the image id.</p> <code>'imageid'</code> <code>subset</code> <p>string, optional imageid of a single image to be subsetted for analyis.</p> <code>None</code> <code>num_motifs</code> <p>int, optional The number of requested latent motifs to be extracted from the training corpus.</p> <code>10</code> <code>random_state</code> <p>int, optional Either a randomState object or a seed to generate one. Useful for reproducibility.</p> <code>0</code> <code>label</code> <p>string, optional Key for the returned data, stored in <code>adata.uns</code>.</p> <code>'spatial_lda'</code> <p>Returns:</p> Name Type Description <code>adata</code> <p>AnnData object Updated AnnData object with the results stored in <code>adata.uns ['spatial_lda']</code>.</p> <pre><code>    # Running the radius method\n    adata = sm.tl.spatial_lda (adata, num_motifs=10, radius=100)\n</code></pre> Source code in <code>scimap/tools/_spatial_lda.py</code> <pre><code>def spatial_lda (adata, x_coordinate='X_centroid',y_coordinate='Y_centroid',\n                 phenotype='phenotype', method='radius', radius=30, knn=10,\n                 imageid='imageid',num_motifs=10, random_state=0, subset=None,\n                 label='spatial_lda',**kwargs):\n\"\"\"\nParameters:\n    adata : AnnData object\n\n    x_coordinate : float, required  \n        Column name containing the x-coordinates values.\n\n    y_coordinate : float, required  \n        Column name containing the y-coordinates values.\n\n    phenotype : string, required  \n        Column name of the column containing the phenotype information. \n        It could also be any categorical assignment given to single cells.\n\n    method : string, optional  \n        Two options are available: a) 'radius', b) 'knn'.  \n        a) radius - Identifies the neighbours within a given radius for every cell.  \n        b) knn - Identifies the K nearest neigbours for every cell.  \n\n    radius : int, optional  \n        The radius used to define a local neighbhourhood.\n\n    knn : int, optional  \n        Number of cells considered for defining the local neighbhourhood.\n\n    imageid : string, optional  \n        Column name of the column containing the image id.\n\n    subset : string, optional  \n        imageid of a single image to be subsetted for analyis.\n\n    num_motifs : int, optional  \n        The number of requested latent motifs to be extracted from the training corpus.\n\n    random_state : int, optional  \n        Either a randomState object or a seed to generate one. Useful for reproducibility.\n\n    label : string, optional  \n        Key for the returned data, stored in `adata.uns`.\n\nReturns:\n    adata : AnnData object  \n        Updated AnnData object with the results stored in `adata.uns ['spatial_lda']`.\n\nExample:\n```python\n    # Running the radius method\n    adata = sm.tl.spatial_lda (adata, num_motifs=10, radius=100)\n```\n    \"\"\"\n\n    # Function\n    def spatial_lda_internal (adata_subset, x_coordinate,y_coordinate,phenotype, \n                              method, radius, knn, imageid):\n\n        # Print which image is being processed\n        print('Processing: ' + str(np.unique(adata_subset.obs[imageid])))\n\n        # Create a DataFrame with the necessary inforamtion\n        data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n\n        # Identify neighbourhoods based on the method used\n        # a) KNN method\n        if method == 'knn':\n            print(\"Identifying the \" + str(knn) + \" nearest neighbours for every cell\")\n            tree = BallTree(data[['x','y']], leaf_size= 2)\n            ind = tree.query(data[['x','y']], k=knn, return_distance= False)\n            #ind = [np.array(x) for x in ind]\n            ind = list(np.array(item) for item in ind)\n\n        # b) Local radius method\n        if method == 'radius':\n            print(\"Identifying neighbours within \" + str(radius) + \" pixels of every cell\")\n            kdt = BallTree(data[['x','y']], leaf_size= 2) \n            ind = kdt.query_radius(data[['x','y']], r=radius, return_distance=False)\n\n        # Map phenotype\n        phenomap = dict(zip(list(range(len(ind))), data['phenotype'])) # Used for mapping\n        for i in range(len(ind)):\n            ind[i] = [phenomap[letter] for letter in ind[i]]\n\n        # return\n        return ind\n\n    # Subset a particular image if needed\n    if subset is not None:\n        adata_list = [adata[adata.obs[imageid] == subset]]\n    else:\n        adata_list = [adata[adata.obs[imageid] == i] for i in adata.obs[imageid].unique()]\n\n    # Apply function to all images\n    # Create lamda function \n    r_spatial_lda_internal = lambda x: spatial_lda_internal(adata_subset=x,\n                                                            x_coordinate=x_coordinate,\n                                                            y_coordinate=y_coordinate,\n                                                            phenotype=phenotype, \n                                                            method=method, \n                                                            radius=radius, \n                                                            knn=knn, \n                                                            imageid=imageid) \n    all_data = list(map(r_spatial_lda_internal, adata_list)) # Apply function \n\n    # combine all the data into one\n    texts = np.concatenate( all_data, axis=0 ).tolist()\n\n    # LDA pre-processing\n    print ('Pre-Processing Spatial LDA')\n    # Create Dictionary\n    id2word = corpora.Dictionary(texts)\n\n    # Term Document Frequency\n    corpus = [id2word.doc2bow(text) for text in texts]\n\n    # Build LDA model\n    print ('Training Spatial LDA')\n    try:\n        lda_model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n                                                   id2word=id2word,\n                                                   num_topics=num_motifs, \n                                                   random_state=random_state,**kwargs)\n    except:\n        lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n                                                   id2word=id2word,\n                                                   num_topics=num_motifs, \n                                                   random_state=random_state,**kwargs)\n\n    # Compute Coherence Score\n    print ('Calculating the Coherence Score')\n    coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n    coherence_lda = coherence_model_lda.get_coherence()\n    print('\\nCoherence Score: ', coherence_lda)\n\n    # isolate the latent features\n    print ('Gathering the latent weights')\n    topic_weights = []\n    for row_list in lda_model[corpus]:\n        tmp = np.zeros(num_motifs)\n        for i, w in row_list:\n            tmp[i] = w\n        topic_weights.append(tmp)\n    # conver to dataframe\n    arr = pd.DataFrame(topic_weights, index=adata.obs.index).fillna(0)\n    arr = arr.add_prefix('Motif_')\n\n    # isolate the weights of phenotypes\n    pattern = \"(\\d\\.\\d+).\\\"(.*?)\\\"\"\n    cell_weight = pd.DataFrame(index=np.unique(adata.obs[phenotype]))\n    for i in range(0, len(lda_model.print_topics())):\n        level1 = lda_model.print_topics()[i][1]\n        tmp = pd.DataFrame(re.findall(pattern, level1))\n        tmp.index = tmp[1]\n        tmp = tmp.drop(columns=1)\n        tmp.columns = ['Motif_'+ str(i)]\n        cell_weight = cell_weight.merge(tmp, how='outer', left_index=True, right_index=True)\n    # fill zeros\n    cell_weight = cell_weight.fillna(0).astype(float)\n\n    # save the results in anndata object\n    adata.uns[label] = arr # save the weight for each cell\n    adata.uns[str(label)+'_probability'] = cell_weight # weights of each cell type\n    #adata.uns[str(label)+'_model'] = lda_model\n\n    # return\n    return adata\n</code></pre>"},{"location":"Functions/tl/spatial_pscore/","title":"spatial_pscore","text":"<p>Short Description</p> <p><code>sm.tl.spatial_pscore</code>: A scoring system to evaluate user defined proximity between cell types. The function generates two scores and saved at <code>adata.uns</code>:  A) Proximity Density: Total number of interactions identified divided by the total number of  cells of the cell-types that were used for interaction analysis. B) Proximity Volume: Total number of interactions identified divided by the total number of all cells in the data. The interaction sites are also recorded and saved in <code>adata.obs</code></p>"},{"location":"Functions/tl/spatial_pscore/#scimap.tools._spatial_pscore--functions","title":"Functions","text":""},{"location":"Functions/tl/spatial_pscore/#scimap.tools._spatial_pscore.spatial_pscore","title":"<code>spatial_pscore(adata, proximity, score_by='imageid', x_coordinate='X_centroid', y_coordinate='Y_centroid', phenotype='phenotype', method='radius', radius=20, knn=3, imageid='imageid', subset=None, label='spatial_pscore')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData object</p> required <code>proximity</code> <p>list Pass a list of cell-types for which the proximity score needs to calculated. e.g. ['CellType-A', 'CellType-B']</p> required <code>score_by</code> <p>string, optional If the scores need to compared across region's of interest, the column name containing the ROI's should be passed. By default the score is calculated across the entire image.</p> <code>'imageid'</code> <code>x_coordinate</code> <p>float, required Column name containing the x-coordinates values.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <p>float, required Column name containing the y-coordinates values.</p> <code>'Y_centroid'</code> <code>phenotype</code> <p>string, required Column name of the column containing the phenotype information.  It could also be any categorical assignment given to single cells.</p> <code>'phenotype'</code> <code>method</code> <p>string, optional Two options are available: a) 'radius', b) 'knn'. a) radius - Identifies the neighbours within a given radius for every cell. b) knn - Identifies the K nearest neigbours for every cell.  </p> <code>'radius'</code> <code>radius</code> <p>int, optional The radius used to define a local neighbhourhood.</p> <code>20</code> <code>knn</code> <p>int, optional Number of cells considered for defining the local neighbhourhood.</p> <code>3</code> <code>imageid</code> <p>string, optional Column name of the column containing the image id.</p> <code>'imageid'</code> <code>subset</code> <p>string, optional imageid of a single image to be subsetted for analyis.</p> <code>None</code> <code>label</code> <p>string, optional Key for the returned data, stored in <code>adata.obs</code> and <code>adata.uns</code>.</p> <code>'spatial_pscore'</code> <p>Returns:</p> Name Type Description <code>adata</code> <p>AnnData object Updated AnnData object with the results stored in <code>adata.obs ['spatial_pscore']</code> and <code>adata.uns ['spatial_pscore']</code>.</p> <pre><code>    # Calculate the score for proximity between `Tumor CD30+` cells and `M2 Macrophages`\n    adata =  sm.tl.spatial_pscore (adata,proximity= ['Tumor CD30+', 'M2 Macrophages'], score_by = 'ImageId',\n                             x_coordinate='X_position',y_coordinate='Y_position',\n                             phenotype='phenotype',method='radius',radius=20,knn=3,\n                             imageid='ImageId',subset=None, label='spatial_pscore')\n</code></pre> Source code in <code>scimap/tools/_spatial_pscore.py</code> <pre><code>def spatial_pscore (adata,proximity, score_by='imageid', x_coordinate='X_centroid',y_coordinate='Y_centroid',\n                    phenotype='phenotype',method='radius',radius=20,knn=3,\n                    imageid='imageid',subset=None, label='spatial_pscore'):\n\"\"\"\nParameters:\n    adata : AnnData object\n\n    proximity : list  \n        Pass a list of cell-types for which the proximity score needs to calculated. e.g. ['CellType-A', 'CellType-B']\n\n    score_by : string, optional  \n        If the scores need to compared across region's of interest, the column name containing the ROI's\n        should be passed. By default the score is calculated across the entire image.\n\n    x_coordinate : float, required  \n        Column name containing the x-coordinates values.\n\n    y_coordinate : float, required  \n        Column name containing the y-coordinates values.\n\n    phenotype : string, required  \n        Column name of the column containing the phenotype information. \n        It could also be any categorical assignment given to single cells.\n\n    method : string, optional  \n        Two options are available: a) 'radius', b) 'knn'.  \n        a) radius - Identifies the neighbours within a given radius for every cell.  \n        b) knn - Identifies the K nearest neigbours for every cell.  \n\n    radius : int, optional  \n        The radius used to define a local neighbhourhood.\n\n    knn : int, optional  \n        Number of cells considered for defining the local neighbhourhood.\n\n    imageid : string, optional  \n        Column name of the column containing the image id.\n\n    subset : string, optional  \n        imageid of a single image to be subsetted for analyis.\n\n    label : string, optional  \n        Key for the returned data, stored in `adata.obs` and `adata.uns`.\n\nReturns:\n    adata : AnnData object  \n        Updated AnnData object with the results stored in `adata.obs ['spatial_pscore']` and `adata.uns ['spatial_pscore']`.\n\nExample:\n```python\n    # Calculate the score for proximity between `Tumor CD30+` cells and `M2 Macrophages`\n    adata =  sm.tl.spatial_pscore (adata,proximity= ['Tumor CD30+', 'M2 Macrophages'], score_by = 'ImageId',\n                             x_coordinate='X_position',y_coordinate='Y_position',\n                             phenotype='phenotype',method='radius',radius=20,knn=3,\n                             imageid='ImageId',subset=None, label='spatial_pscore')\n\n```\n    \"\"\"\n\n\n    # Start\n    def spatial_pscore_internal (adata_subset,proximity,x_coordinate,y_coordinate,phenotype,method,radius,knn,\n                                imageid,subset,label):\n\n        # Create a DataFrame with the necessary inforamtion\n        data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n\n        # Identify neighbourhoods based on the method used\n        # a) KNN method\n        if method == 'knn':\n            print(\"Identifying the \" + str(knn) + \" nearest neighbours for every cell\")\n            tree = BallTree(data[['x','y']], leaf_size= 2)\n            ind = tree.query(data[['x','y']], k=knn, return_distance= False)\n            neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n            neighbours_ind = neighbours.copy() # neighbour DF\n            #neighbours.drop(0, axis=1, inplace=True) # Remove self neighbour\n\n        # b) Local radius method\n        if method == 'radius':\n            print(\"Identifying neighbours within \" + str(radius) + \" pixels of every cell\")\n            kdt = BallTree(data[['x','y']], metric='euclidean') \n            ind = kdt.query_radius(data[['x','y']], r=radius, return_distance=False)\n            #for i in range(0, len(ind)): ind[i] = np.delete(ind[i], np.argwhere(ind[i] == i))#remove self\n            neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n            neighbours_ind = neighbours.copy() # neighbour DF\n\n        # Map phenotype\n        phenomap = dict(zip(list(range(len(ind))), data['phenotype'])) # Used for mapping\n        phenomap_ind = dict(zip(list(range(len(ind))), data.index)) # Used for mapping cell_nme\n\n        # Loop through (all functionized methods were very slow)\n        for i in neighbours.columns:\n            neighbours[i] = neighbours[i].dropna().map(phenomap, na_action='ignore')\n        # do the same index and cell name\n        for i in neighbours_ind.columns:\n            neighbours_ind[i] = neighbours_ind[i].dropna().map(phenomap_ind, na_action='ignore')\n\n\n        # Idetify all the neighbourhoods that contains the user defined proximity phenotypes\n        #for i in proximity:\n        #    print (str('Finding neighbourhoods with ') + str(i))\n        #    nn = neighbours[neighbours.isin([i])].dropna(how='all').index\n        #    neighbours = neighbours.loc[nn]\n        matches = np.ones(len(neighbours), bool)\n        for v in proximity:\n            matches &amp;= (neighbours == v).any(axis=1)\n        neighbours = neighbours[matches]\n\n\n        # Identify all the cells that was part of the neighbourhood in this analysis\n        neighbours_ind = neighbours_ind.loc[neighbours.index]\n        neighbours_ind_unique = pd.unique(neighbours_ind.values.ravel())\n\n        # subset the neighbourhood cells to include only the cells in the user defined list\n        cleaned_neighbours_ind_unique = [x for x in neighbours_ind_unique if str(x) != 'nan']\n        d = data.loc[cleaned_neighbours_ind_unique]\n        d = d[d[phenotype].isin(proximity)].index\n\n        # return neighbours for score and image_neighbours for plotting on image\n        return {'neighbours': neighbours.index, 'image_neighbours': d }\n\n\n    # Subset a particular image if needed\n    if subset is not None:\n        adata_list = [adata[adata.obs[imageid] == subset]]\n    else:\n        adata_list = [adata[adata.obs[imageid] == i] for i in adata.obs[imageid].unique()]\n\n    # Apply function to all images and create a master dataframe\n    # Create lamda function \n    r_spatial_pscore_internal = lambda x: spatial_pscore_internal(adata_subset=x,proximity=proximity,\n                                                   x_coordinate=x_coordinate,\n                                                   y_coordinate=y_coordinate,phenotype=phenotype,\n                                                   method=method,radius=radius,knn=knn,\n                                                   imageid=imageid,subset=subset,label=label) \n    all_data = list(map(r_spatial_pscore_internal, adata_list)) # Apply function\n\n\n    # Merge all the results into a single dataframe    \n    proximity_site_cells =  np.concatenate([d['image_neighbours'] for d in all_data], axis=0)\n\n    # Add it to the AnnData Object\n    adata.obs[label] = np.where(adata.obs.index.isin(proximity_site_cells), '_'.join(proximity), \"other\")\n\n    ##### SCORING #####\n    proximity_neigh = np.concatenate([d['neighbours'] for d in all_data], axis=0)\n    wh_d = adata.obs.copy()\n    wh_d[label] = np.where(wh_d.index.isin(proximity_neigh), '_'.join(proximity), \"other\")\n\n    # Define a scoring system\n    name = '_'.join(proximity)\n    whole_data = wh_d[[score_by, label, phenotype]]\n\n    # proximity volume\n    p_v = whole_data.groupby([score_by, label]).size().unstack().fillna(0)\n    p_v ['All Cells'] = p_v[name] + p_v[\"other\"]\n    p_v['Proximity Volume'] = p_v[name] / p_v['All Cells']\n    p_v = p_v.fillna(0) # replace NA\n    p_v = p_v.replace([np.inf, -np.inf], 0)\n    p_v = p_v.drop(columns = 'other')\n\n    # subset the phenotypes of interest\n    w_d = whole_data[whole_data[phenotype].isin(proximity)]\n    # proximity density\n    p_d = w_d.groupby([score_by, label]).size().unstack().fillna(0)\n    p_d ['Celltype of interest'] = p_d[name] + p_d[\"other\"]\n    p_d['Proximity Density'] = p_d[name] / p_d['Celltype of interest']\n    p_d = p_d.fillna(0) # replace NA\n    p_d = p_d.replace([np.inf, -np.inf], 0)\n    p_d = p_d.drop(columns = ['other', name])\n\n    # Merge Promimity volumne and density\n    proximity_score = pd.merge(p_v, p_d, left_index=True, right_index=True)\n\n    # Add it to the anndata object\n    adata.uns[label] = proximity_score\n\n    # Print\n    print(\"Please check:\\nadata.obs['\" + str(label) + \"'] &amp;\\nadata.uns['\"+ str(label) + \"'] for results\")\n\n    # Return \n    return adata\n</code></pre>"},{"location":"Functions/tl/spatial_similarity_search/","title":"spatial_similarity_search","text":"<p>Short Description</p> <p><code>sm.tl.spatial_similarity_search</code>: The function allows users to identify regions within a image  that are similar to a user defined region based on the underlying molecular profile.</p> <p>The result is saved within <code>adata.obs</code>. The user can visualize the results on the image using <code>sm.pl.image_viewer</code> and then modify the <code>similarity_threshold</code> parameter to attain the best redults. </p>"},{"location":"Functions/tl/spatial_similarity_search/#scimap.tools._spatial_similarity_search--function","title":"Function","text":""},{"location":"Functions/tl/spatial_similarity_search/#scimap.tools._spatial_similarity_search.spatial_similarity_search","title":"<code>spatial_similarity_search(adata, ROI_column, x_coordinate='X_centroid', y_coordinate='Y_centroid', similarity_threshold=0.5, ROI_subset=None, method='radius', radius=30, knn=10, imageid='imageid', use_raw=True, subset=None, label='spatial_similarity_search', reuse_similarity_matrix=None, morphological_features=None, use_only_morphological_features=False, output_dir=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData object loaded into memory or path to AnnData object.  </p> required <code>ROI_column</code> <p>string, required Column name containing the ROI or region for which the similarity is sorted. This should be a small region in the image that the user is interested in. The ROI can be added by using the <code>sm.pl.addROI_image</code> function.  </p> required <code>ROI_subset</code> <p>list, optional A list of ROI's within the <code>ROI_column</code> for which similarity is sorted. By default similarity is calculated for  every ROI within the <code>ROI_column</code>. The user can also restrict it to one or fewer ROI's by passing its name through  this parameter. The default is None.  </p> <code>None</code> <code>similarity_threshold</code> <p>float, optional This threshold can be changed to adjust for the strictness of similarity. Often the user would need to run this  function with multiple <code>thresholds</code> to identify the best fit (based on visual interpretation of the results.  To decrease compute time during this process the  similarity vectors are saved and hence this parameter can be  coupled with <code>reuse_similarity_matrix</code> parameter for optimal run time efficiency. The default is 0.5.</p> <code>0.5</code> <code>x_coordinate</code> <p>float, required Column name containing the x-coordinates values.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <p>float, required Column name containing the y-coordinates values.  </p> <code>'Y_centroid'</code> <code>method</code> <p>string, optional Two options are available: a) <code>radius</code>, b) <code>knn</code>. a) <code>radius</code> - Identifies the neighbours within a given radius for every cell. b) <code>knn</code> - Identifies the K nearest neigbours for every cell.  </p> <code>'radius'</code> <code>radius</code> <p>int, optional The radius used to define a local neighbhourhood.</p> <code>30</code> <code>knn</code> <p>int, optional Number of cells considered for defining the local neighbhourhood.</p> <code>10</code> <code>imageid</code> <p>string, optional Column name of the column containing the image id.</p> <code>'imageid'</code> <code>use_raw</code> <p>boolian, optional Argument to denote whether to use the raw data or scaled data after applying <code>sm.pp.rescale</code>.</p> <code>True</code> <code>subset</code> <p>string, optional imageid of a single image to be subsetted for analyis. Note, if this is used, the similarity will  not be computed for other images in the dataset. This is often used for quick look at a single image. </p> <code>None</code> <code>label</code> <p>string, optional Key for the returned data, stored in <code>adata.obs</code>. The results will be stored as [label]_ROIname</p> <code>'spatial_similarity_search'</code> <code>reuse_similarity_matrix</code> <p>string, optional In order to save compute time for large datasets, this function can be run once and the <code>similarity_threshold</code>  can be adjusted multiple times to identify the regions that best resemble the input ROI. In order to use this  parameter, pass the <code>label</code> used when running this function for the first time. The defaul label is  <code>spatial_similarity_search</code>. The default is None.</p> <code>None</code> <code>morphological_features</code> <p>list, optional For calculating the similarity between regions, in addition to the molecular/marker inforamtion, any additional  information such as morphological features pertaining to individual cells can be passed into the algorithm.  If the data was generated using the <code>mcmicro</code> pipeline these ['Area', 'MajorAxisLength','MinorAxisLength', 'Eccentricity', 'Solidity', 'Extent', 'Orientation']  are the usual morphological features that are captured. These can be passed into this parameter. Note one can use any additional  feature that is stored in <code>adata.obs</code>. The default is None. </p> <code>None</code> <code>use_only_morphological_features</code> <p>bool, optional If the user passes data through <code>morphological_features</code>, one also has an option to identify regions of similarity  just using the morphological features. If <code>morphological_features</code> is included and <code>use_only_morphological_features</code>  is set to <code>False</code>, both the morphological features and molecular features will be used. The default is False.</p> <code>False</code> <code>output_dir</code> <p>string, optional Path to output directory.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>adata</code> <p>AnnData object Updated AnnData object with the results stored in <code>adata.obs [{label}_{ROIname}]</code>.</p> <pre><code>    # Running the spatial_similarity_search with the radius method\n    adata = sm.tl.spatial_similarity_search (adata,ROI_column = 'Blood_Vessel_ROI',\n                                               similarity_threshold=0.5,\n                                               ROI_subset = 'blood_vessel',\n                                               method='radius', radius=30, \n                                               label='spatial_similarity_search',\n                                               reuse_similarity_matrix=None)\n\n    # Rerun to adjust the similarity_threshold while using the pre-computed similarity matrix\n    adata = sm.tl.spatial_similarity_search (adata,ROI_column = 'Blood_Vessel_ROI',\n                                               similarity_threshold=0.7,\n                                               ROI_subset = 'blood_vessel',\n                                               method='radius', radius=30, \n                                               label='spatial_similarity_search',\n                                               reuse_similarity_matrix='spatial_similarity_search')\n    # visulaize the results in napari\n    image_path = \"/Users/aj/Documents/exemplar-001/registration/exemplar-001.ome.tif\"\n    sm.pl.image_viewer (image_path, adata, subset = 'unmicst-exemplar-001_cell', \n                        overlay='spatial_similarity_search_blood_vessel', point_color='White')\n</code></pre> Source code in <code>scimap/tools/_spatial_similarity_search.py</code> <pre><code>def spatial_similarity_search (adata,ROI_column,\n                               x_coordinate='X_centroid',\n                               y_coordinate='Y_centroid',\n                               similarity_threshold=0.5,\n                               ROI_subset = None,\n                               method='radius', radius=30, \n                               knn=10, imageid='imageid', \n                               use_raw=True, subset=None,\n                               label='spatial_similarity_search',\n                               reuse_similarity_matrix=None,\n                               morphological_features=None,\n                               use_only_morphological_features=False,\n                               output_dir=None):\n\"\"\"\nParameters:\n    adata : AnnData object loaded into memory or path to AnnData object.  \n\n    ROI_column : string, required  \n        Column name containing the ROI or region for which the similarity is sorted. This should be a small region in the\n        image that the user is interested in. The ROI can be added by using the `sm.pl.addROI_image` function.  \n\n    ROI_subset : list, optional  \n        A list of ROI's within the `ROI_column` for which similarity is sorted. By default similarity is calculated for \n        every ROI within the `ROI_column`. The user can also restrict it to one or fewer ROI's by passing its name through \n        this parameter. The default is None.  \n\n    similarity_threshold : float, optional  \n        This threshold can be changed to adjust for the strictness of similarity. Often the user would need to run this \n        function with multiple `thresholds` to identify the best fit (based on visual interpretation of the results. \n        To decrease compute time during this process the  similarity vectors are saved and hence this parameter can be \n        coupled with `reuse_similarity_matrix` parameter for optimal run time efficiency. The default is 0.5.\n\n    x_coordinate : float, required  \n        Column name containing the x-coordinates values.\n\n    y_coordinate : float, required  \n        Column name containing the y-coordinates values.  \n\n    method : string, optional  \n        Two options are available: a) `radius`, b) `knn`.  \n        a) `radius` - Identifies the neighbours within a given radius for every cell.  \n        b) `knn` - Identifies the K nearest neigbours for every cell.  \n\n    radius : int, optional  \n        The radius used to define a local neighbhourhood.\n\n    knn : int, optional  \n        Number of cells considered for defining the local neighbhourhood.\n\n    imageid : string, optional  \n        Column name of the column containing the image id.\n\n    use_raw : boolian, optional  \n        Argument to denote whether to use the raw data or scaled data after applying `sm.pp.rescale`.\n\n    subset : string, optional  \n        imageid of a single image to be subsetted for analyis. Note, if this is used, the similarity will \n        not be computed for other images in the dataset. This is often used for quick look at a single image. \n\n    label : string, optional  \n        Key for the returned data, stored in `adata.obs`. The results will be stored as [label]_ROIname\n\n    reuse_similarity_matrix : string, optional  \n        In order to save compute time for large datasets, this function can be run once and the `similarity_threshold` \n        can be adjusted multiple times to identify the regions that best resemble the input ROI. In order to use this \n        parameter, pass the `label` used when running this function for the first time. The defaul label is \n        `spatial_similarity_search`. The default is None.\n\n    morphological_features : list, optional  \n        For calculating the similarity between regions, in addition to the molecular/marker inforamtion, any additional \n        information such as morphological features pertaining to individual cells can be passed into the algorithm. \n        If the data was generated using the `mcmicro` pipeline these ['Area', 'MajorAxisLength','MinorAxisLength', 'Eccentricity', 'Solidity', 'Extent', 'Orientation'] \n        are the usual morphological features that are captured. These can be passed into this parameter. Note one can use any additional \n        feature that is stored in `adata.obs`. The default is None. \n\n    use_only_morphological_features : bool, optional  \n        If the user passes data through `morphological_features`, one also has an option to identify regions of similarity \n        just using the morphological features. If `morphological_features` is included and `use_only_morphological_features` \n        is set to `False`, both the morphological features and molecular features will be used. The default is False.\n\n    output_dir : string, optional  \n        Path to output directory.\n\nReturns:\n    adata : AnnData object  \n        Updated AnnData object with the results stored in `adata.obs [{label}_{ROIname}]`.\n\nExample:\n```python\n    # Running the spatial_similarity_search with the radius method\n    adata = sm.tl.spatial_similarity_search (adata,ROI_column = 'Blood_Vessel_ROI',\n                                               similarity_threshold=0.5,\n                                               ROI_subset = 'blood_vessel',\n                                               method='radius', radius=30, \n                                               label='spatial_similarity_search',\n                                               reuse_similarity_matrix=None)\n\n    # Rerun to adjust the similarity_threshold while using the pre-computed similarity matrix\n    adata = sm.tl.spatial_similarity_search (adata,ROI_column = 'Blood_Vessel_ROI',\n                                               similarity_threshold=0.7,\n                                               ROI_subset = 'blood_vessel',\n                                               method='radius', radius=30, \n                                               label='spatial_similarity_search',\n                                               reuse_similarity_matrix='spatial_similarity_search')\n    # visulaize the results in napari\n    image_path = \"/Users/aj/Documents/exemplar-001/registration/exemplar-001.ome.tif\"\n    sm.pl.image_viewer (image_path, adata, subset = 'unmicst-exemplar-001_cell', \n                        overlay='spatial_similarity_search_blood_vessel', point_color='White')\n\n```\n    \"\"\"\n\n\n    #x_coordinate='X_centroid'; y_coordinate='Y_centroid'; method='radius'; radius=30; knn=10; imageid='imageid'; \n    #use_raw=True ; log=True; subset=None; label='spatial_similarity_search'; output_dir=None; ROI_column='ASMA'; ROI_subset = None; similarity_threshold=0.5\n    # morphological_features = ['Area', 'MajorAxisLength','MinorAxisLength', 'Eccentricity', 'Solidity', 'Extent', 'Orientation']\n    #adata_subset = adata.copy()\n\n    # Load the andata object    \n    if isinstance(adata, str):\n        imid = str(adata.rsplit('/', 1)[-1])\n        adata = anndata.read(adata)\n    else:\n        imid = \"adata_spatial_similarity_search\"\n        adata = adata\n\n    # Error statements\n    if use_raw is False:\n        if all(adata.X[0] &lt; 1) is False:\n            raise ValueError('Please run `sm.pp.rescale` first if you wish to use `use_raw = False`')\n\n    # Function to calculate the distance between two vectors\n    @numba.jit(nopython=True, parallel=True, cache=True)\n    def euclidian_score(query_neighbourhood):\n        return 1.0 / ((np.sqrt(np.sum((spatial_lag_array - query_neighbourhood) ** 2, axis=1))) + 1.0)\n\n\n    def spatial_expression_internal (adata_subset, x_coordinate, y_coordinate,\n                                     method, radius, knn, imageid, use_raw,\n                                     morphological_features, use_only_morphological_features):\n\n        # Create a DataFrame with the necessary inforamtion\n        data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate]})\n\n        # Identify neighbourhoods based on the method used\n        # a) KNN method\n        if method == 'knn':\n            print(\"Identifying the \" + str(knn) + \" nearest neighbours for every cell\")\n            tree = BallTree(data, leaf_size= 2)\n            dist, ind = tree.query(data, k=knn, return_distance= True)\n\n\n        # b) Local radius method\n        if method == 'radius':\n            print(\"Identifying neighbours within \" + str(radius) + \" pixels of every cell\")\n            kdt = BallTree(data, metric='euclidean')\n            ind, dist = kdt.query_radius(data, r=radius, return_distance= True)\n\n        # Normalize range (0-1) and account for total number of cells \n        d = scipy.sparse.lil_matrix((len(data), len(data)))\n        for row, (columns, values) in enumerate(zip(ind, dist)):\n            # Drop self-distance element.\n            idx = columns != row\n            columns = columns[idx]\n            values = values[idx]\n            if len(values) == 1:\n                values = [1.0]\n            elif len(values) &gt; 1:\n                # Normalize distances.\n                values = (values.max() - values) / (values.max() - values.min())\n                values /= values.sum()\n            # Assign row to matrix.\n            d[row, columns] = values\n\n        # convert to csr sparse matrix\n        wn_matrix_sparse = d.tocsr()\n\n        # to dense matrix\n        #dense = pd.DataFrame(wn_matrix_sparse.todense())\n\n\n        # normalize data\n        molecular_matrix = pd.DataFrame(adata_subset.raw.X, columns = adata_subset.var.index, index=adata_subset.obs.index)\n        # clip outliers\n        def clipping (x):\n                clip = x.clip(lower =np.percentile(x,0.01), upper=np.percentile(x,99.99)).tolist()\n                return clip\n        gmm_data = molecular_matrix.apply(clipping)\n        # log trasform\n        normalised_data = np.log1p(gmm_data)\n        # scale data\n        #transformer = RobustScaler().fit(n_log)\n        #normalised_data = pd.DataFrame(transformer.transform(n_log), columns = adata_subset.var.index, index=adata_subset.obs.index)\n        #normalised_data = n_log\n\n        #### Calculation of spatial lag\n\n        # a) use only morphological features?\n        if morphological_features is not None:\n            if isinstance(morphological_features, str):\n                morphological_features = [morphological_features]\n            morph_f = adata_subset.obs[morphological_features]\n\n            transformer = RobustScaler().fit(morph_f)\n            morph_f = pd.DataFrame(transformer.transform(morph_f), columns = morph_f.columns, index=morph_f.index)\n\n            if use_only_morphological_features is True:\n                spatial_lag = pd.DataFrame(wn_matrix_sparse * morph_f, columns = morph_f.columns, index=morph_f.index)\n\n\n        # b) use morphological features and molecular features?\n        if morphological_features is not None and use_only_morphological_features is False:\n            if use_raw==True:\n                combined_matrix = pd.concat([normalised_data, morph_f], axis=1)\n                spatial_lag = pd.DataFrame(wn_matrix_sparse * combined_matrix, columns = combined_matrix.columns, index=combined_matrix.index)     \n            else:\n                molecular_matrix = pd.DataFrame(adata_subset.X, columns = adata_subset.var.index, index=adata_subset.obs.index)\n                combined_matrix = pd.concat([molecular_matrix, morph_f], axis=1)\n                spatial_lag = pd.DataFrame(wn_matrix_sparse * combined_matrix, columns = combined_matrix.columns, index=combined_matrix.index) \n\n        # c) use only molecular features\n        if morphological_features is None:\n            if use_raw==True:\n                spatial_lag = pd.DataFrame(wn_matrix_sparse * normalised_data, columns = adata_subset.var.index, index=adata_subset.obs.index)\n            else:\n                spatial_lag = pd.DataFrame(wn_matrix_sparse * adata_subset.X, columns = adata_subset.var.index, index=adata_subset.obs.index)\n\n        # return value\n        return spatial_lag\n\n\n    # check if the user wants to reuse the spatial lag vector that was previously calculated\n    if reuse_similarity_matrix is None:\n        # Subset a particular image if needed\n        if subset is not None:\n            if isinstance(subset, str):\n                subset = [subset]\n            adata_list = [adata[adata.obs[imageid].isin(subset)]]\n        else:\n            adata_list = [adata[adata.obs[imageid] == i] for i in adata.obs[imageid].unique()]\n\n\n        # Apply function to all images and create a master dataframe\n        # Create lamda function \n        r_spatial_expression_internal = lambda x: spatial_expression_internal(adata_subset=x, \n                                                                    x_coordinate=x_coordinate, \n                                                                    y_coordinate=y_coordinate, \n                                                                    method=method, radius=radius, \n                                                                    knn=knn, imageid=imageid, \n                                                                    use_raw=use_raw,\n                                                                    morphological_features=morphological_features, \n                                                                    use_only_morphological_features=use_only_morphological_features) \n\n        all_data = list(map(r_spatial_expression_internal, adata_list)) # Apply function \n\n        # Merge all the results into a single dataframe    \n        result = []\n        for i in range(len(all_data)):\n            result.append(all_data[i])\n        result = pd.concat(result, join='outer')  \n\n        # save the results in adata object\n        adata.uns[label] = result\n    else:\n        result = adata.uns[reuse_similarity_matrix]\n\n\n    ### Identify the ROI's of interest and then correlate it with all spatial lag\n\n    # calculate the distance between queri ROI and all neighbourhoods\n    # figure out the roi's that need to be processed\n    if ROI_subset is None:\n        ROI_subset = list(adata.obs[ROI_column].unique())\n        ROI_subset = [ x for x in ROI_subset if x != 'Other' ]\n    else:\n        if isinstance(ROI_subset, str):\n            ROI_subset = [ROI_subset]\n\n\n    # Figure out all the cells that fall within the user defined ROI's\n    query_neigh = adata[adata.obs[ROI_column].isin(ROI_subset)].obs[[ROI_column]]\n\n    #result = spatial_lag\n    #np.max(all_roi_scores)\n    #np.min(all_roi_scores)\n\n    # for each ROI calculate the median spatial lag\n    median_spatial_lag = pd.merge(result.loc[query_neigh.index], query_neigh, left_index=True, right_index=True, how='outer')\n    median_spatial_lag = median_spatial_lag.groupby(ROI_column).median()\n\n    # apply the distance function to each defined ROI's\n    spatial_lag_array = np.array(result)\n    median_spatial_lag_array = np.array(median_spatial_lag)\n\n    # func\n    #all_roi_scores = np.array([distance.euclidean(median_spatial_lag_array[0],x) for x in spatial_lag_array])\n    #all_roi_scores = pd.DataFrame(all_roi_scores, columns=median_spatial_lag.index, index = result.index)\n    all_roi_scores = np.array([euclidian_score(x) for x in median_spatial_lag_array])\n    #all_roi_scores = median_spatial_lag.apply(euclidian_score, axis = 1) when spatial lag is a df\n    # convert that to a df for returning\n    all_roi_scores = pd.DataFrame(all_roi_scores, index=median_spatial_lag.index, columns = result.index).T\n\n    # rescale the scores\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    s = scaler.fit_transform(all_roi_scores)\n    all_roi_scores = pd.DataFrame(s, columns = all_roi_scores.columns, index= all_roi_scores.index)\n\n    ### Threshold the results to identify neighbourhoods that are similar to the \n    all_roi_scores_threshold = pd.DataFrame(np.where(all_roi_scores &gt;= similarity_threshold, 'similar_to_ROI', 'other'), index = all_roi_scores.index, columns = all_roi_scores.columns)\n\n    # rename columns of the \n    A = list(all_roi_scores.columns)\n    column_names = [label + \"_\" + str(s) for s in A]\n    all_roi_scores_threshold.columns = column_names\n\n    # delete the result columns from adata if they already exist\n    adata_obs = adata.obs\n    if any(x in adata_obs.columns for x in column_names):\n        adata_obs = adata_obs.drop(column_names, axis = 1)\n\n    # Merge the results with adata.obs\n    final_results = pd.merge(adata_obs, all_roi_scores_threshold, left_index=True, right_index=True, how='outer')\n\n    # Reindex the cells\n    final_results = final_results.replace(np.nan, 'not_computed')\n    final_results = final_results.reindex(adata.obs.index)\n\n    # return the data\n    adata.obs = final_results\n\n    # Save data if requested\n    if output_dir is not None:\n        output_dir = pathlib.Path(output_dir)\n        output_dir.mkdir(exist_ok=True, parents=True)\n        adata.write(output_dir / imid)\n    else:    \n        # Return data\n        return adata\n</code></pre>"},{"location":"Functions/tl/umap/","title":"umap","text":"<p>Short Description</p> <p><code>sm.tl.umap</code>: The function allows users to perform dimensionality reduction using UMAP </p>"},{"location":"Functions/tl/umap/#scimap.tools._umap--function","title":"Function","text":""},{"location":"Functions/tl/umap/#scimap.tools._umap.umap","title":"<code>umap(adata, use_layer=None, use_raw=False, log=False, n_neighbors=15, n_components=2, metric='euclidean', min_dist=0.1, random_state=0, label='umap', **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData Object  </p> required <code>use_layer</code> <p>string, optional Pass name of any <code>Layer</code> in AnnData. The default is <code>None</code> and <code>adata.X</code> is used.</p> <code>None</code> <code>use_raw</code> <p>bool, optional If set to <code>True</code>, values in <code>adata.raw.X</code> will be used. The default is False.</p> <code>False</code> <code>log</code> <p>bool, optional If set to <code>True</code>, the data will natural log transformed using <code>np.log1p()</code>. The default is False.</p> <code>False</code> <code>n_neighbors</code> <p>int, optional The size of local neighborhood (in terms of number of neighboring sample points)  used for manifold approximation. Larger values result in more global views of the manifold,  while smaller values result in more local data being preserved. In general  values should be in the range 2 to 100. The default is 15.</p> <code>15</code> <code>n_components</code> <p>int, optional The dimension of the space to embed into. This defaults to 2 to provide easy visualization,  but can reasonably be set to any integer value in the range 2 to 100. The default is 2.</p> <code>2</code> <code>metric</code> <p>TYPE, optional The metric to use to compute distances in high dimensional space.  Check <code>https://umap-learn.readthedocs.io/en/latest/api.html</code> for all available  options. The default is 'euclidean'.</p> <code>'euclidean'</code> <code>min_dist</code> <p>float, optional The effective minimum distance between embedded points. Smaller values will  result in a more clustered/clumped embedding where nearby points on the manifold  are drawn closer together, while larger values will result on a more even  dispersal of points. The value should be set relative to the spread value,  which determines the scale at which embedded points will be spread out. The default is 0.1.</p> <code>0.1</code> <code>random_state</code> <p>int, optional If int, random_state is the seed used by the random number generator;  If RandomState instance, random_state is the random number generator;  If None, the random number generator is the RandomState instance used by np.random. The default is 0.</p> <code>0</code> <code>label</code> <p>string, optional Key used to save the embeddings.  Check <code>adata.obsm[label]</code> for results. The default is 'umap'.</p> <code>'umap'</code> <code>**kwargs</code> <p>Other <code>umap</code> parameters. Check <code>https://umap-learn.readthedocs.io/en/latest/api.html</code> </p> <code>{}</code> <p>Returns:</p> Name Type Description <code>adata</code> <p>Modified AnnData object Embedding stored in <code>adata.obsm[label]</code>.</p> <pre><code># Run UMAP\nadata = sm.tl.umap(adata)\n\n# plot results\nsm.pl.umap(adata)\n</code></pre> Source code in <code>scimap/tools/_umap.py</code> <pre><code>def umap (adata, use_layer=None, use_raw=False, log=False,\n          n_neighbors=15, n_components=2, metric='euclidean',min_dist=0.1, random_state=0, \n          label='umap', **kwargs):\n\"\"\"\nParameters:\n\n    adata : AnnData Object  \n\n    use_layer : string, optional  \n        Pass name of any `Layer` in AnnData. The default is `None` and `adata.X` is used.\n\n    use_raw : bool, optional  \n        If set to `True`, values in `adata.raw.X` will be used. The default is False.\n\n    log : bool, optional  \n        If set to `True`, the data will natural log transformed using `np.log1p()`. The default is False.\n\n    n_neighbors : int, optional  \n        The size of local neighborhood (in terms of number of neighboring sample points) \n        used for manifold approximation. Larger values result in more global views of the manifold, \n        while smaller values result in more local data being preserved. In general \n        values should be in the range 2 to 100. The default is 15.\n\n    n_components : int, optional  \n        The dimension of the space to embed into. This defaults to 2 to provide easy visualization, \n        but can reasonably be set to any integer value in the range 2 to 100. The default is 2.\n\n    metric : TYPE, optional  \n        The metric to use to compute distances in high dimensional space. \n        Check `https://umap-learn.readthedocs.io/en/latest/api.html` for all available \n        options. The default is 'euclidean'.\n\n    min_dist : float, optional  \n        The effective minimum distance between embedded points. Smaller values will \n        result in a more clustered/clumped embedding where nearby points on the manifold \n        are drawn closer together, while larger values will result on a more even \n        dispersal of points. The value should be set relative to the spread value, \n        which determines the scale at which embedded points will be spread out. The default is 0.1.\n\n    random_state : int, optional  \n        If int, random_state is the seed used by the random number generator; \n        If RandomState instance, random_state is the random number generator; \n        If None, the random number generator is the RandomState instance used by np.random. The default is 0.\n\n    label : string, optional  \n        Key used to save the embeddings. \n        Check `adata.obsm[label]` for results. The default is 'umap'.\n\n    **kwargs : Other `umap` parameters. Check `https://umap-learn.readthedocs.io/en/latest/api.html`  \n\nReturns:\n\n    adata : Modified AnnData object\n        Embedding stored in `adata.obsm[label]`.\n\nExample:\n```python\n# Run UMAP\nadata = sm.tl.umap(adata)\n\n# plot results\nsm.pl.umap(adata)\n```\n\n    \"\"\"\n\n    # adata_layer=None;use_raw=False;log=False;n_neighbors=15;n_components=2;metric='euclidean';min_dist=0.1;\n    # random_state=0;\n    # load data\n    if use_layer is not None:\n        data = adata.layers[use_layer]\n    elif use_raw is True:\n        data = adata.raw.X\n    else:\n        data = adata.X\n\n    # log the data if user requests\n    if log is True:\n        data = np.log1p(data)\n\n\n    # embedding\n    embedding = um.UMAP(n_neighbors=n_neighbors,\n                          n_components=n_components,\n                          metric=metric,\n                          min_dist=min_dist,\n                          random_state=random_state).fit_transform(data)\n\n    # plot\n    #plt.scatter(embedding[:, 0], embedding[:, 1], s=5)\n\n    # return data\n    adata.obsm[label] = embedding\n    return adata\n</code></pre>"},{"location":"tutorials/1-scimap-tutorial-getting-started/","title":"Getting Started with Scimap","text":"<pre><code>#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Fri Jun 26 23:11:32 2020\n@author: Ajit Johnson Nirmal\nScimap Getting Started tutorial\n\"\"\"\n</code></pre> <pre><code>'\\nCreated on Fri Jun 26 23:11:32 2020\\n@author: Ajit Johnson Nirmal\\nScimap Getting Started tutorial\\n'\n</code></pre> <pre><code># Before you start make sure you have installed the following packages\n# pip install scimap\n# pip install scanpy\n# pip install leidenalg\n# pip install PyQt5\n</code></pre>"},{"location":"tutorials/1-scimap-tutorial-getting-started/#tutorial-material","title":"Tutorial material","text":"<p>You can download the material for this tutorial from the following link: The presentation files are available here:</p>"},{"location":"tutorials/1-scimap-tutorial-getting-started/#tutorial-video","title":"Tutorial video","text":"<pre><code>from IPython.display import HTML\nHTML('&lt;iframe width=\"450\" height=\"250\" src=\"https://www.youtube.com/embed/knh5elRksUk\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen&gt;&lt;/iframe&gt;')\n</code></pre> <pre><code># Load necessary libraries\nimport sys\nimport os\nimport anndata as ad\nimport pandas as pd\nimport scanpy as sc\nimport seaborn as sns; sns.set(color_codes=True)\n\n# Import Scimap\nimport scimap as sm\n</code></pre> <pre><code># Set the working directory\nos.chdir (\"/Users/aj/Desktop/scimap_tutorial/\")\n</code></pre>"},{"location":"tutorials/1-scimap-tutorial-getting-started/#load-data-using-anndata","title":"Load data using AnnData","text":"<pre><code># Load data\ndata = pd.read_csv ('counts_table.csv') # Counts matrix\nmeta = pd.read_csv ('meta_data.csv') # Meta data like x and y coordinates \n\n# combine the data and metadata file to generate the AnnData object\nadata = ad.AnnData (data)\nadata.obs = meta\n</code></pre> <p>Print adata to check for it's content</p> <pre><code>adata\n</code></pre> <pre><code>AnnData object with n_obs \u00d7 n_vars = 4825 \u00d7 48\nobs: 'X_centroid', 'Y_centroid', 'Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity', 'Solidity', 'Extent', 'Orientation'\n</code></pre> <pre><code>adata.obs # prints the meta data\n</code></pre> X_centroid Y_centroid Area MajorAxisLength MinorAxisLength Eccentricity Solidity Extent Orientation 0 511.555556 9.846154 117 14.532270 10.273628 0.707261 0.959016 0.750000 -0.695369 1 579.330097 9.398058 103 16.056286 8.776323 0.837396 0.903509 0.613095 1.115707 2 630.958333 12.883333 120 15.222005 10.310756 0.735653 0.975610 0.681818 0.151616 3 745.194631 16.275168 149 14.380200 13.404759 0.362027 0.967532 0.662222 -0.270451 4 657.173653 18.035928 167 17.675831 12.110106 0.728428 0.943503 0.695833 -0.810890 ... ... ... ... ... ... ... ... ... ... 4820 559.597403 1091.577922 154 18.150307 11.683288 0.765281 0.900585 0.570370 -0.342315 4821 619.983871 1092.959677 248 21.734414 15.565820 0.697912 0.864111 0.551111 1.432242 4822 583.317073 1093.573171 82 12.060039 9.539789 0.611784 0.964706 0.630769 0.203023 4823 607.064394 1101.583333 264 22.549494 15.905321 0.708858 0.882943 0.661654 0.691838 4824 641.592486 1100.132948 346 23.149806 19.375564 0.547257 0.945355 0.791762 -1.390516 <p>4825 rows \u00d7 9 columns</p> <pre><code>adata.X # prints the counts table\n</code></pre> <pre><code>array([[16640.564  ,   719.6325 ,   527.7094 , ...,  1085.735  ,\n218.54701,  3170.47   ],\n[16938.3    ,   686.5534 ,   469.30096, ...,  1075.6407 ,\n164.48544,  3116.767  ],\n[16243.542  ,   819.4167 ,   604.39166, ...,  1164.3917 ,\n227.74167,  3156.1084 ],\n...,\n[28656.256  ,   878.2561 ,   585.3293 , ...,  1233.183  ,\n1243.5488 ,  3194.195  ],\n[22054.818  ,   685.8485 ,   424.85226, ...,  1031.2424 ,\n313.32574,  3038.8105 ],\n[23992.854  ,   850.25146,   529.89886, ...,  1000.5578 ,\n285.98267,  3087.3005 ]], dtype=float32)\n</code></pre> <pre><code>adata.var[0:5] # prints the first 5 channel or marker names\n</code></pre> DNA1 BG1 BG2 BG3 DNA2 <p>You would have noticed that - the data is not in log scale - All the DNA channels are there - The background channels are there If we diretly perform clustering or any other type of analysis, the above mentioned factors may affect the results and so it is recommended to remove them.</p>"},{"location":"tutorials/1-scimap-tutorial-getting-started/#load-data-using-scimaps-helper-function","title":"Load data using scimap's helper function","text":"<p>Use this if the single-cell data was generated using mcmicro pipeline. With this function though many of the above limitations can be imediately addressed. By default it removes DNA channels and you can pass any channel name into <code>drop_markers</code> parameter inorder to not import them.</p> <pre><code>image_path = ['/Users/aj/Desktop/scimap_tutorial/mcmicro_output.csv']\nadata = sm.pp.mcmicro_to_scimap (image_path, drop_markers = [\"PERK\", \"NOS2\",\"BG1\",\"BG2\",\"BG3\",\"ACTIN\"])\n</code></pre> <pre><code>Loading mcmicro_output.csv\n</code></pre> <p>Check adata contents now as we did previously</p> <pre><code>adata\n</code></pre> <pre><code>AnnData object with n_obs \u00d7 n_vars = 4825 \u00d7 30\nobs: 'X_centroid', 'Y_centroid', 'Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity', 'Solidity', 'Extent', 'Orientation', 'imageid'\nuns: 'all_markers'\n</code></pre> <pre><code>adata.X # Will now contain log normalized data\n</code></pre> <pre><code>array([[6.3674684, 6.4287267, 7.3826084, ..., 6.990933 , 5.3915663,\n8.061951 ],\n[6.340171 , 6.094227 , 7.339796 , ..., 6.981601 , 5.1088834,\n8.044872 ],\n[6.503502 , 6.3549495, 7.4734573, ..., 7.0608125, 5.4325933,\n8.057412 ],\n...,\n[6.5583014, 6.660794 , 7.4199724, ..., 7.1181645, 7.1265283,\n8.069404 ],\n[6.3370404, 6.281594 , 7.2397914, ..., 6.939489 , 5.7504296,\n8.01955  ],\n[6.3805585, 6.180567 , 7.2547846, ..., 6.909312 , 5.659422 ,\n8.035377 ]], dtype=float32)\n</code></pre> <pre><code>adata.raw.X # contains the raw data\n</code></pre> <pre><code>array([[ 581.5812 ,  618.38464, 1606.7778 , ..., 1085.735  ,  218.54701,\n3170.47   ],\n[ 565.8932 ,  442.29126, 1539.3981 , ..., 1075.6407 ,  164.48544,\n3116.767  ],\n[ 666.475  ,  574.3333 , 1759.6833 , ..., 1164.3917 ,  227.74167,\n3156.1084 ],\n...,\n[ 704.0732 ,  780.1707 , 1667.9878 , ..., 1233.183  , 1243.5488 ,\n3194.195  ],\n[ 564.1212 ,  533.64014, 1392.803  , ..., 1031.2424 ,  313.32574,\n3038.8105 ],\n[ 589.2572 ,  482.2659 , 1413.8584 , ..., 1000.5578 ,  285.98267,\n3087.3005 ]], dtype=float32)\n</code></pre> <pre><code>adata.obs # prints the meta data\n</code></pre> X_centroid Y_centroid Area MajorAxisLength MinorAxisLength Eccentricity Solidity Extent Orientation imageid mcmicro_output_1 511.555556 9.846154 117 14.532270 10.273628 0.707261 0.959016 0.750000 -0.695369 mcmicro_output mcmicro_output_2 579.330097 9.398058 103 16.056286 8.776323 0.837396 0.903509 0.613095 1.115707 mcmicro_output mcmicro_output_3 630.958333 12.883333 120 15.222005 10.310756 0.735653 0.975610 0.681818 0.151616 mcmicro_output mcmicro_output_4 745.194631 16.275168 149 14.380200 13.404759 0.362027 0.967532 0.662222 -0.270451 mcmicro_output mcmicro_output_5 657.173653 18.035928 167 17.675831 12.110106 0.728428 0.943503 0.695833 -0.810890 mcmicro_output ... ... ... ... ... ... ... ... ... ... ... mcmicro_output_4821 559.597403 1091.577922 154 18.150307 11.683288 0.765281 0.900585 0.570370 -0.342315 mcmicro_output mcmicro_output_4822 619.983871 1092.959677 248 21.734414 15.565820 0.697912 0.864111 0.551111 1.432242 mcmicro_output mcmicro_output_4823 583.317073 1093.573171 82 12.060039 9.539789 0.611784 0.964706 0.630769 0.203023 mcmicro_output mcmicro_output_4824 607.064394 1101.583333 264 22.549494 15.905321 0.708858 0.882943 0.661654 0.691838 mcmicro_output mcmicro_output_4825 641.592486 1100.132948 346 23.149806 19.375564 0.547257 0.945355 0.791762 -1.390516 mcmicro_output <p>4825 rows \u00d7 10 columns</p>"},{"location":"tutorials/1-scimap-tutorial-getting-started/#we-can-use-scanpy-package-to-explore-the-data","title":"We can use scanpy package to explore the data","text":"<pre><code>sc.pl.highest_expr_genes(adata, n_top=20, ) # Most expressing proteins\n</code></pre> <pre><code>sc.tl.pca(adata, svd_solver='arpack') # peform PCA\nsc.pl.pca(adata, color='KI67') # scatter plot in the PCA coordinates\n</code></pre> <pre><code>sc.pl.pca_variance_ratio(adata) # PCs to the total variance in the data\n</code></pre> <pre><code># Save the results\nadata.write('tutorial_data.h5ad')\n</code></pre> <p>This concludes the <code>getting started</code> tutorial, continue with the <code>phenotyping</code> tutorial.</p>"},{"location":"tutorials/2-scimap-tutorial-cell-phenotyping/","title":"Cell-Phenotyping using Scimap","text":"<pre><code>#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Fri Jun 28 18:10:06 2020\n@author: Ajit Johnson Nirmal\nScimap Cell Phenotyping Tutorial\n\"\"\"\n</code></pre> <pre><code>'\\nCreated on Fri Jun 28 18:10:06 2020\\n@author: Ajit Johnson Nirmal\\nScimap Cell Phenotyping Tutorial\\n'\n</code></pre>"},{"location":"tutorials/2-scimap-tutorial-cell-phenotyping/#tutorial-material","title":"Tutorial material","text":"<p>You can download the material for this tutorial from the following link: The presentation files are available here:</p>"},{"location":"tutorials/2-scimap-tutorial-cell-phenotyping/#tutorial-video","title":"Tutorial video","text":"<pre><code>from IPython.display import HTML\nHTML('&lt;iframe width=\"450\" height=\"250\" src=\"https://www.youtube.com/embed/knh5elRksUk\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen&gt;&lt;/iframe&gt;')\n</code></pre> <pre><code># Load necessary libraries\nimport sys\nimport os\nimport anndata as ad\nimport pandas as pd\nimport scanpy as sc\nimport seaborn as sns; sns.set(color_codes=True)\n\n# Import Scimap\nimport scimap as sm\n</code></pre> <pre><code># Set the working directory\nos.chdir (\"/Users/aj/Desktop/scimap_tutorial/\")\n</code></pre> <pre><code># Load data\nadata = ad.read('tutorial_data.h5ad')\n</code></pre>"},{"location":"tutorials/2-scimap-tutorial-cell-phenotyping/#clustering-and-data-exploration","title":"Clustering and data exploration","text":"<p>You could use clustering and marker expression analysis within clusters to assign cell types similar to what is carried out with single-cell sequencing data.</p> <pre><code>sc.pp.neighbors(adata, n_neighbors=30, n_pcs=10) # Computing the neighborhood graph\n</code></pre> <pre><code>sc.tl.umap(adata) # Build a UMAP to visualize the neighbourhood graph\n</code></pre> <pre><code>sc.pl.umap(adata, color=['CD3D', 'CD20', 'CD163'], cmap= 'vlag', use_raw=False, s=30) # Plot the UMAP\n</code></pre> <p></p> <p>We can already begin to spot issues with carrying out this mode of phenotyping approach. As you can see there is an area of co-expression of CD3D and CD20, which is likely because of segmentation errors. Additionally the boundaries are not distinct between cell-types and it is highly likely that errors will be introduced due to this reason. </p> <pre><code>sc.tl.leiden(adata, resolution = 1) # Clustering the neighborhood graph\n</code></pre> <pre><code>sc.pl.umap(adata, color=['leiden', 'CD3D', 'CD20'],cmap= 'vlag', use_raw=False) # View the clustering\n</code></pre> <p></p>"},{"location":"tutorials/2-scimap-tutorial-cell-phenotyping/#finding-marker-genes","title":"Finding marker genes","text":"<pre><code>sc.tl.rank_genes_groups(adata, 'leiden', method='t-test')\nsc.pl.rank_genes_groups(adata, n_genes=10, sharey=False, fontsize=16)\n</code></pre> <p>From the above plots, it is likely that clusters 1, 2 and 7 could be combined to form a T cell cluster. However, as mentioned earlier the boundaries are not clear and it only get increasingly complex as one would want to perform deeper phenotyping such as CD4 helper T cells, CD8 T cells, regulatory T cells and so on. </p> <p>Additionally, marker analsyis suggests that CD30 is most expressed in cluster 8. If you look at the actual image, you will realize that CD30 is not expressed by any cell in this image and the analysis is picking up high background fluorescence. </p>"},{"location":"tutorials/2-scimap-tutorial-cell-phenotyping/#probability-distribution-based-phenotyping","title":"Probability distribution based phenotyping","text":"<p>This approach is more labor intensive, however is significantly more sensitive and much more scalable than clustering based approaches. Takes less than 5 mins to run over a million cells once the gates are identified.</p>"},{"location":"tutorials/2-scimap-tutorial-cell-phenotyping/#in-order-to-run-the-method-you-need-2-things","title":"In order to run the method, you need 2 things","text":"<ul> <li>a gating workflow strategy <code>.csv file</code></li> <li>manual gates <code>.csv file</code>. If manual gates are not provided, the algorithm will attempt to rescale the data by fitting two gaussians on the data. However, it is adviced to perform manual gating as I have found it to be more sensitive.</li> </ul> <p>The algorithm involves three steps: 1. Identify the gates using <code>sm.pl.gate_finder</code> 2. Rescale the data based on the identified gates using <code>sm.pp.rescale</code> 3. Run the phenotyping algorithm on the rescaled data using <code>sm.tl.phenotype</code></p>"},{"location":"tutorials/2-scimap-tutorial-cell-phenotyping/#define-manual-gates-to-rescale-data-before-running-the-phenotyping-algorithm","title":"Define manual gates to rescale data before running the phenotyping algorithm","text":"<p>Instantiating the Qt GUI can take a few seconds and if you create the Viewer before it is finished, the kernel will die and the viewer will not launch. For this reason the %gui qt magic command should always be run in a separate cell from creating the viewer</p> <pre><code>%gui qt\n</code></pre>"},{"location":"tutorials/2-scimap-tutorial-cell-phenotyping/#step-1-identify-the-gates-using-smplgate_finder","title":"Step 1: Identify the gates using <code>sm.pl.gate_finder</code>","text":"<pre><code>image_path = '/Users/aj/Desktop/scimap_tutorial/reactive_core.tif'\nmarker_of_interest = 'CD45'\n</code></pre> <pre><code>sm.pl.gate_finder (image_path, adata, marker_of_interest, \n                   from_gate = 5, to_gate = 9, increment = 0.1, \n                   markers=['ASMA','DNA11', 'CD20', 'CD3D'], point_size=6)\n</code></pre>"},{"location":"tutorials/2-scimap-tutorial-cell-phenotyping/#step-2-rescale-the-data-based-on-the-identified-gates-using-smpprescale","title":"Step 2: Rescale the data based on the identified gates using <code>sm.pp.rescale</code>","text":"<p>Note: Below we are passing a <code>manual_gates.csv</code> into the <code>gate</code> parameter. This contatins gates that were visually determined using the <code>sm.pl.gate_finder</code> function. For the markers included in the <code>manual_gates.csv</code> file,  the function will scale the data such that cells with expression greater than the gate  will be considered as positive for that marker and cells with expression below the gate is considered negative. </p> <p>For markers that are not included in the <code>manual_gates.csv</code> file, the function will automatically try to determine a gate by running a gaussian mixture model algorithm on the data. </p>"},{"location":"tutorials/2-scimap-tutorial-cell-phenotyping/#note-for-v0220","title":"Note (for &gt;=v.0.22.0)","text":"<p>Please note that passing manual gates for multiple images has been introduced in <code>scimap &gt;=v.0.22.0</code></p> <pre><code># Load the manual gates and rescale the data based on the gates\nmanual_gate = pd.read_csv('manual_gates.csv')\nadata = sm.pp.rescale (adata, gate=manual_gate)\n</code></pre> <pre><code>Scaling Image [mcmicro_output]\nCategories (1, object): [mcmicro_output]\nFinding the optimal gate for CD10\nFinding the optimal gate for CD2\nFinding the optimal gate for CD30\nFinding the optimal gate for CD43\nFinding the optimal gate for CD5\nFinding the optimal gate for CD57\nFinding the optimal gate for CD7\nFinding the optimal gate for KI67\nFinding the optimal gate for MHCI\nFinding the optimal gate for PDL1\nFinding the optimal gate for PS6\nFinding the optimal gate for PSTAT3\nScaling ASMA\nScaling CD163\nScaling CD206\nScaling CD68\nScaling CD20\nScaling CD21\nScaling CD3D\nScaling CD45\nScaling CD56\nScaling CD8A\nScaling FOXP3\nScaling CD11B\nScaling CD11C\nScaling CD15\nScaling CD4\nScaling PD1\nScaling HLADR\nScaling CD25\n</code></pre> <pre><code># View the scaled data (note that the log data is replaced with scaled data)\n# If you ever want the log data back you will need to run-  np.log1p(adata.raw.X)\nadata.X \n</code></pre> <pre><code>array([[0.17841106, 0.45723783, 0.49234127, ..., 0.15973007, 0.1665647 ,\n        0.20024123],\n       [0.155838  , 0.21377199, 0.34924023, ..., 0.1522421 , 0.0885678 ,\n        0.15338667],\n       [0.29090098, 0.37456273, 0.50752728, ..., 0.21580293, 0.17788475,\n        0.18778977],\n       ...,\n       [0.33621626, 0.70161347, 0.70359459, ..., 0.26182348, 0.60810172,\n        0.22068843],\n       [0.15324935, 0.51044092, 0.60877724, ..., 0.11845023, 0.26558105,\n        0.08391592],\n       [0.18923565, 0.431478  , 0.58019522, ..., 0.09423545, 0.24047052,\n        0.12733514]])\n</code></pre>"},{"location":"tutorials/2-scimap-tutorial-cell-phenotyping/#step-3-run-the-phenotyping-algorithm-on-the-rescaled-data-using-smtlphenotype","title":"Step 3: Run the phenotyping algorithm on the rescaled data using <code>sm.tl.phenotype</code>","text":"<pre><code># Load the gating workflow\nphenotype = pd.read_csv('phenotype_workflow.csv')\nadata = sm.tl.phenotype_cells (adata, phenotype=phenotype, label=\"phenotype\") \n</code></pre> <pre><code>Phenotyping Other Immune cells\nPhenotyping ASMA+ cells\n-- Subsetting Other Immune cells\nPhenotyping T cells\nPhenotyping B cells\nPhenotyping Myeloid Lineage\nPhenotyping NK cells\nPhenotyping Granulocytes\n-- Subsetting Myeloid Lineage\nPhenotyping T cells\nPhenotyping B cells\nPhenotyping NK cells\nPhenotyping Granulocytes\nPhenotyping CD68+ Macrophages\nPhenotyping M2 Macrophages\nPhenotyping Myeloid Dendritic cells\nPhenotyping Follicular Dendritic cells\n-- Subsetting T cells\nPhenotyping CD4 T cells\nPhenotyping CD8 T cells\n-- Subsetting CD4 T cells\nPhenotyping Regulatory T cells\nPhenotyping Follicular Helper T cells\n-- Subsetting CD8 T cells\nPhenotyping PD1+ T cells\n-- Subsetting Myeloid Dendritic cells\nPhenotyping CD25+ Dendritic cells\nConsolidating the phenotypes across all groups\n</code></pre> <pre><code># Summary of the phenotyping\nadata.obs['phenotype'].value_counts()\n</code></pre> <pre><code>B cells                       2037\nCD4 T cells                    502\nASMA+ cells                    420\nRegulatory T cells             418\nCD8 T cells                    322\nFollicular Helper T cells      282\nT cells                        146\nUnknown                        140\nOther Immune cells             137\nMyeloid Dendritic cells        124\nFollicular Dendritic cells      87\nMyeloid Lineage                 80\nPD1+ T cells                    63\nM2 Macrophages                  55\nGranulocytes                     8\nNK cells                         3\nCD25+ Dendritic cells            1\nName: phenotype, dtype: int64\n</code></pre> <p>It is likely that <code>CD25+ Dendritic cells, NK cells &amp; Granulocytes</code> are artifacts. You could set <code>pheno_threshold_abs= 10</code> to move these cells into <code>unknown</code> category.</p> <p>Once the phenotyping is performed, it is adviced to overlay the phenotypes on the image and check if they are correct. If not, alter the <code>phenotyping workflow</code> file or the <code>manual gate</code> to account for the errors.</p> <pre><code># View phenotypes\nsm.pl.image_viewer (image_path, adata, overlay = 'phenotype', point_color='white', point_size=6)\n</code></pre> <pre><code># View Leiden clustering\nsm.pl.image_viewer (image_path, adata, overlay = 'leiden', point_color='white', point_size=6)\n</code></pre>"},{"location":"tutorials/2-scimap-tutorial-cell-phenotyping/#heatmap-and-umap-of-the-probability-based-phenotyping","title":"Heatmap and UMAP of the probability based phenotyping","text":"<pre><code>sc.tl.dendrogram(adata, groupby='phenotype')\n</code></pre> <pre><code>sc.pl.matrixplot(adata, var_names= adata.var.index, groupby='phenotype', dendrogram=True, use_raw=False, cmap=\"vlag\", standard_scale='var')\n</code></pre> <pre><code>GridSpec(2, 3, height_ratios=[0, 10.5], width_ratios=[9.6, 0.8, 0.2])\n</code></pre> <pre><code>sc.pl.umap(adata, color=['leiden', 'phenotype']) # View the clustering\n</code></pre> <pre><code>sns.set(rc={'figure.figsize':(11.7,8.27)})\nsc.pl.umap(adata, color=['phenotype'],legend_loc='on data', title='', frameon=False, s = 100) # View the clustering\n</code></pre> <pre><code>sc.pl.umap(adata, color=['CD3D', 'PD1', 'CD20'],cmap= 'vlag', use_raw=False, frameon=False, s = 100) # View the clustering\n</code></pre> <p>As it can be seen from above 3 UMAP's it would have been very difficult to find the Follicular helper T cells by a pure clustering approach. Also, the B cells as can be seen above does not from a nice seperate cluster. These among other illustrate the importance of using the probability based algorithm for deep phenotyping.</p> <pre><code># Confirm Follicular helper T cells in the image\nsm.pl.image_viewer (image_path, adata, \n                    overlay = 'phenotype', overlay_category=['Follicular Helper T cells'], \n                    markers = ['CD3D','CD20','PD1','CD8A','CD4','DNA11'],\n                    point_color='white', point_size=6)\n</code></pre> <pre><code># Save the results\nadata.write('tutorial_data.h5ad')\n</code></pre> <p>This concludes this tutorial</p>"},{"location":"tutorials/3-Cell_Type_calling_and_adding_ROIs/","title":"Cell-Phenotyping and adding ROIs","text":"<pre><code>\"\"\"\nCreated on Mon May 16 19:00:32 2022\n@author: Ajit Johnson Nirmal\nSCIMAP tutorial May 2022\n\"\"\"\n</code></pre> <pre><code># load packages\nimport scimap as sm\nimport scanpy as sc\nimport pandas as pd\n</code></pre>"},{"location":"tutorials/3-Cell_Type_calling_and_adding_ROIs/#tutorial-material","title":"Tutorial material","text":"<p>You can download the material for this tutorial from the following link: The jupyter notebook is available here:</p> <pre><code>common_path = \"/Users/aj/Dropbox (Partners HealthCare)/conferences/scimap_tutorial/may_2022_tutorial/\"\n#common_path = \"C:/Users/ajn16/Dropbox (Partners HealthCare)/conferences/scimap_tutorial/may_2022_tutorial/\"\n</code></pre> <pre><code># load data\nadata = sm.pp.mcmicro_to_scimap (image_path= str(common_path) + 'exemplar_001/quantification/unmicst-exemplar-001_cell.csv')\n</code></pre> <pre><code>Loading unmicst-exemplar-001_cell.csv\n</code></pre> <pre><code>adata\n</code></pre> <pre><code>AnnData object with n_obs \u00d7 n_vars = 11170 \u00d7 9\nobs: 'X_centroid', 'Y_centroid', 'Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity', 'Solidity', 'Extent', 'Orientation', 'imageid'\nuns: 'all_markers'\n</code></pre> <pre><code># Markers in dataset\nadata.var.index\n</code></pre> <pre><code>Index(['ELANE', 'CD57', 'CD45', 'CD11B', 'SMA', 'CD16', 'ECAD', 'FOXP3',\n'NCAM'],\ndtype='object')\n</code></pre>"},{"location":"tutorials/3-Cell_Type_calling_and_adding_ROIs/#manually-gate-the-data","title":"manually gate the data","text":"<pre><code># manually gate the data\nimage_path = str(common_path) + 'exemplar_001/registration/exemplar-001.ome.tif'\n</code></pre> <pre><code>marker_of_interest = 'ECAD'\n</code></pre> <pre><code>sm.pl.gate_finder (image_path, adata, marker_of_interest, \n                   from_gate = 5, to_gate = 9, increment = 0.1, \n                   point_size=10)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/3-Cell_Type_calling_and_adding_ROIs/#rescale-the-data-based-on-the-manual-gates","title":"rescale the data based on the manual gates","text":"<pre><code>manual_gate = pd.read_csv(str(common_path) + 'manual_gates.csv')\n</code></pre> <pre><code>manual_gate\n</code></pre> markers gate 0 ELANE 7.9 1 CD57 8.1 2 CD45 6.3 3 CD11B 7.2 4 SMA 7.6 5 CD16 6.8 6 ECAD 7.4 7 FOXP3 7.0 8 NCAM 7.2 <pre><code># rescale the data\nadata = sm.pp.rescale (adata, gate=manual_gate)\n</code></pre> <pre><code>Scaling Image ['unmicst-exemplar-001_cell']\nScaling ELANE\nScaling CD57\nScaling CD45\nScaling CD11B\nScaling SMA\nScaling CD16\nScaling ECAD\nScaling FOXP3\nScaling NCAM\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/3-Cell_Type_calling_and_adding_ROIs/#phenotyping-cells","title":"Phenotyping cells","text":"<pre><code># load the phenotyping workflow\nphenotype = pd.read_csv(str(common_path) + 'phenotype_workflow.csv')\n</code></pre> <pre><code>phenotype.style.format(na_rep='')\n</code></pre> Unnamed: 0 Unnamed: 1 CD57 CD45 CD11B SMA CD16 ECAD FOXP3 0 all Other Immune cells anypos anypos anypos anypos anypos 1 all ASMA+ cells pos 2 all Tumor pos 3 Other Immune cells Myeloid pos 4 Other Immune cells NK cells pos 5 Other Immune cells Neutrophils pos 6 Other Immune cells Treg pos <pre><code># Run the phenotyping algorithm\nadata = sm.tl.phenotype_cells (adata, phenotype=phenotype, label=\"phenotype\") \n</code></pre> <pre><code>Phenotyping Other Immune cells\nPhenotyping ASMA+ cells\nPhenotyping Tumor\n-- Subsetting Other Immune cells\nPhenotyping Myeloid\nPhenotyping NK cells\nPhenotyping Neutrophils\nPhenotyping Treg\nConsolidating the phenotypes across all groups\n</code></pre> <pre><code># Check the number of phenotyped cells\nadata.obs['phenotype'].value_counts()\n</code></pre> <pre><code>Other Immune cells    3707\nTumor                 2499\nUnknown               1782\nMyeloid               1140\nNeutrophils            895\nASMA+ cells            457\nTreg                   364\nNK cells               326\nName: phenotype, dtype: int64\n</code></pre> <pre><code># Visualize cell types\nsm.pl.image_viewer (image_path, adata, overlay = 'phenotype', point_color='white', point_size=10)\n</code></pre> <pre><code># add seg mask\nseg_mask_path = str(common_path) + 'exemplar_001/qc/s3seg/unmicst-exemplar-001/cellOutlines.ome.tif'\nsm.pl.image_viewer (image_path, adata, \n                    seg_mask = seg_mask_path,\n                    overlay = 'phenotype', \n                    point_color='white', \n                    point_size=10)\n</code></pre> <pre><code># Visualize heatmap of cell types\nsc.pl.matrixplot(adata, var_names= adata.var.index, groupby='phenotype', dendrogram=True, use_raw=False, cmap=\"vlag\", standard_scale='var')\n</code></pre> <pre><code>... storing 'imageid' as categorical\n... storing 'phenotype' as categorical\n\n\nWARNING: dendrogram data not found (using key=dendrogram_phenotype). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.\n</code></pre>"},{"location":"tutorials/3-Cell_Type_calling_and_adding_ROIs/#voronoi-plots","title":"Voronoi Plots","text":"<pre><code>sm.pl.voronoi(adata, color_by='phenotype', \n                 voronoi_edge_color = 'black',\n                 voronoi_line_width = 0.3, \n                 voronoi_alpha = 0.8, \n                 size_max=5000,\n                 overlay_points=None, \n                 plot_legend=True, \n                 legend_size=6)\n</code></pre> <pre><code># Map user defined colors\ncolors = {'ASMA+ cells': '#8AC926', \n          'Myeloid': \"#E9D8A6\", \n          'NK cells':  \"#0A9396\",\n          'Neutrophils': \"#CA6702\", \n          'Other Immune cells':'#001219',\n          'Treg': \"#005F73\", \n          'Tumor':  \"#9B2226\",\n          'Unknown': '#BCB8B1'\n    }\n</code></pre> <pre><code>import matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [15, 10]\nsm.pl.voronoi(adata, color_by='phenotype', \n                  colors = colors,\n                 voronoi_edge_color = 'black',\n                 voronoi_line_width = 0.3, \n                 voronoi_alpha = 0.8, \n                 #size_max=5000,\n                 overlay_points=None, \n                 plot_legend=True, \n                 legend_size=6)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/3-Cell_Type_calling_and_adding_ROIs/#adding-roi-to-images","title":"Adding ROI to images","text":"<pre><code>adata = sm.pl.addROI_image(image_path, adata, \n                             subset=None, \n                             imageid='imageid', \n                             overlay=None, overlay_category=None,\n                             markers=None, \n                             channel_names='default', \n                             x_coordinate='X_centroid', y_coordinate='Y_centroid', \n                             seg_mask=None, \n                             overwrite=True, \n                             label='ROI')\n</code></pre> <pre><code>        Opening Napari;\nAdd shape layers (on left) to draw ROI's. \n        Rename the shape layer to give a name to your ROI\n        Multiple shape layers are supported\n        ROI's should not overlap\nClose Napari to save ROI's.\n\nIdentifying cells within selected ROI's\n\n\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ninside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ninside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ninside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ninside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ninside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ninside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n</code></pre> <pre><code># check ROI cell count\nadata.obs['ROI'].value_counts()\n</code></pre> <pre><code>Other        8075\nCD57-high    2115\nCD57-low      980\nName: ROI, dtype: int64\n</code></pre> <pre><code># Add ROI individually\nadata = sm.pl.addROI_image(image_path, adata, \n                     overwrite=True, \n                     label='ROI_individual')\n</code></pre> <pre><code>        Opening Napari;\nAdd shape layers (on left) to draw ROI's. \n        Rename the shape layer to give a name to your ROI\n        Multiple shape layers are supported\n        ROI's should not overlap\nClose Napari to save ROI's.\n\nIdentifying cells within selected ROI's\n\n\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ninside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ninside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ninside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ninside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ninside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ninside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ninside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n</code></pre> <pre><code># check number of cells\nadata.obs['ROI_individual'].value_counts()\n</code></pre> <pre><code>Other          8025\nCD57-high-2     969\nCD57-low-1      710\nCD57-high-1     427\nCD57-low-3      393\nCD57-low-2      293\nCD57-high-3     188\nartifacts       165\nName: ROI_individual, dtype: int64\n</code></pre> <pre><code># Scatter plot to show the differnt ROI's\nimport pandas as pd\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = 'browser'\ndef plotly (adata,phenotype,image_id=None,x='X_centroid',y='Y_centroid',size=2, **kwargs):\n    if image_id is not None:\n        adata = adata[adata.obs['imageid'] == image_id]    \n    data = pd.DataFrame({'x':adata.obs[x], 'y':adata.obs[y],'col': adata.obs[phenotype]})\n    data = data.sort_values(by=['col'])\n    fig = px.scatter(data, x=\"x\", y=\"y\", color=\"col\", **kwargs)\n    fig.update_traces(marker=dict(size=size),selector=dict(mode='markers'),hoverlabel = dict(namelength = -1))\n    fig.update_yaxes(autorange=\"reversed\", tickformat='g')\n    fig.update_xaxes(tickformat='g')\n    fig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)','paper_bgcolor': 'rgba(0, 0, 0, 0)'})\n    return fig\n\nplotly (adata,phenotype='ROI_individual',image_id=None,x='X_centroid',y='Y_centroid',size=10)\n</code></pre> <pre><code># voronoi plot\nsm.pl.voronoi(adata, color_by='ROI_individual', \n                 voronoi_edge_color = 'black',\n                 voronoi_line_width = 0.3, \n                 voronoi_alpha = 0.8, \n                 size_max=5000,\n                 overlay_points=None, \n                 plot_legend=True, \n                 legend_size=6)\n</code></pre> <pre><code>bdata = adata[adata.obs['ROI_individual'] != 'artifacts']\n</code></pre> <pre><code>plotly (bdata,phenotype='ROI_individual',image_id=None,x='X_centroid',y='Y_centroid',size=10)\n</code></pre> <pre><code># save adata\nadata.write(str(common_path) + 'may2022_tutorial.h5ad')\n</code></pre> <pre><code>... storing 'ROI' as categorical\n... storing 'ROI_individual' as categorical\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/4-CellType_Proportion_Exploration/","title":"CellType Proportion Exploration","text":"<pre><code>\"\"\"\nCreated on Mon May 16 19:00:32 2022\n@author: Ajit Johnson Nirmal\nSCIMAP tutorial May 2022\n\"\"\"\n</code></pre> <pre><code># load packages\nimport scimap as sm\nimport scanpy as sc\nimport pandas as pd\nimport anndata as ad\n</code></pre>"},{"location":"tutorials/4-CellType_Proportion_Exploration/#tutorial-material","title":"Tutorial material","text":"<p>You can download the material for this tutorial from the following link: The jupyter notebook is available here:</p> <pre><code>common_path = \"/Users/aj/Dropbox (Partners HealthCare)/conferences/scimap_tutorial/may_2022_tutorial/\"\n#common_path = \"C:/Users/ajn16/Dropbox (Partners HealthCare)/conferences/scimap_tutorial/may_2022_tutorial/\"\n</code></pre> <pre><code># load data\n#adata = sm.pp.mcmicro_to_scimap (image_path= str(common_path) + 'exemplar_001/quantification/unmicst-exemplar-001_cell.csv')\n#manual_gate = pd.read_csv(str(common_path) + 'manual_gates.csv')\n#adata = sm.pp.rescale (adata, gate=manual_gate)\n#phenotype = pd.read_csv(str(common_path) + 'phenotype_workflow.csv')\n#adata = sm.tl.phenotype_cells (adata, phenotype=phenotype, label=\"phenotype\") \n# add user defined ROI's before proceeding\n</code></pre> <pre><code># load saved anndata object\nadata = ad.read(str(common_path) + 'may2022_tutorial.h5ad')\n</code></pre> <pre><code>adata\n</code></pre> <pre><code>AnnData object with n_obs \u00d7 n_vars = 11170 \u00d7 9\nobs: 'X_centroid', 'Y_centroid', 'Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity', 'Solidity', 'Extent', 'Orientation', 'imageid', 'phenotype', 'index_info', 'ROI', 'ROI_individual'\nuns: 'all_markers', 'dendrogram_phenotype'\n</code></pre>"},{"location":"tutorials/4-CellType_Proportion_Exploration/#investigate-cell-type-composition-within-the-rois","title":"Investigate cell-type composition within the ROI's","text":"<pre><code># https://scimap.xyz/All%20Functions/C.%20Plotting/sm.pl.stacked_barplot/\nsm.pl.stacked_barplot (adata,\n                       x_axis='ROI_individual',\n                       y_axis='phenotype',\n                       method='absolute')\n</code></pre> <pre><code># Plot the number of cells normalized to 100% \nsm.pl.stacked_barplot (adata,\n                       x_axis='ROI_individual',\n                       y_axis='phenotype',\n                       method='percent')\n</code></pre> <pre><code># specify the elements to be in the plot\nx_axis_elements = ['CD57-low-1', 'CD57-low-2', 'CD57-low-3', 'CD57-high-2', 'CD57-high-1', 'CD57-high-3']\ny_axis_elements = ['ASMA+ cells', 'Myeloid', 'NK cells', 'Neutrophils', 'Other Immune cells', 'Treg', 'Tumor']\n</code></pre> <pre><code># replot\nsm.pl.stacked_barplot (adata,\n                       x_axis='ROI_individual',\n                       y_axis='phenotype',\n                       method='percent',\n                       subset_xaxis=x_axis_elements,\n                       subset_yaxis=y_axis_elements)\n</code></pre> <pre><code># quiet a number of parameters to play around:\nsm.pl.stacked_barplot (adata, \n                x_axis='ROI_individual', y_axis='phenotype', \n                subset_xaxis=x_axis_elements, subset_yaxis=y_axis_elements, \n                order_xaxis=None, order_yaxis=None, \n                method='percent', plot_tool='plotly', \n                matplotlib_cmap=None, \n                matplotlib_bbox_to_anchor=(1, 1.02), \n                matplotlib_legend_loc=2, \n                return_data=False)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/4-CellType_Proportion_Exploration/#calculate-the-fold-change-in-cell-types-between-the-different-rois","title":"Calculate the fold change in cell types between the different ROI's","text":"<pre><code>adata = sm.tl.foldchange (adata, \n                          from_group=['CD57-low-1', 'CD57-low-2', 'CD57-low-3'], \n                          to_group=None, \n                          imageid='ROI_individual', \n                          phenotype='phenotype',\n                          normalize=True, \n                          subset_phenotype=None, \n                          label='foldchange')\n</code></pre> <pre><code>/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/tools/_foldchange.py:102: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/tools/_foldchange.py:103: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/tools/_foldchange.py:104: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/tools/_foldchange.py:109: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/tools/_foldchange.py:110: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\ncalculating P values\n</code></pre> <pre><code>adata\n</code></pre> <pre><code>AnnData object with n_obs \u00d7 n_vars = 11170 \u00d7 9\nobs: 'X_centroid', 'Y_centroid', 'Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity', 'Solidity', 'Extent', 'Orientation', 'imageid', 'phenotype', 'index_info', 'ROI', 'ROI_individual'\nuns: 'all_markers', 'dendrogram_phenotype', 'foldchange_pval', 'foldchange_fc'\n</code></pre> <pre><code># Heatmap of foldchnage  \nsm.pl.foldchange (adata, label='foldchange', method='heatmap',\n                     p_val=0.05, nonsig_color='grey',\n                     cmap = 'vlag', log=True, center=0, linecolor='black',linewidths=0.7,\n                     vmin=-5, vmax=5, row_cluster=False)\n</code></pre> <pre><code># Parallel_coordinates plot of the foldchanges\nsm.pl.foldchange (adata, label='foldchange', \n                  subset_xaxis = ['ASMA+ cells', 'NK cells', 'Neutrophils', 'Treg', 'Tumor'],\n                log=True, method='parallel_coordinates', invert_axis=True,\n                parallel_coordinates_color=['black','blue','green','red','#000000'],\n                matplotlib_bbox_to_anchor=(1.04,1),\n                matplotlib_legend_loc='upper left',\n                xticks_rotation=90,\n                return_data = False)\n</code></pre> <pre><code># save adata\nadata.write(str(common_path) + 'may2022_tutorial.h5ad')\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/5-Simple_Spatial_Analysis/","title":"Simple Spatial Analysis","text":"<pre><code>\"\"\"\nCreated on Mon May 16 19:00:32 2022\n@author: Ajit Johnson Nirmal\nSCIMAP tutorial May 2022\n\"\"\"\n</code></pre> <pre><code># load packages\nimport scimap as sm\nimport scanpy as sc\nimport pandas as pd\nimport anndata as ad\n</code></pre>"},{"location":"tutorials/5-Simple_Spatial_Analysis/#tutorial-material","title":"Tutorial material","text":"<p>You can download the material for this tutorial from the following link: The jupyter notebook is available here:</p> <pre><code>common_path = \"/Users/aj/Dropbox (Partners HealthCare)/conferences/scimap_tutorial/may_2022_tutorial/\"\n#common_path = \"C:/Users/ajn16/Dropbox (Partners HealthCare)/conferences/scimap_tutorial/may_2022_tutorial/\"\n</code></pre> <pre><code># load data\n#adata = sm.pp.mcmicro_to_scimap (image_path= str(common_path) + 'exemplar_001/quantification/unmicst-exemplar-001_cell.csv')\n#manual_gate = pd.read_csv(str(common_path) + 'manual_gates.csv')\n#adata = sm.pp.rescale (adata, gate=manual_gate)\n#phenotype = pd.read_csv(str(common_path) + 'phenotype_workflow.csv')\n#adata = sm.tl.phenotype_cells (adata, phenotype=phenotype, label=\"phenotype\") \n# add user defined ROI's before proceeding\n</code></pre> <pre><code># load saved anndata object\nadata = ad.read(str(common_path) + 'may2022_tutorial.h5ad')\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/5-Simple_Spatial_Analysis/#calculate-distances-between-cell-types","title":"Calculate distances between cell types","text":"<p><code>sm.tl.spatial_distance</code>: The function allows users to calculate the average shortest between phenotypes or clusters of interest (3D data supported).</p> <pre><code>adata = sm.tl.spatial_distance (adata, \n                               x_coordinate='X_centroid', y_coordinate='Y_centroid', \n                               z_coordinate=None, \n                               phenotype='phenotype', \n                               subset=None, \n                               imageid='imageid', \n                               label='spatial_distance')\n</code></pre> <pre><code>Processing Image: unmicst-exemplar-001_cell\n</code></pre> <pre><code>adata.uns['spatial_distance']\n</code></pre> Other Immune cells Unknown Myeloid Tumor ASMA+ cells Neutrophils Treg NK cells unmicst-exemplar-001_cell_1 0.000000 508.809972 561.874000 547.544519 506.115689 581.323686 570.267087 1248.001853 unmicst-exemplar-001_cell_2 0.000000 25.516388 63.601485 67.024246 27.928445 157.289841 100.258654 816.837582 unmicst-exemplar-001_cell_3 0.000000 15.315383 59.503385 56.590105 34.479892 147.005355 96.374952 817.307871 unmicst-exemplar-001_cell_4 0.000000 28.482334 13.752853 51.500837 46.148651 111.763900 143.243322 746.050742 unmicst-exemplar-001_cell_5 26.357699 0.000000 45.589024 30.234937 58.354288 120.715789 96.739267 824.241184 ... ... ... ... ... ... ... ... ... unmicst-exemplar-001_cell_11166 0.000000 106.320078 70.605640 96.293073 50.637223 91.990689 43.229554 410.740868 unmicst-exemplar-001_cell_11167 0.000000 31.114913 72.531210 118.065360 54.921505 136.323479 30.072174 399.697389 unmicst-exemplar-001_cell_11168 0.000000 50.369768 70.748013 126.968337 36.065610 123.048957 40.094561 409.435592 unmicst-exemplar-001_cell_11169 0.000000 103.275795 64.057762 91.786425 64.741519 93.600860 35.697321 397.194037 unmicst-exemplar-001_cell_11170 10.165511 0.000000 88.288672 113.521913 86.006117 150.562555 23.735243 389.273701 <p>11170 rows \u00d7 8 columns</p> <pre><code># summary heatmap\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [3, 1]\nsm.pl.spatial_distance (adata)\n</code></pre> <p></p> <pre><code># Heatmap without summarizing the individual images\nsm.pl.spatial_distance (adata, heatmap_summarize=False)\n</code></pre> <p></p> <pre><code>sm.pl.spatial_distance (adata, heatmap_summarize=False, imageid='ROI_individual')\n</code></pre> <p></p> <pre><code># Numeric plot of shortest distance of phenotypes \n# from tumor cells\nsm.pl.spatial_distance (adata, method='numeric',distance_from='Tumor')\n</code></pre> <p></p> <pre><code>sm.pl.spatial_distance (adata, method='numeric',distance_from='Tumor', log=True)\n</code></pre> <p></p> <pre><code># plot for each ROI seperately\nsm.pl.spatial_distance (adata, method='numeric',distance_from='Tumor', imageid='ROI')\n</code></pre> <p></p> <pre><code>sm.pl.spatial_distance (adata, method='numeric',distance_from='Tumor', imageid='ROI', log=True)\n</code></pre> <p></p> <pre><code># Distribution plot of shortest distance of phenotypes from Tumor cells\nsm.pl.spatial_distance (adata, method='distribution',distance_from='Tumor',distance_to = 'ASMA+ cells',\n    imageid='ROI_individual', log=True)\n</code></pre> <p></p> <pre><code>\n</code></pre>"},{"location":"tutorials/5-Simple_Spatial_Analysis/#spatial-co-occurance-analysis","title":"Spatial co-occurance analysis","text":"<p><code>sm.tl.spatial_interaction</code>: The function allows users to computes how likely celltypes are found next to each another compared to random background (3D data supported).</p> <pre><code># Using the radius method to identify local neighbours compute P-values\nadata = sm.tl.spatial_interaction (adata, \n                                  method='radius', \n                                  radius=30, \n                                  label='spatial_interaction_radius')\n</code></pre> <pre><code>Processing Image: ['unmicst-exemplar-001_cell']\nCategories (1, object): ['unmicst-exemplar-001_cell']\nIdentifying neighbours within 30 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\n</code></pre> <pre><code># Using the KNN method to identify local neighbours \nadata = sm.tl.spatial_interaction(adata, \n                                  method='knn', \n                                  knn=10, \n                                  label='spatial_interaction_knn')\n</code></pre> <pre><code>Processing Image: ['unmicst-exemplar-001_cell']\nCategories (1, object): ['unmicst-exemplar-001_cell']\nIdentifying the 10 nearest neighbours for every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\n</code></pre> <pre><code># view results\n# spatial_interaction heatmap for a single image\nsm.pl.spatial_interaction(adata, \n                          summarize_plot=True, \n                          binary_view=True,\n                          spatial_interaction='spatial_interaction_radius',\n                          row_cluster=False, linewidths=0.75, linecolor='black')\n</code></pre> <p></p> <pre><code># spatial_interaction heatmap for a single image\nsm.pl.spatial_interaction(adata, \n                          summarize_plot=True, \n                          binary_view=True,\n                          spatial_interaction='spatial_interaction_knn',\n                          row_cluster=False, linewidths=0.75, linecolor='black')\n</code></pre> <p></p> <pre><code># Pass the ROI's as different images\nadata = sm.tl.spatial_interaction(adata, \n                                  method='radius', \n                                  imageid = 'ROI_individual',\n                                  radius=30, \n                                  label='spatial_interaction_radius_roi')\n</code></pre> <pre><code>Processing Image: ['Other']\nCategories (1, object): ['Other']\nIdentifying neighbours within 30 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\nProcessing Image: ['artifacts']\nCategories (1, object): ['artifacts']\nIdentifying neighbours within 30 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\nProcessing Image: ['CD57-low-1']\nCategories (1, object): ['CD57-low-1']\nIdentifying neighbours within 30 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\nProcessing Image: ['CD57-low-3']\nCategories (1, object): ['CD57-low-3']\nIdentifying neighbours within 30 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\nProcessing Image: ['CD57-low-2']\nCategories (1, object): ['CD57-low-2']\nIdentifying neighbours within 30 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\nProcessing Image: ['CD57-high-3']\nCategories (1, object): ['CD57-high-3']\nIdentifying neighbours within 30 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\nProcessing Image: ['CD57-high-1']\nCategories (1, object): ['CD57-high-1']\nIdentifying neighbours within 30 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\nProcessing Image: ['CD57-high-2']\nCategories (1, object): ['CD57-high-2']\nIdentifying neighbours within 30 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\n</code></pre> <pre><code># spatial_interaction heatmap\nsm.pl.spatial_interaction(adata, \n                          summarize_plot=True, \n                          spatial_interaction='spatial_interaction_radius_roi',\n                          row_cluster=True, linewidths=0.75, linecolor='black')\n</code></pre> <p></p> <pre><code># spatial_interaction heatmap\nsm.pl.spatial_interaction(adata, \n                          summarize_plot=False, \n                          spatial_interaction='spatial_interaction_radius_roi',\n                          yticklabels=True,\n                          row_cluster=True, linewidths=0.75, linecolor='black')\n</code></pre> <p></p> <pre><code>\n</code></pre>"},{"location":"tutorials/5-Simple_Spatial_Analysis/#quantifying-the-proximity-score","title":"Quantifying the proximity score","text":"<p><code>sm.tl.spatial_pscore</code>: A scoring system to evaluate user defined proximity between cell types.  </p> <p>The function generates two scores and saved at adata.uns: - Proximity Density: Total number of interactions identified divided by the total number of cells of the cell-types that were used for interaction analysis. - Proximity Volume: Total number of interactions identified divided by the total number of all cells in the data. The interaction sites are also recorded and saved in adata.obs</p> <pre><code># Calculate the score for proximity between `Tumor CD30+` cells and `M2 Macrophages`\nadata =  sm.tl.spatial_pscore (adata,proximity= ['Tumor', 'NK cells'],\n                               score_by = 'ROI_individual',\n                               phenotype='phenotype',\n                               method='radius',\n                               radius=20,\n                               subset=None, \n                               label='spatial_pscore')\n</code></pre> <pre><code>Identifying neighbours within 20 pixels of every cell\nFinding neighbourhoods with Tumor\nFinding neighbourhoods with NK cells\nPlease check:\nadata.obs['spatial_pscore'] &amp;\nadata.uns['spatial_pscore'] for results\n</code></pre> <pre><code># Plot only `Proximity Volume` scores\nplt.figure(figsize=(10, 5))\nsm.pl.spatial_pscore (adata, color='Black', plot_score='Proximity Volume')\n</code></pre> <pre><code>/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning:\n\nPass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n</code></pre> <p></p> <pre><code># Plot only `Proximity Density` scores\nplt.figure(figsize=(10, 5))\nsm.pl.spatial_pscore (adata, color='Black', plot_score='Proximity Density')\n</code></pre> <pre><code>/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning:\n\nPass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n</code></pre> <p></p> <pre><code># voronoi plot\nplt.rcParams['figure.figsize'] = [15, 10]\nsm.pl.voronoi(adata, color_by='spatial_pscore', \n                 voronoi_edge_color = 'black',\n                 voronoi_line_width = 0.3, \n                 voronoi_alpha = 0.8, \n                 size_max=5000,\n                 overlay_points=None, \n                 plot_legend=True, \n                 legend_size=6)\n</code></pre> <p></p> <pre><code># save adata\nadata.write(str(common_path) + 'may2022_tutorial.h5ad')\n</code></pre> <pre><code>/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/anndata/_core/anndata.py:1228: FutureWarning:\n\nThe `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n\n... storing 'spatial_pscore' as categorical\n</code></pre> <p>This concludes this tutorial</p>"},{"location":"tutorials/6_animate_with_scimap/","title":"Animate with scimap","text":"<pre><code># 31 May 2022\n# Animate UMAP with SCIMAP\n# Ajit Johnson Nirmal\n</code></pre>"},{"location":"tutorials/6_animate_with_scimap/#preparing-data","title":"Preparing Data","text":"<p>The objective is to create an animation showing transition between UMAP plot and XY coordinate plot in spatial data.</p> <p>Let us use the same data that we used in the previous tutorial.</p> <pre><code># Let us start off with importing scimap\nimport scimap as sm\n</code></pre> <pre><code># let us import the same data that we using the previous tutorial\n# Check out the previous tutorial for details\ncommon_path = \"/Users/aj/Dropbox (Partners HealthCare)/conferences/scimap_tutorial/may_2022_tutorial/\"\nadata = sm.pp.mcmicro_to_scimap (feature_table_path= str(common_path) + 'exemplar_001/quantification/unmicst-exemplar-001_cell.csv')\n</code></pre> <pre><code>Loading unmicst-exemplar-001_cell.csv\n</code></pre> <p>All you need to be aware of is that you would need the XY coordinates in <code>adata.obs</code>. Check out the first two columns below. </p> <pre><code>adata.obs.head(3)\n</code></pre> X_centroid Y_centroid Area MajorAxisLength MinorAxisLength Eccentricity unmicst-exemplar-001_cell_1 1768.330435 257.226087 115 12.375868 11.823117 0.295521 unmicst-exemplar-001_cell_2 1107.173913 665.869565 92 11.874070 9.982065 0.541562 unmicst-exemplar-001_cell_3 1116.290323 671.338710 62 9.995049 8.673949 0.496871 <p>We already have one of the coordinate systems in place (i.e. the XY system). Let us generate the other coordinate system. We are going to perform <code>UMAP</code> but you can use any other method such as <code>PCA</code> or <code>TSNE</code> etc...</p> <pre><code># Run UMAP in scimap\nadata = sm.tl.umap (adata)\n</code></pre> <pre><code>OMP: Info #270: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n</code></pre> <pre><code>\n</code></pre> <p>If you are interested to know where the umap results are stored, it is in <code>adata.obsm</code>.  You might also need to know this if you plan to pass in your custom coordinate systems. You could save your custom coordinates as a 2D array in <code>adata.obsm</code> and call it in the <code>sm.hl.animate()</code> function</p> <pre><code># take a sneek peek at the UMAP results\nadata.obsm['umap']\n</code></pre> <pre><code>array([[ 5.8368936,  5.994031 ],\n[ 7.6336074,  8.640663 ],\n[ 7.0792394,  8.212058 ],\n...,\n[ 9.53943  , 11.315233 ],\n[ 8.265402 , 12.259403 ],\n[ 5.8973293,  6.0002956]], dtype=float32)\n</code></pre> <p>Now that we are set with both the coordinate systems can create the animation. However, it may be still a bit dull as we do not have intersting way to color the plot.  A common way to color a plot is by its cell-types. As I had showed previously, you could use scimap's cell phenotyping method to identify cell types. For simplicity let us cluster the data and color by those clusters.</p> <pre><code># Perform k means clustering with k=5 and save the results in a column called kmeans\nadata = adata = sm.tl.cluster (adata, k= 5, method = 'kmeans', label='kmeans')\n</code></pre> <pre><code>Kmeans clustering\n</code></pre> <pre><code># check results\nadata.obs['kmeans'].value_counts()\n</code></pre> <pre><code>1    5050\n4    4345\n0     996\n3     703\n2      76\nName: kmeans, dtype: int64\n</code></pre> <p>As you can see above we have identified 5 clusters.</p>"},{"location":"tutorials/6_animate_with_scimap/#time-for-animation","title":"Time for Animation","text":"<p>Here is the documentaion for all the parameters that are available within the <code>animate</code> function. Something to keep in mind is that not all IDE's are able to render the animation and so I highly recommend saving the animation to disk before viewing it. As saving takes quiet a long time, I generally optimize the look of the animation by subsampling the data. Sometimes <code>jupyter notebook</code> just renders a still image and so that might also help with optimization. </p> <pre><code>sm.hl.animate (adata, color='kmeans')\n</code></pre> <p></p> <p>Let us now save the animation to disk. In order to save the animation you would need something called <code>imagemagick</code> installed on your computer. Please follow this link to install it. </p> <p>To save the animation to your disk pass, the path to the location, along with the file name like so: <code>save_animation = \"/path/to/directory/my_figure\"</code></p> <pre><code>sm.hl.animate (adata, color='kmeans',\n               save_animation = '/Users/aj/Downloads/test')\n</code></pre> <pre><code>Saving file- This can take several minutes to hours for large files\n</code></pre> <p></p> <p>You might notice that the <code>gif</code> images are quiet large. I will add supoort to saving as <code>mp4</code> soon.  I generally use some online tool to convert it to <code>mp4</code> for reducing the file size. </p> <p>There are a number of <code>parameters</code> to play around with to customize the look of the animation. Check out the documentation for more details. <pre><code>palette=None, \nsubset=None, subsample=None,\nuse_layer=None, use_raw=False, log=False, \nn_frames=50, interval=50, reverse=True, final_frame=5, \ns=None, alpha=1, cmap='vlag', tight_layout=True, \nplot_legend=False, title=None, fontsize=20, pltStyle=None,\nfigsize=(5, 5)\n</code></pre></p> <p>Please note you can only plot one image at a time as in most cases the XY are unique to each image. If you are working with a dataset with multiple images, please use the <code>subset</code> parameter to subset the one image that you want to plot. As I mentioned earlier use the <code>subsample</code> parameter to optimize the feel of the plot. </p> <p>You could also <code>color</code> the plot by expression of a particular marker by using and these parmaters control different aspects of it <code>use_layer=None, use_raw=False, log=False</code> </p> <pre><code>sm.hl.animate (adata, color='CD45')\n</code></pre> <p></p> <p>Use <code>n_frames=50, interval=50, reverse=True, final_frame=5</code> to control the smoothness and duration of the animation. You can also change the theme/ background of the plot using the <code>pltStyle=None</code> paramater. </p> <pre><code>sm.hl.animate (adata, color='kmeans', pltStyle='dark_background', s=1)\n</code></pre> <p></p> <p>Note that I changed the dot size with <code>s=1</code> in the above plot. If you think that is still large, increase  the size of the entire figure using <code>figsize = (25,25)</code> which will retrospectively make the points smaller. </p>"},{"location":"tutorials/6_animate_with_scimap/#happy-animating","title":"Happy Animating.","text":"<p>I would love to see what you create. Tag me on twitter.</p>"},{"location":"tutorials/Releases/CHANGELOG/","title":"0.21.0 (2022-05-29)","text":"<ul> <li>Added <code>sm.hl.animate</code> and <code>sm.pl.umap</code></li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#02016-2022-05-28","title":"0.20.16 (2022-05-28)","text":"<ul> <li>Added <code>sm.tl.umap</code> and <code>sm.tl.spatial_similarity_search</code></li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#0190-2022-04-03","title":"0.19.0 (2022-04-03)","text":"<ul> <li>Included support for <code>Apple M1</code> machines</li> <li>Included support for native rendering of Zarr stored images using Napari: <code>pl.image_viewer</code> and <code>pl.gate_finder</code></li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#0140-2021-04-10","title":"0.14.0 (2021-04-10)","text":"<ul> <li>Included <code>sm.tl.foldchange</code> function. Also calculated p-val by Fisher exact test</li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#0120-2021-02-12","title":"0.12.0 (2021-02-12)","text":"<ul> <li>Included <code>sm.pl.voronoi</code> function. Now possible to draw voronoi diagram of the images using X/Y coordinates</li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#0110-2021-01-30","title":"0.11.0 (2021-01-30)","text":"<ul> <li>Included <code>spatial_pscore</code> function</li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#0100-2020-11-27","title":"0.10.0 (2020-11-27)","text":"<ul> <li>Included <code>stacked_barplot</code> function to generate a stacked barplot from any two cloumns</li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#090-2020-11-21","title":"0.9.0 (2020-11-21)","text":"<ul> <li>Updated <code>pl.image_viewer</code> and <code>pl.gate_finder</code> functions -     Implemeted Zarr functionality for napari viz.</li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#087-2020-11-18","title":"0.8.7 (2020-11-18)","text":"<ul> <li>Updated <code>pl.spatial_interaction</code> function to include two additional parameters -     <code>subset_phenotype</code> and <code>subset_neighbour_phenotype</code>. </li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#083-2020-11-16","title":"0.8.3 (2020-11-16)","text":"<ul> <li>Added <code>hl.add_roi</code> function. Used to incorporate ROI's extracted from Omero into the scimap object.</li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#080-2020-11-09","title":"0.8.0 (2020-11-09)","text":"<ul> <li>Updated <code>pp.mcmicro_to_scimap</code> function. Added a new parameter <code>unique_CellId</code></li> <li>Added a helper function <code>scimap_to_csv</code> to save the andata object as a CSV.</li> <li>Added documentation and tests for <code>scimap_to_csv</code></li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#0710-2020-10-30","title":"0.7.10 (2020-10-30)","text":"<ul> <li>Updated <code>pp.rescale</code> function. If a gate is included in the <code>manual_gate.csv</code>     file but no gate value is provided, the algorithm simply scales the data between    0-1 without changing the undelying structure.</li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#076-2020-10-27","title":"0.7.6 (2020-10-27)","text":"<ul> <li>Updated <code>hl.spatial_distance</code> to include option to convert to     log scale and also pass multiple <code>distance_to</code> parameter.</li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#075-2020-10-27","title":"0.7.5 (2020-10-27)","text":"<ul> <li>Updated <code>hl.classify</code> to improve speed</li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#073-2020-10-27","title":"0.7.3 (2020-10-27)","text":"<ul> <li>Addition of binary view in <code>pl.spatial_interaction</code></li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#072-2020-10-26","title":"0.7.2 (2020-10-26)","text":"<ul> <li>Addition of <code>hl.classify</code> function.</li> <li>Documentation for <code>hl.classify</code> function.</li> <li>Readme file modification</li> </ul>"},{"location":"tutorials/Releases/license/","title":"License","text":"<p>The MIT License (MIT)</p> <p>Copyright \u00a9 2020, Ajit Johnson Nirmal</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"}]}